DOI,title,1,2,3,4,5
10.1016/j.jhydrol.2007.12.026,Uncertainty assessment of integrated distributed hydrological models using GLUE with Markov chain Monte Carlo sampling (2008),The study also indicates that property distributed information of discharge is particularly crucial in model calibration and validation.,processes is accounted for by defining a measure of model performance that includes multiple criteria and spatially-distributed information.,"In recent years, there has been an increase in the application of distributed, physically-based and integrated hydrological models.",It is demonstrated that the employed methodology increases the identifiability of the parameters and results in satisfactory multi-variable simulations and uncertainty estimates.,"Many questions regarding how to property calibrate and validate distributed models and assess the uncertainty of the estimated parameters and the spatially-distributed responses are, however, still quite unexplored."
10.1016/j.jcp.2017.01.060,Inferring solutions of differential equations using noisy multi-fidelity data (2017),The only observables are scarce noisy multi-fidelity data for the forcing and solution that are not required to reside on the domain boundary.,"This general framework circumvents the tyranny of numerical discretization as well as the consistency and stability issues of time-integration, and is scalable to high-dimensions.",,,
10.1016/j.jcp.2013.01.018,A flexible numerical approach for quantification of epistemic uncertainty (2013),"If more probabilistic information about the epistemic variables is known a posteriori, the solution statistics can then be evaluated at post-process steps.",And there have been few studies and methods to deal with epistemic uncertainty.,These features thus make the new approach more flexible and amicable to practical implementation.,"() -], where a framework for numerical treatment of epistemic uncertainty was proposed.","Most notably, the new method () does not require the encapsulation problem to be in a bounded domain such as a hypercube; () does not require the solution of the encapsulation problem to converge point-wise."
10.1016/j.jcp.2016.08.043,Stability analysis of thermo-acoustic nonlinear eigenproblems in annular combustors. Part II. Uncertainty quantification (2016),It is shown that the adjoint approach reduces the number of nonlinear-eigenproblem calculations by as much as the Monte Carlo samples.,Monte Carlo and Active Subspace Identification methods are combined with first-and second-order adjoint sensitivities to perform (forward) uncertainty quantification analysis of the thermo-acoustic stability of two annular combustor configurations.,,,
10.1016/j.cma.2005.02.002,Review of options for structural design sensitivity analysis. Part 1: Linear systems (2005),"The objective is to put these different approaches to design sensitivity analysis in the context of accuracy and consistency, computational cost, and implementation options and effort.",A future paper will address design sensitivity analysis in nonlinear structural problems.,,,
10.1016/j.cma.2017.01.041,Accelerating Monte Carlo estimation with derivatives of high-level finite element models (2017),We find similar trends when comparing with a modern non-intrusive multi-level polynomial chaos expansion method.,A complete working example showing the solution of the stochastic viscous Burgers equation is included as supplementary material.,The use of derivative information amounts to a correction to the standard Monte Carlo estimation procedure that reduces the variance under certain conditions.,To study the effectiveness of the derivative-driven method we consider two stochastic PDEs; a one-dimensional Burgers equation with stochastic viscosity and a three-dimensional geometrically non-linear Mooney-Rivlin hyperelastic equation with stochastic density and volumetric material parameter.,
10.1007/s00158-010-0493-y,Effect of approximation fidelity on vibration-based elastic constants identification (2010),"With a Bayesian identification approach, the lower-fidelity analytical approximation led to reasonable results, but with much lower accuracy than the higher-fidelity approximation.","For a least squares identification approach, the approximate analytical solution led to physically implausible properties, while the high-fidelity response surface approximation obtained reasonable estimates.",This article first demonstrates that a very accurate response surface approximation can be constructed by using dimensional analysis.,,
10.1007/s00158-007-0174-7,Design optimization of stiffened storage tank for spacecraft (2008),Its structural weight is one of the key criterions in the design phase.,Stiffened storage tank is an important structural component in spacecraft.,A brief introduction to sensitivity analysis and optimization solution algorithm is also given.,There are six design cases considered in the design procedures.,
10.1016/j.jcp.2011.10.028,Adaptive ANOVA decomposition of stochastic incompressible and compressible flows (2012),"For the compressible flow, the effects of random geometric perturbations (simulating random roughness) on the scattering of a strong shock wave is investigated both analytically and numerically.",Realistic representation of stochastic inputs associated with various sources of uncertainty in the simulation of fluid flows leads to high dimensional representations that are computationally prohibitive.,We demonstrate that for both cases even draconian truncations of the ANOVA expansion lead to accurate solutions with a speed-up factor of three orders of magnitude compared to Monte Carlo and at least one order of magnitude compared to sparse grids for comparable accuracy.,A probabilistic collocation method is combined with adaptive ANOVA to obtain both incompressible and compressible flow solutions.,"We present three different adaptivity criteria and compare the adaptive ANOVA method against sparse grid, Monte Carlo and quasi-Monte Carlo methods to evaluate its relative efficiency and accuracy."
10.1016/j.jhydrol.2009.07.063,Improving parameter estimation for column experiments by multi-model evaluation and comparison (2009),"While the non-equilibrium convection dispersion equation model may match the data well, uncertainty in parameter estimates is often large.",In this work we investigate approaches to improve match for the equilibrium model and reduce parameter estimate uncertainty for the non-equilibrium model.,"By evaluating and comparing the multiple estimates obtained with different choices of calibration parameters (e.g., fixing or estimating water content), parameterizations and models (e.g., equilibrium or non-equilibrium), the reliability of the data interpretation can be improved by quantifying uncertainty in the experiment, considering alternative transport processes, and following the principle of parsimony.",The mismatch may be overcome by calibrating the effective water content.,
10.1016/j.jhydrol.2016.02.058,Copula-based IDF curves and empirical rainfall thresholds for flash floods and rainfall-induced landslides (2016),"The sensitivity analysis results indicate that the inter-event time definition (IETD) and subsample definition methodology can have a significant influence on the position of rainfall events in the intensity-duration space, the constructed IDF curves and on the relationship between the empirical rainfall threshold curves and the IDF curves constructed using the copula approach.","Floods, landslides and debris flows are natural events that occur all over the world and are often induced by extreme rainfall conditions.","Furthermore, a combination of several empirical rainfall thresholds with an appropriate high-density rainfall measurement network can be used as part of the early warning system of the initiation of landslides and debris flows.","However, different rainfall threshold curves should be used for lowland and mountainous areas in Slovenia.",The intensity-duration frequency (IDF) relationship was constructed using the Frank copula function for several rainfall stations using high-resolution rainfall data with an average subsample length of  years.
10.1016/j.jcp.2016.06.005,Polynomial meta-models with canonical low-rank approximations: Numerical insights and comparison to sparse polynomial chaos expansions (2016),"In the sequel, we confront canonical LRA to sparse PCE in structural-mechanics and heat-conduction applications based on finite-element solutions.","Through extensive numerical investigations, we herein first shed light on issues relating to the construction of canonical LRA with a particular greedy algorithm involving a sequential updating of the polynomial coefficients along separate dimensions.","Canonical LRA exhibit smaller errors than sparse PCE in cases when the number of available model evaluations is small with respect to the input dimension, a situation that is often encountered in real-life problems.",An alternative for developing meta-models with polynomial functions in high-dimensional problems is offered by the newly emerged low-rank approximations (LRA) approach.,The growing need for uncertainty analysis of complex computational models has led to an expanding use of meta-models across engineering and sciences.
10.1007/s00158-016-1487-1,Uncertainty quantification in reliability estimation with limit state surrogates (2016),A unified approach to connect the model calibration analysis using the Kennedy and O'Hagan (KOH) framework to the construction of limit state surrogate and to estimating the uncertainty in reliability analysis is developed.,The variability in the GP prediction (surrogate uncertainty) is included in reliability analysis through correlated sampling of the model predictions at different inputs.,"Model-based reliability analysis is affected by different types of epistemic uncertainty, due to inadequate data and modeling errors.","The Monte Carlo sampling (MCS) error, which represents the error due to limited Monte Carlo samples, is quantified by constructing a probability density function.",Two examples are used to demonstrate the proposed techniques.
10.1016/j.envsoft.2016.03.011,Modelling socio-ecological systems with MAIA: A biogas infrastructure simulation (2016),We used an agent-based modelling framework called MAIA to build this model with the initial motivation that it facilitates modelling complex institutional structures.,The modelling experience however proved that MAIA can also act as an integrated solution to address other major modelling challenges identified in the literature for modelling evolving socio-ecological systems.,"Building on comprehensive reviews, we reflect on our modelling experience and address four key challenges of modelling evolving socio-ecological systems using agents: () design and parameterization of models of agent behaviour and decision-making, () system representation in the social and spatial dimension, () integration of socio-demographic, ecological, and biophysical models, () verification, validation and sensitivity analysis of such ABMs.","Similar to other renewable energy technologies, the development of a biogas infrastructure in the Netherlands is going through social, institutional and ecological evolution.",
10.1007/s00158-012-0867-4,"Application of gradient-based optimization methods for a rotor system with static stress, natural frequency,and harmonic response constraints (2013)",An in-house beam-based finite element method code is used for the prediction of static and dynamic characteristics of the rotor system.,The two optimization methods are compared and discussed in regard to their performance.,Design variables are inner radii and wall thicknesses of shaft sections.,A nonlinear constrained optimization problem is considered.,Sensitivity coefficients for the natural frequencies are obtained directly from the quadratic eigenvalue problem.
10.1016/j.jhydrol.2017.06.004,Bayesian flood forecasting methods: A review (2017),"The review starts with an overview of fundamentals of BFS and recent advances in BFS, followed with BFS application in river stage forecasting and real-time flood forecasting, then move to a critical analysis by evaluating advantages and limitations of Bayesian forecasting methods and other predictive uncertainty assessment approaches in flood forecasting, and finally discusses the future research direction in Bayesian flood forecasting.",Some emerging Bayesian forecasting methods (e.g.,This paper presents a comprehensive review on Bayesian forecasting approaches applied in flood forecasting from  till now.,It is widely recognized that quantification and reduction of uncertainty associated with the hydrologic forecast is of great importance for flood estimation and rational decision making.,Future research in the context of Bayesian flood forecasting should be on assimilation of various sources of newly available information and improvement of predictive performance assessment methods.
10.1016/j.envsoft.2015.09.011,Simple approach to emulating complex computer models for global sensitivity analysis (2015),Emulators can be used to speed up the process by replacing the computer model with a statistical model that mimics the computer model and is computationally efficient.,,,,
10.1007/s00158-012-0831-3,Topology optimization to minimize the dynamic compliance of a bi-material plate in a thermal environment (2013),Topology optimization to minimize the structural dynamic compliance in a thermal environment is carried out in this paper.,"The thermal stress is first evaluated, and then considered as pre-stress in the subsequent dynamic analysis with the introduction of the geometric stiffness matrix.",A bi-material plate subjected to a uniform temperature rise is investigated.,A way to carry out the optimization in the thermal environments is presented here.,"The stress induced by the equivalent thermal force which is known as design-dependent load could reduce the stiffness of the structure, thus altering the optimal topology design."
10.1016/j.jhydrol.2013.11.027,Multisite rainfall downscaling and disaggregation in a tropical urban area (2014),"In the second part of the study, an integrated downscaling-disaggregation framework based on M-G, KNN, and MuDRain was used to generate hourly rainfall at multiple sites.","systematic downscaling-disaggregation study was conducted over Singapore Island, with an aim to generate high spatial and temporal resolution rainfall data under future climate-change conditions.",The framework was also used to project future rainfall conditions under HadCM SRES A and B scenarios.,"The results revealed that, for multisite downscaling, M-G performs better than S-G-K in covering the observed data with a lower RMSE value; for single-site disaggregation, KNN could better keep the basic statistics (i.e.",The study consisted of two major components.
10.1016/j.envsoft.2012.01.019,A sensitivity study of the WRF model in wind simulation for an area of high wind energy (2012),"Data from three wind measuring stations located within the chosen area were compared with the model results, in terms of Root Mean Square Error, Standard Deviation Error and Bias.",The grid nudging and integration time of the simulations were the tested numerical options.,"The wind direction is reasonably simulated by the model especially in wind regimes where there is a clear dominant sector, but in the presence of low wind speeds the characterization of the wind direction (observed and simulated) is very subjective and led to higher deviations between simulations and observations.","The performance of the Weather Research and Forecast (WRF) model in wind simulation was evaluated under different numerical and physical options for an area of Portugal, located in complex terrain and characterized by its significant wind energy resource.","Also, the influences of the local terrain complexity and simulation domain resolution on the model results were also studied."
10.1016/j.envsoft.2013.09.028,Parameter optimization of distributed hydrological model with a modified dynamically dimensioned search algorithm (2014),"The performance of the MDDS is compared to that of the dynamically dimensioned search (DDS), the DDS identifying only the most sensitive parameters, and the shuffled complex evolution (SCE) method, respectively, for calibration of the easy distributed hydrological model (EasyDHM).",and ) for randn' used in the MDDS algorithm or the number of strata used in the Latin hypercube (LH) sampling.,"The results show the following: the MDDS algorithm outperforms the DDS algorithm, the DDS algorithm identifying the most sensitive parameters, and the SCE algorithm within a specified maximum number of function evaluations (fewer than ); the MDDS algorithm shows robustness compared with the DDS algorithm when the maximum number of model evaluations is less than ; the advantages of the MDDS algorithm are more obvious for a high-dimensional distributed hydrological model, such as the EasyDHM model; and the optimization results from the MDDS algorithm are not very sensitive to either the variance (between .",The comparisons range from  to  model evaluations per optimization trial.,The distinguishing feature of the MDDS is that the algorithm makes full use of sensitivity information in the optimization procedure.
10.1016/S0022-1694(01)00430-9,Fuzzy conceptual rainfall-runoff models (2001),The methodology is illustrated using: () a linear conceptual rainfall-runoff model; () an experimental two-parameter model; and () a simplified version of the Sacramento soil moisture accounting model of the US National Weather Services river forecast system (SAC-SMA) known as the six-parameter model.,"In particular, bi-objective and tri-objective fuzzy regression models are applied in the case of linear conceptual rainfall-runoff models so that the decision maker may be able to trade off prediction vagueness (uncertainty) and the embedding outliers.","For the non-linear models, a fuzzy least squares regression framework is applied to derive the model parameters.",,
10.1016/j.cma.2014.07.017,Bayesian uncertainty quantification and propagation for discrete element simulations of granular materials (2014),"In turn, the parametric model uncertainties are propagated to predict Quantities of Interest (QoI) for two testbed applications: silo discharge and vibration induced mass-segregation.",Most importantly the results demonstrate the importance of including parametric and modeling uncertainties in the potentials employed in Discrete Element Methods.,The present Bayesian framework provides robust predictions for the behavior of granular materials using DEM simulations.,Predictions in the behavior of granular materials using Discrete Element Methods (DEM) hinge on the employed interaction potentials.,Our approach relies on experimentally measured coefficients of restitution for single steel particle-wall collisions.
10.1016/j.jcp.2016.12.033,An asymptotic-preserving stochastic Galerkin method for the radiative heat transfer equations with random inputs and diffusive scalings (2017),For linearized problem we prove the regularity of the solution in the random space and consequently the spectral accuracy of the gPC-SG method.,"Several numerical tests are presented to show the efficiency and accuracy of proposed scheme, especially in the diffusive regime.","In this problem the random inputs arise due to uncertainties in cross section, initial data or boundary data.","We use the generalized polynomial chaos based stochastic Galerkin (gPCSG) method, which is combined with the micro-macro decomposition based deterministic AP framework in order to handle efficiently the diffusive regime.","In this paper, we develop an Asymptotic-Preserving (AP) stochastic Galerkin scheme for the radiative heat transfer equations with random inputs and diffusive scalings."
10.1016/j.cma.2016.09.024,A generalized multi-resolution expansion for uncertainty propagation with application to cardiovascular modeling (2017),"A general stochastic system may be characterized by a large number of arbitrarily distributed and correlated random inputs, and a limited support response with sharp gradients or event discontinuities.",We also show how these binary refinements are particularly effective in avoiding the exponential increase in the multi-resolution basis cardinality and significantly reduce the regression complexity for moderate to high dimensional random inputs.,The performance of the approach is demonstrated through previously proposed uncertainty propagation benchmarks and stochastic multi-scale finite element simulations in cardiovascular flow.,"In this work, we generalize a previously proposed multi-resolution approach to uncertainty propagation to develop a method that improves computational efficiency, can handle arbitrarily distributed random inputs and non-smooth stochastic responses, and naturally facilitates adaptivity, i.e., the expansion coefficients encode information on solution refinement.","This motivates continued research into novel adaptive algorithms for uncertainty propagation, particularly those handling high dimensional, arbitrarily distributed random inputs and non-smooth stochastic responses."
10.1007/s00158-003-0374-8,Sensitivity analysis of bridge flutter with respect to mechanical parameters of the deck (2004),"During the design phase, the sensitivity analysis gives very interesting information about the gradient of the flutter speed with respect to the key chosen design variables, moments of inertia of the bridge deck.",A methodology for carrying out an analytical sensitivity analysis of the flutter phenomenon in long-span bridges is developed.,Decks of bridges are generally bluff bodies and therefore the aeroelastic forces under wind action have to be experimentally evaluated in wind tunnels.,,
10.1016/j.envsoft.2005.04.010,Sensitivity analysis based on regional splits and regression trees (SARS-RT) (2006),The method which has been proposed in this paper is based on multiple regression trees (so called Random Forests).,The examples demonstrate the capability of this methodology and stress the importance of the application of sensitivity analysis.,Two methods of sensitivity analysis are used: in the first method the total information gain achieved by each parameter is evaluated.,The latter distinction is applied in the generalized likelihood uncertainty estimation (GLUE) and regional sensitivity analysis (RSA) framework to analyse model results and is used here to derive regression tree (model) structures.,The splits at each node of the regression tree are sampled from a probability distribution.
10.1016/j.cma.2009.02.030,Finite element response sensitivity analysis of multi-yield-surface J(2) plasticity model by direct differentiation method (2009),This algorithm is implemented in a general-purpose nonlinear finite element analysis program.,The normalized response sensitivity analysis results are then used to measure the relative importance of the soil constitutive parameters on the system response.,The complete derivation of the DDM-based response sensitivity algorithm is presented.,"Finite element (FE) response sensitivity analysis is an essential tool for gradient-based optimization methods used in various sub-fields of civil engineering such as structural optimization, reliability analysis, system identification, and finite element model updating.","The work presented in this paper extends significantly the framework of DDM-based response sensitivity analysis, since it enables numerous applications involving the use of the multi-yield-surface J() plasticity material model."
10.1016/j.cma.2015.03.012,A Bayesian approach to selecting hyperelastic constitutive models of soft tissue (2015),"While numerous constitutive models have been proposed in the literature, an objective method is needed to select a parsimonious model that represents the experimental data well and has good predictive capability.","In this work, we discuss a Bayesian approach to this problem based on Bayes factors.",A nested sampling approach is used to evaluate the evidence integrals.,"In our results, we highlight the robustness of the proposed Bayesian approach to model selection compared to the likelihood ratio, and discuss the use of the four factors to draw a complete picture of the model selection problem.",
10.1016/j.jcp.2016.01.004,An adaptive strategy on the error of the objective functions for uncertainty-based derivative-free optimization (2016),"In multi-objective problems, the decision is based on the comparison of the error bounding box of the current design and the current Pareto front.",The errors on the objective function can be interpreted with the abstraction of a bounding box around the nominal estimation in the objective functions space.,"With this strategy, fewer computations are made for clearly dominated solutions and an accurate estimate of the objective function is provided for the interesting, non-dominated solutions.","In single-objective problems, the current bounding box is compared to the current optimal design.","In addition, in some cases the uncertainty quantification methods providing the objective functions also supply the possibility of adaptive refinement to reduce the error bounding box."
10.1016/j.jhydrol.2010.04.010,Hydrological model uncertainty assessment in southern Africa (2010),Further work is required to reduce some of the subjectivity in the methods and to investigate other approaches for constraining the uncertainty.,"The method is based on well-documented principles of sensitivity and uncertainty analysis, but recognizes the limitations that exist within the region (data scarcity and accuracy, model user attitudes, etc.).","This paper proposes a framework for establishing parameter values, exploring parameter inter-dependencies and setting parameter uncertainty bounds for a monthly time-step rainfall-runoff model (Pitman model) that is widely used in the region.",The parameters that dominate the model response and their degree of uncertainty vary between regions.,Four example applications taken from different climate and physiographic regions of South Africa illustrate that the methods are appropriate for generating behavioural stream flow simulations which include parameter uncertainty.
10.1016/j.jhydrol.2011.12.027,Separating aleatory and epistemic uncertainties: Probabilistic sewer flooding evaluation using probability box (2012),Uncertainty is generally present in flood evaluation and can be divided into aleatory and epistemic categories.,Simulation results demonstrate the critical importance of separating aleatory and epistemic uncertainties and of maintaining the uncertainty type (either aleatory or epistemic) in uncertainty propagation.,It is suggested that the pooling of aleatory and epistemic uncertainties may lead to incoherent information in the model output.,"Consequently, the probabilistic flood evaluation is expressed by probability boxes.",
10.1016/j.envsoft.2017.01.004,A modernized version of a 1D soil vegetation atmosphere transfer model for improving its future use in land surface interactions studies (2017),"In particular, a new interface to the model is presented, so-called ""SimSphere-SOA"" which forms a command line land biosphere tool, a Web Service interface and a parameters verification facade that offers a standardised environment for specification execution and result retrieval of a typical model simulation based on Service Oriented Architecture (SOA).",The inclusion of those new functions in SimSphere are of considerable importance in the light of the model's expanding use worldwide as an educational and research tool.,"The use of these new functionalities offered by SimSphere-SOA is also demonstrated using a ""real world"" simulation configuration file.",This way a simulation by the model can be executed efficiently and subsequently the model simulation outputs may be used in any kind of relevant analysis required.,"Herein, we present recent advancements introduced to SimSphere code, aiming at making its use more integrated to the automation of processes within High Performance Computing (HPC) that allows using the model at large scale."
10.1007/s00158-005-0582-5,A topology optimization approach using VOF method (2006),"Through numerical examples, the validity of the proposed method is investigated.","To suppress these phenomena, the employment of additional strategies such as the perimeter control or the filtering method will be required.","In this paper, a topology optimization method which can eliminate these difficulties is developed based on the volume of fluid (VOF) method.",,
10.1007/s00158-014-1208-6,The ESO method revisited (2015),A complementary discussion on previous communications about ESO and strategies to overcome the Zhou-Rozvany problem is also presented.,It is also discussed that the Bidirectional ESO (BESO) method is not prone to this shortcoming and it is suggested that the two methods be considered as completely separate optimisation techniques.,By proposing a problem statement for ESO followed by an accurate sensitivity analysis a framework is presented in which ESO is mathematically justifiable.,"It is shown that when using a sufficiently accurate sensitivity analysis, ESO method is not prone to the problem proposed by Zhou and Rozvany (Struct Multidiscip Optim ():-, ).",
10.1016/j.jcp.2011.03.001,A stochastic mixed finite element heterogeneous multiscale method for flow in porous media (2011),Numerical examples are presented for both deterministic and stochastic permeability to show the accuracy and efficiency of the developed stochastic multiscale method.,"Starting from a specified covariance function, the stochastic log-permeability is discretized in the stochastic space using a truncated Karhunen-Loeve expansion with several random variables.","In order to capture the small scale heterogeneity, a new mixed multiscale finite element method is developed within the framework of the heterogeneous multiscale method (HMM) in the spatial domain.",This new method ensures both local and global mass conservation.,"Due to the small correlation length of the covariance function, this often results in a high stochastic dimensionality."
10.1007/s00158-016-1565-4,Topology optimization for hybrid additive-subtractive manufacturing (2017),"Given the manufacturing strategy, the topology design is produced through additive manufacturing and the shape preserved boundary segments will be processed by post-machining.","To address this issue, this work presents a topology optimization method for hybrid additive and subtractive manufacturing.","To be specific, the boundary segments of the input design domain are categorized into two types: (i) Freeform boundary segments freely evolve through the casting SIMP method, and (ii) shape preserved boundary segments suppress the freeform evolvement and are composed of machining features through a feature fitting algorithm.","Part design for this hybrid manufacturing approach has been done by trial-and-error, and no dedicated design methodology exists for this manufacturing approach.",
10.1016/j.envsoft.2012.09.011,Characterising performance of environmental models (2013),"This paper reviews techniques available across various fields for characterising the performance of environmental models with focus on numerical, graphical and qualitative methods.","In order to use environmental models effectively for management and decision-making, it is vital to establish an appropriate level of confidence in their performance.","General classes of direct value comparison, coupling real and modelled values, preserving data patterns, indirect metrics based on parameter values, and data transformations are discussed.","A five-step procedure for performance evaluation of models is suggested, with the key elements including: (i) (re)assessment of the model's aim, scale and scope; (ii) characterisation of the data for calibration and testing; (iii) visual and other analysis to detect under- or non-modelled behaviour and to gain an overview of overall performance; (iv) selection of basic performance criteria; and (v) consideration of more advanced methods to handle problems such as systematic divergence between modelled and observed values.",
10.1016/S0045-7825(00)00228-0,Implicit consistent and continuum tangent operators in elastoplastic boundary element formulations (2001),This paper presents an assessment and comparison of boundary element method (BEM) formulations for elastoplasticity using both the consistent tangent operator (CTO) and the continuum tangent operator (CON).,"This computational setting is also used in the development of a method for calculating the J integral, which is an important parameter in (nonlinear) fracture mechanics.",These operators are integrated into a single computational implementation using linear or quadratic elements for both boundary and domain discretizations.,,
10.1016/j.jhydrol.2015.05.051,Modeling residual hydrologic errors with Bayesian inference (2015),This technical note outlines a residual error model (likelihood function) specification framework that aims to provide guidance for the application of more appropriate residual error models through a nested approach that is both flexible and extendible.,Hydrologic modelers are confronted with the challenge of producing estimates of the uncertainty associated with model predictions across an array of catchments and hydrologic flow regimes.,,,
10.1016/j.cma.2014.11.021,Stochastic reduced order models for inverse problems under uncertainty (2015),Characterizing the uncertainties with SROMs transforms the stochastic optimization problem into a deterministic one.,The non-intrusive nature of SROMs facilitates efficient gradient computations for random vector unknowns and relies entirely on calls to existing deterministic solvers.,The new and widely-applicable SROM framework is formulated for a general stochastic optimization problem in terms of an abstract objective function and constraining model.,"Given statistical information about an observed state variable in a system, unknown parameters are estimated probabilistically through the solution of a model-constrained, stochastic optimization problem.",We also show that the approach remains effective for the case where the loading in the problem is random as well.
10.1016/j.envsoft.2006.09.009,A macroscopic collisional model for debris-flows simulation (2007),"It is able to simulate the erosion of the regolith along the flow path, besides branching and rejoining events of the flow masses.","In case of no dissipation, conservation of energy and momentum are also assured.",Calibration confirmed the reliability of the model in reproducing the considered case of study.,"Model calibration has been carried out through parallel Genetic Algorithms, by considering the May  Curti-Samo (Campania, Southern Italy) debris flow.",
10.1016/j.jcp.2009.03.022,Verified predictions of shape sensitivities in wall-bounded turbulent flows by an adaptive finite-element method (2009),"To ensure accuracy, grid convergence and to reduce computational time, an adaptive finite-element method driven by asymptotically exact error estimations is used.",error estimators and the adaptive strategy.,The adaptive process is controlled by error estimates on both flow and sensitivity solutions.,A Continuous Sensitivity Equation (CSE) method is presented for shape parameters in turbulent wall-bounded flows modeled with the standard k-epsilon turbulence model with wall functions.,"Differentiation of boundary conditions and their complex dependencies on shape parameters, including the two-velocity scale wall functions, is presented in details along with the appropriate methodology required for the CSE method."
10.1016/j.cma.2014.11.012,Topology optimization of viscoelastic structures using a time-dependent adjoint method (2015),Creep plots are used to quantify the impact of the viscoelastic optimization method.,The results show that the design of the optimal structure is highly dependent on the load duration and the complete load history.,This result supports the design premise that it is necessary to account for the full viscoelastic response of the structure when designing for optimal long-term performance.,The resulting formula is then incorporated into a computational topology optimization framework in order to achieve optimal topologies based on the expected lifespan or operating cycle of the structure.,Designs are optimized for minimum mass subject to a constraint on the maximum local deflection.
10.1007/s00158-014-1137-4,Thermo-structural optimization of integrated thermal protection panels with one-layer and two-layer corrugated cores based on simulated annealing algorithm (2015),The results demonstrated that the two-layer structure provides superior structural efficiency and performance to resist thermal buckling deformation in comparison with the one-layer panel.,"Heat transfer and structural field analysis for each panel configuration were performed to obtain the temperature, buckling, stress and deflection responses for structural components of interest, which were then considered as critical constraints of the optimization problem.","Toexplore weight saving potential capability, a multidisciplinary optimization procedure based on simulated annealing algorithm was proposed to unveil the minimum weight design for integrated thermal protection system subjected to in-service thermal and mechanical loads.",The panel configurations with one-layer and two-layer corrugated cores are considered for comparison.,
10.1016/j.envost.2006.08.008,Systematic testing of an integrated systems model for coastal zone management using sensitivity and uncertainty analyses (2007),This paper presents such a framework and the respective procedure.,"The inherent complexity of the integrated systems models, the philosophical debate about the model validity and validation, the uncertainty in model inputs, parameters and future context and the scarcity of field data complicate model validation.",The usefulness of the procedure is demonstrated for two examples.,"Three tests, namely, Parameter-Verification, Behaviour-Anomaly and Policy-Sensitivity are selected to test a Rapid assessment Model for Coastal-zone Management (RaMCo).",
10.1007/s00158-016-1612-1,Topology optimization of structures with anisotropic plastic materials using enhanced assumed strain elements (2017),The objective of topology optimization is to maximize the plastic work.,The results illustrate that the optimized topologies are highly dependent on the plastic anisotropic material properties.,"In order to avoid the locking issue, the Enhanced Assumed Strain (EAS) elements are adopted in the finite element discretization, and the anisotropic Hoffman plasticity model, which can simulate the strength differences in tension and compression, is incorporated within the framework of density-based topology optimization.",,
10.1016/j.jcp.2014.07.027,An adjoint-based lattice Boltzmann method for noise control problems (2014),The line search step in Newton's descent method is performed through a combination of complex differentiation and adjoint problem in the lattice Boltzmann method.,"To this end, an adjoint-based lattice Boltzmann method is proposed to solve the adjoint problem.",,,
10.1007/s00158-017-1724-2,Level set topology optimization considering damage (2017),The geometry of the structures is represented by the level set method.,The sensitivities are evaluated by an analytical derivation of the discretized governing equations of the system and considering the adjoint approach.,This paper provides a level set based topology optimization approach to design structures exhibiting resistance to damage.,The mechanical model represents quasi-brittle materials.,
10.1016/j.cma.2011.11.001,On the assessment of a Bayesian validation methodology for data reduction models relevant to shock tube experiments (2012),Experimental data collected at the Electric Arc Shock Tube (EAST) facility at the NASA Ames Research Center (ARC) are employed to illustrate the validation procedure.,These processes usually employ mathematical models that have to be properly calibrated and rigorously validated so that their reliability can be clearly assessed.,A validation procedure based on a Bayesian approach is applied here to a data reduction model used in shock tube experiments.,,
10.1016/S0045-7825(02)00538-8,Computational design of deformation processes for materials with ductile damage (2003),A continuum sensitivity method is developed for thermoplasticity combined with ductile damage at finite.,,,,
10.1016/j.envsoft.2007.09.008,Nutrient load modelling during floods in intermittent rivers: An operational approach (2008),The model simulates pollutographs at the outlet of the catchment during rainfall events: the rainfall triggers the processes.,"Three parameters describe the processes involved: the initial stock of pollutants on the hillslopes, the production parameter (which is related to the lag time of the catchment) and the routing parameter (which is related to the lag time of a basic river reach).","First, sensitivity analysis demonstrated that each of the parameters controlled one key-feature of the pollutograph.","Reliable tools for evaluating pollutant loads from land sources are needed for managing the water quality of the receiving waters, but available water quality models are not suitable for simulating these flash flood events.","An operational tool, D-PoL (Diffuse-Pollution Load), to estimate the pollutant loads transferred during rainfall events by small Mediterranean rivers is described."
10.1007/s00158-011-0696-x,PolyTop: a Matlab implementation of a general topology optimization framework using unstructured polygonal finite element meshes (2012),"Also, as part of our examination of the topology optimization problem, we review the various steps taken in casting the optimal shape problem as a sizing optimization problem.",The code also features a modular structure in which the analysis routine and the optimization algorithm are separated from the specific choice of topology optimization formulation.,This endeavor allows us to isolate the finite element and geometric analysis parameters and how they are related to the design variables of the discrete optimization problem.,We address issues pertaining to the use of unstructured meshes and arbitrary design domains in topology optimization that have received little attention in the literature.,
10.1016/j.cma.2016.04.001,Structural topology optimization with minimum distance control of multiphase embedded components by level set method (2016),Several numerical examples are presented to demonstrate the validity and effectiveness of the proposed method.,"Different from existing distance detection methods relying on explicit topology representation, the proposed constraint is imposed as a unified integral form, for which the design sensitivity can be readily obtained.",This paper presents a novel topology optimization method for designing structures with multiphase embedded components under minimum distance constraints in the level set framework.,,
10.1007/s00158-014-1081-3,Probabilistic sensitivity analysis for novel second-order reliability method (SORM) using generalized chi-squared distribution (2014),"In terms of accuracy, the proposed probabilistic sensitivity analysis is compared with the finite difference method (FDM) using the Monte Carlo simulation (MCS) through numerical examples.","Thus, this study presents sensitivity analysis of the novel SORM at MPP for more accurate RBDO.","To develop RBDO utilizing the recently proposed novel second-order reliability method (SORM) that improves conventional SORM approaches in terms of accuracy, the sensitivities of the probabilistic constraints at the most probable point (MPP) are required.",The numerical examples demonstrate that the analytic sensitivity of the novel SORM agrees very well with the sensitivity obtained by FDM using MCS when a performance function is quadratic in U-space and input variables are normally distributed.,Reliability-based design optimization (RBDO) requires evaluation of sensitivities of probabilistic constraints.
10.1016/j.cma.2010.08.013,Computational uncertainty analysis in multiresolution materials via stochastic constitutive theory (2011),"The contribution of this work is twofold: uncertainty is propagated from heterogeneous material ""structure"" to material ""property"" via the stochastic constitutive theory, and rigorous, data-driven mathematics are formalized to represent complicated dependence structures in multivariate statistical distributions.","To the authors' knowledge, this is the first work in multiresolution mechanics that presents an approach to computationally derive correlation functions from numerical experiments, as opposed, for instance, to assuming one a priori.","Ubiquitous fine resolution uncertainty sources influencing prediction of material properties based on their structures are categorized in detail, and this research transmits these uncertainties to coarser material resolutions by introducing a stochastic constitutive theory deduced from volume element simulations.","To implement the stochastic upscaling process, two advanced uncertainty quantification methods are examined: statistical copula functions and random process polynomial chaos expansion.",
10.1016/j.jhydrol.2017.03.063,Determination of the saturated film conductivity to improve the EMFX model in describing the soil hydraulic properties over the entire moisture range (2017),High quality data that cover the complete moisture range for a variety of soil textures are required to further test the method.,"The sensitivity analysis result suggests that the uncertainty in the film thickness estimation is important in explaining the model underestimation of hydraulic conductivity for the soils with fine texture, in addition to the uncertainties from the measurements and the model structure.","Difficulty in measuring hydraulic conductivity, particularly under dry conditions, calls for methods of predicting the conductivity from easily obtained soil properties.","This method reduces one fitting parameter in the previous EMFX model, making it possible to predict the hydraulic conductivity from the soil water retention curve over the complete moisture range.","In comparison with the commonly used van Genuchten-Mualem model, the EMFX-K model significantly improves the prediction of hydraulic conductivity under dry conditions."
10.1016/j.envsoft.2012.04.005,Assessing the use of activated sludge process design guidelines in wastewater treatment plant projects: A methodology based on global sensitivity analysis (2012),Design outputs are calculated by sampling the previously defined input ranges and propagating this variation through the design guideline.,"Standard regression coefficients (SRC), cluster analysis (CA) and response surfaces (RS) are used to identify/interpret the design inputs that influence the variation on the design outputs the most.","For this reason, there is a need to determine how both design inputs and outputs are linked and how they affect wastewater treatment plant (WWTP) designs.","The novelty of this approach relies on working with design input and output ranges instead of single values, identifying the most influential design inputs on the different design outputs and improving the interpretation of the generated results with a set of visualization tools.","Design inputs (wastewater characteristics, operational settings, effluent requirements or safety factors, ...) need to be supplied when using activated sludge process design guidelines (ASPDG) to determine the design outputs (biological reactor volume, the dissolved oxygen demand or the different internal/external recycle flow-rates)."
10.1007/s001580050156,Sensitivity analysis and optimum design curves for the minimum cost design of singly and doubly reinforced concrete beams (2000),"Despite the simplification of the cost model and the assumptions made, satisfactory and reliable results have been obtained and confirmed by using standard design office procedures.",This paper reports on the application of the Lagrangian Multiplier Method (LMM) to the minimum cost design of both singly and doubly reinforced concrete rectangular beams under Limit state design conditions.,The proposed approach is effective and reliable without the need for iterative trials.,Cost objective functions and stress constraints are derived and implemented within the optimization method.,Optimum design curves have been developed that can be used without prior knowledge of optimization.
10.1007/s00158-016-1621-0,An efficient lightweight design strategy for body-in-white based on implicit parameterization technique (2017),"In the early design phase of vehicles, performing lightweight design of body-in-white (BIW) using shape, size and topology optimization is a challenge.","Firstly, a full parameterized model of BIW is established with implicit parametrization technique via SFE-CONCEPT.","The large amount of design parameters including size, shape of cross-sections and positions of various parts are the main contributors to the challenge, which will lead to the huge computational cost for running a large number of finite element (FE) simulations and function evaluations.","Secondly, the GSA technique is used to reduce the dimensions of design space.",
10.1016/j.cma.2012.06.022,Integrated layout design of multi-component systems using XFEM and analytical sensitivity analysis (2012),Both solid and void components are considered to show the efficiency and accuracy of the proposed shape sensitivity analysis method.,The level set method is used to represent components and is combined with the XFEM to describe material discontinuities across elements.,"Furthermore, a revised finite circle method that adapts shape changes of elliptical components is proposed for the definition of non-overlapping constraints.",An analytical shape sensitivity analysis method with respect to positions and shapes of components is developed.,This study presents the integrated layout optimization of multi-component systems using a fixed mesh.
10.1016/j.jcp.2015.12.031,"Variational Bayesian strategies for high-dimensional, stochastic design problems (2016)","the high computational cost of each forward simulation, the large number of random variables) but also by the need to solve a nonlinear optimization problem involving large numbers of design variables and potentially constraints.",We propose a framework that is suitable for a class of such problems and is based on the idea of recasting them as probabilistic inference tasks.,"This paper is concerned with a lesser-studied problem in the context of model-based, uncertainty quantification (UQ), that of optimization/design/control under uncertainty.",We demonstrate the validity of the proposed approach in the context of two numerical examples involving thousands of random and design variables.,
10.1007/s00158-014-1131-x,Isogeometric configuration design optimization of built-up structures (2015),The obtained design sensitivity is further utilized in the shape design optimization of built-up structures.,"Due to the non-interpolatory property of the NURBS basis functions, a mismatch of patches in the built-up structures could occur during the isogeometric design optimization, which can be easily resolved using transformed basis functions.",We derive the isogeometric configuration sensitivity of the Mindlin plates by using the material derivative and adjoint approaches.,The impact of exact curvature in the bending problem of Mindlin plates on the configuration design sensitivity is demonstrated through numerical examples.,
10.1016/j.envsoft.2007.05.010,Parameter and input data uncertainty estimation for the assessment of long-term soil organic carbon dynamics (2008),"Sources of uncertainties assessed in this study stem from uncertainties in model parameterisation and from uncertainties in model input data (climate, soil data, and land management assumptions).","The use of integrated soil organic matter (SOM) models to assess SOM dynamics under climate change, land use change and different land management practices require a quantification of uncertainties and key sensitive factors related to the respective modelling framework.",Results obtained by this study can be transferred and used in other simulation models of this kind.,"Derived from this analysis, key sensitive model parameters and interactions between them were identified: the mineralization rate coefficient, the carbon use efficiency parameter (synthesis coefficient) along with parameters determining the soil temperature influence on SOM turnover (mainly Q  value) and the soil input related data (soil bulk density and initial soil C content) introduced the highest degree of model uncertainty.",to +/- .% soil carbon content (.-.
10.1016/j.jhydrol.2013.11.031,Uncertainty in open channel discharge measurements acquired with StreamPro ADCP (2014),The assessment of individual uncertainty components is based on the best available information and the results of customized experiments.,This paper investigates the implementation of a rigorous uncertainty analysis protocol to measurements conducted with StreamPro ADCP operated with the stationary method (a.k.a.,The implementation example illustrates that the standardized uncertainty analysis framework can be successfully applied for hydrometric measurements.,Elements and framework of the uncertainty analysis presented in this paper can be applied to other instruments that estimate stream discharge using a section-by-section method.,The StreamPro Acoustic Doppler Current Profiler (ADCP) is a favorite solution for making discharge measurements of medium and small streams in practical situations.
10.1016/j.cma.2017.06.021,Arbitrary void feature control in level set topology optimization (2017),"Feature-driven topology optimization has been extensively studied in the past decade, and the majority of the works have treated it as the multi-component/void layout optimization problem.","To be specific, by tailoring the specified void feature size, the void length scale is guaranteed to be larger than that.",A major limitation of this treatment is that the number of components/voids should be defined in advance.,Numerical stability of this method is discussed and an auxiliary algorithm has been developed to enhance it.,"Through a few numerical case studies, it is proven that the void feature control method is effective while only limited compromise of the structural performance has been observed."
10.1016/j.envsoft.2009.10.005,"Sensitivity analysis of the rice model WARM in Europe: Exploring the effects of different locations, climates and methods of analysis on model sensitivity to crop parameters (2010)","Exceptions were observed, depending on the sensitivity method (e.g.","Radiation use efficiency (RUE), optimum temperature (T(opt)), and leaf area index at emergence (LAI(ini)) ranked in most of the combinations site x year as first, second and third most relevant parameters.","LAI(ini) resulted not relevant by the Morris method), or site-continentality pattern (e.g.","This issue is addressed, in this study, as an application of sensitivity analysis techniques to a crop model in the Mediterranean region.","In particular, an application of Morris and Sobol' sensitivity analysis methods to the rice model WARM is presented."
10.1016/j.envsoft.2016.11.024,Exploring snow model parameter sensitivity using Sobol' variance decomposition (2017),"However, the lack of sensitivity of SNOW- to climate warming suggests that it may not be as reliable as a more sensitive model like VIC.","We consider several distinct snow-dominated locations in the western United States, running both SNOW-, a conceptual degree-day model, and the Variable Infiltration Capacity (VIC) snow model, a physically based model.",Model performance is rigorously evaluated through global sensitivity analysis and a temperature warming analysis is conducted to explore how model parameterizations affect portrayals of climate change.,,
10.1016/j.jhydrol.2013.03.047,Effects of measurement uncertainties of meteorological data on estimates of site water balance components (2013),"In this study, the actual measurement uncertainties of input and reference data are the main focus.","Summarised and generalised, the measurement uncertainties of all input data create an uncertainty on average of around % in the simulated annual evapotranspiration and of around % in the simulated annual seepage.",A special feature is the use of evapotranspiration (measured via the eddy covariance) instead of runoff for evaluation of simulation results.,"Thereby, it has become apparent that the effects of measurement uncertainties on model results are similar for complex and for simple models.",It is demonstrated that uncertainties of individual variables are not simply superposed but interact in a complex way.
10.1016/j.envsoft.2014.05.026,An evaluation of adaptive surrogate modeling based optimization with two benchmark problems (2014),(C)  The Authors.,A minimum Interpolation Surface method is the best adaptive sampling method.,"It involves several steps, including initial sampling, regression and adaptive sampling.",Some - times the dimension of the problem may be the proper initial sample size; ) The ASMO method is much more efficient than the widely used Shuffled Complex Evolution global optimization method.,Low discrepancy Quasi Monte Carlo methods are the most suitable initial sampling designs.
10.1016/j.jcp.2008.01.019,A scalable framework for the solution of stochastic inverse problems using a sparse grid collocation approach (2008),The stochastic inverse/design problem is transformed to a deterministic optimization problem in a larger-dimensional space that is subsequently solved using deterministic optimization algorithms.,The representation of the underlying uncertainties and the resultant stochastic dependant variables is performed using a sparse grid collocation methodology.,"The design framework relies entirely on deterministic direct and sensitivity analysis of the continuum systems, thereby significantly enhancing the range of applicability of the framework for the design in the presence of uncertainty of many other systems usually analyzed with legacy codes.","A scalable, parallel methodology for stochastic inverse/design problems is developed in this article.",Experimental evidence suggests that the dynamics of many physical phenomena are significantly affected by the underlying uncertainties associated with variations in properties and fluctuations in operating conditions.
10.1007/s00158-014-1150-7,Reliability-based design optimization for vehicle occupant protection system based on ensemble of metamodels (2015),"The First Order Reliability Method (FORM) and Second Order Reliability Method (SORM) are used to calculate the reliability index, and the results are checked by Monte Carlo (MC) simulation respectively, from which the failure probability of the OPS performance design is obtained.","To provide a feasible framework for decreasing occupant injury degree, this paper presents a practical approach of the Reliability-based Design Optimization (RBDO) for vehicle OPS performance development based on the ensemble of metamodels.","Generally, the deterministic optimum designs without considering the uncertainty of design variables frequently push design constraints to the limit of boundaries and lead objective performance variation to largely fluctuate.",The comparative result shows that the prediction accuracies of the ensemble of metamodels exceed all individual one.,"So, the RBDO is presented and aims to maintain design feasibility at a desired reliability level."
10.1016/j.envsoft.2013.09.005,Evaluating integrated assessment models of global climate change (2013),To answer this urgent question is a challenge because the systems are open and their future behavior is fundamentally unknown.,An important element in evaluating IAM of global climate change is the use of stylized behavior patterns derived from historical observation.,It builds on a systematic and transparent step-by-step demonstration of a model's usefulness testing the plausibility of its behavior.,Insights from these complex models are widely used to advise policy-makers and to inform the general public.,"In this paper, we discuss ways to overcome these problems."
10.1007/s00158-011-0659-2,Sampling-based RBDO using the stochastic sensitivity analysis and Dynamic Kriging method (2011),"In addition, newly proposed efficiency strategies as well as parallel computing help find the optimum design very efficiently.","Once the D-Kriging accurately approximates the responses, there is no further approximation in the estimation of the probabilistic constraints and stochastic sensitivities, and thus the sampling-based RBDO can yield very accurate optimum design.","The Dynamic Kriging (D-Kriging) method is used for surrogate models, and a stochastic sensitivity analysis is introduced to compute the sensitivities of probabilistic constraints with respect to independent or correlated random variables.","To further improve computational efficiency of the sampling-based RBDO method for large-scale engineering problems, parallel computing is proposed as well.",This paper presents a sampling-based RBDO method using surrogate models.
10.1016/j.cma.2003.12.055,Robust design of structures using optimization methods (2004),The first two statistical moments of the stochastic parameters including design variables are considered in conjunction with the second-order perturbation method for the approximation of mean value and variance of the structural response.,The robust design of structures with stochastic parameters is studied using optimization techniques.,The robustness of the feasibility is also taken into account by involving the variability of the Structural response in the constraints.,,
10.1016/j.jcp.2016.05.044,Data-driven probability concentration and sampling on manifold (2016),A new methodology is proposed for generating realizations of a random vector with values in a finite-dimensional Euclidean space that are statistically consistent with a dataset of observations of this vector.,A random matrix is introduced whose columns are independent copies of the random vector and for which the number of columns is the number of data points in the dataset.,"The probability distribution of this random vector, while apriori not known, is presumed to be concentrated on an unknown subset of the Euclidean space.",The convergence aspects of the proposed methodology are analyzed and a numerical validation is explored through three applications of increasing complexity.,The proposed method is found to be robust to noise levels and data complexity as well as to the intrinsic dimension of data and the size of experimental datasets.
10.1016/j.jhydrol.2012.11.045,A groundwater management tool for solving the pumping cost minimization problem for the Tahtali watershed (Izmir-Turkey) using hybrid HS-Solver optimization algorithm (2013),"Results indicate that the proposed simulation-optimization model is found to be efficient in identifying the optimal numbers, locations, and pumping rates of the pumping wells for satisfying the given constraints.","Also, a sensitivity analysis is performed to evaluate the model results for different sets of HS solution parameters.",These constraints that need to be satisfied in the optimization process are set up using the penalty function approach.,Some physical and managerial constraints are defined for this problem.,This study proposes a linked simulation-optimization model to solve the groundwater pumping cost minimization problem for existing and new wells to satisfy any given water demand.
10.1016/j.envsoft.2011.03.013,Performance and sensitivity analysis of stormwater models using a Bayesian approach and long-term high resolution data (2011),Stormwater models are important tools in the design and management of urban drainage systems.,Understanding the sources of uncertainty in these models and their consequences on the model outputs is essential so that subsequent decisions are based on reliable information.,It was found that the effective impervious fraction is the most important parameter in both models while both were insensitive to dry weather related parameters.,"The aim of this paper is to present the performance and parameter sensitivity of stormwater models with different levels of complexities, using the formal Bayesian approach.",
10.1016/j.jhydrol.2017.03.007,Uncertainty analysis of impacts of climate change on snow processes: Case study of interactions of GCM uncertainty and an impact model (2017),"Specifically, when the peaks of the distributions of daily mean temperature projected by GCMs cross the key thresholds set in the model, the GCM uncertainty, even if tiny, can be amplified by the nonlinear propagation through the snow process model.",This amplification results in large uncertainty in projections of CC impact on snow processes.,"In particular, we examined how the uncertainty due to GCMs propagated through the snow model, which contained nonlinear processes defined by thresholds, as an example of the uncertainty caused by interactions among multiple sources of uncertainty.","An assessment based on the climate projections in Coupled Model Intercomparison Project Phase  indicated that heavy -snowfall areas in the temperate zone (especially in low-elevation areas) were markedly vulnerable to temperature change, showing a large SWE reduction even under slight changes in winter temperature.",The impact of climate change on snow water equivalent (SWE) and its uncertainty were investigated in snowy areas of subarctic and temperate climate zones in Japan by using a snow process model and climate projections derived from general circulation models (GCMs).
10.1007/s00158-006-0064-4,Sensitivity analysis of the linear nonconservative systems with fractional damping (2007),"In this paper, the influence of small structural perturbation on a linear, nonconservative dynamical system exhibiting fractional bifurcation was investigated.",The stability conditions of generalized Lyapunov type for the system with hereditary damping were derived.,"In this paper, the influence of small perturbation on a linear, nonconservative dynamical system exhibiting a flutter type bifurcation was investigated.","To study the dynamical instability for nonconservative governing equations with fractional damping, the method of auxiliary eigenvalue problem is applied.",
10.1016/j.jcp.2017.05.051,Nested polynomial trends for the improvement of Gaussian process-based predictors (2017),"Such a method considers the quantity of interest of the system as a particular realization of a Gaussian stochastic process, whose mean and covariance functions have to be identified from the available code evaluations.",Such numerical procedures are generally based on the processing of a huge amount of code evaluations.,"When confronted to deterministic mappings, the Gaussian process regression (GPR), or kriging, presents a good compromise between complexity, efficiency and error control.","When the computational cost associated with one particular evaluation of the code is high, such direct approaches based on the computer code only, are not affordable.","In this context, this work proposes an innovative parametrization of this mean function, which is based on the composition of two polynomials."
10.1016/j.jhydrol.2009.10.025,Parameter optimization and uncertainty analysis for plot-scale continuous modeling of runoff using a formal Bayesian approach (2010),"This study reports on the use the recently developed Differential Evolution Adaptative Metropolis algorithm (DREAM) to calibrate in a Bayesian framework the continuous, spatially distributed, process-based and plot-scale runoff model described by Laloy and Bielders ().",The model validation on an independent -year series of measurements showed reasonable values for the Nash-Sutcliffe efficiency criterion.,"The calibration procedure, relying on  years of daily runoff measurements, accounted for heteroscedasticity and autocorrelation.","for, respectively, the Upper and lower bounds of the % uncertainty interval associated with parameter uncertainty.",The calibrated model reproduced the observed hydrograph satisfactorily during calibration.
10.1007/s00158-008-0266-z,Isogeometric shape design optimization: exact geometry and enhanced sensitivity (2009),The variation of control points results in shape changes and is continuous over the whole design space.,,,,
10.1016/j.jcp.2011.10.031,Data-free inference of the joint distribution of uncertain model parameters (2012),The analysis focuses on the family of posterior distributions consistent with given statistics (e.g.,"The developed approach allows subsequent propagation of uncertainty in model inputs consistent with reported statistics, in the absence of data.",,,
10.1007/s00158-015-1337-6,Reliability-based design optimization by adaptive-sparse polynomial dimensional decomposition (2016),"When applied in collaboration with the multi-point, single-step framework, the proposed methods afford the ability of solving industrial-scale design problems.",This paper puts forward two new methods for reliability-based design optimization (RBDO) of complex engineering systems.,"In both methods, the failure probability and its design sensitivities are determined concurrently from a single stochastic simulation or analysis.","The methods involve an adaptive-sparse polynomial dimensional decomposition (AS-PDD) of a high-dimensional stochastic response for reliability analysis, a novel integration of AS-PDD and score functions for calculating the sensitivities of the failure probability with respect to design variables, and standard gradient-based optimization algorithms, encompassing a multi-point, single-step design process.",
10.1016/j.cma.2014.02.004,Partitioned treatment of uncertainty in coupled domain problems: A separated representation approach (2014),"The construction of the coupled domain solution is achieved though a sequence of approximations with respect to the dimensionality of the random inputs associated with each individual sub-domain and not the combined dimensionality, hence drastically reducing the overall computational cost.",This work is concerned with the propagation of uncertainty across coupled domain problems with high-dimensional random inputs.,,,
10.1007/s00158-008-0309-5,A multi-point reduced-order modeling approach of transient structural dynamics with application to robust design optimization (2009),The basis is further enriched by gradients of the POD modes with respect to the design/random parameters.,The numerical results suggest that the proposed ROM approach is well suited for large parameter changes and that the number of basis vectors needs to be increased only linearly with the number of design and random parameters to maintain a particular ROM performance.,"The accuracy, efficiency and robustness of the proposed framework are studied with a two-dimensional model problem.",This paper presents a reduced-order modeling (ROM) framework for approximating the transient response of linear elastic structures over a range of design and random parameters.,The application of the proposed ROM approach to robust shape optimization demonstrates significant savings in computational cost over using full-order models.
10.1016/j.jcp.2017.04.003,"On the Bayesian calibration of computer model mixtures through experimental data, and the design of predictive models (2017)",We propose the Bayesian calibration of computer model mixture method which relies on the idea of representing the real system output as a mixture of the available computer model outputs with unknown input dependent weight functions.,We provide a technique able to mitigate the computational overhead due to the consideration of multiple computer models that is suitable to the mixture model framework.,"Moreover, it fits a mixture of calibrated computer models that can be used by the domain scientist as a mean to combine the available computer models, in a flexible and principled manner, and perform reliable simulations.","The method builds a fully Bayesian predictive model as an emulator for the real system output by combining, weighting, and calibrating the available models in the Bayesian framework.",The method does not require knowledge of the fidelity order of the models.
10.1016/j.envsoft.2014.09.023,Multiobjective optimisation on a budget: Exploring surrogate modelling for robust multi-reservoir rules generation under hydrological uncertainty (2015),"Developing long term operation rules for multi-reservoir systems is complicated due to the number of decision variables, the non-linearity of system dynamics and the hydrological uncertainty.","Results suggest that MOSBOs are indeed able to provide robust, uncertainty-aware operation rules much faster, without significant loss of neither the generality of evolutionary algorithms nor of the knowledge embedded in domain-specific models.",,,
10.1016/S0045-7825(99)00314-X,Perturbation mapping method for sensitivity analysis of three-dimensional cracks near a free surface (2000),A perturbation mapping method and a computational procedure are presented for evaluating the sensitivity coefficients of the stress intensity factors for three-dimensional planar cracks near a free surface.,Numerical results for penny-shaped and elliptical cracks are presented showing the variation of the sensitivity coefficients with various geometric and material parameters.,The boundary integral equations for evaluating the sensitivity coefficient are solved by using the boundary element method.,"Each of the geometric parameters that affect the stress intensity factor (such as, crack orientation, distance from the free surface, and crack shape parameters) is given a perturbation which defines a mapping between the original and perturbed coordinate systems, from which the sensitivity coefficients are derived.",
10.1016/j.cma.2009.11.021,A gPC-based approach to uncertain transonic aerodynamics (2010),The results allow for a better understanding of the flow sensitivity to such uncertainties and underline the coupling process between the stochastic parameters.,"Two kinds of non-linearities are critical with respect to the skin-friction uncertainties: on one hand, the leeward shock movement characteristic of the supercritical profile and on the other hand, the boundary-layer separation on the aft part of the airfoil downstream the shock.","The sensitivity analysis, thanks to the Sobol' decomposition, shows that a strong non-linear coupling exists between the uncertain parameters.",,
10.1007/s00158-002-0242-y,Recursive sensitivity analysis for constrained multi-rigid-body dynamic systems design optimization (2002),"With the large dimensionality and complexity of many modern multibody dynamic applications, the efficiency of the sensitivity evaluation method used greatly impacts the overall computation costs, and as such can signficantly limit the usefulness of the sensitivity information.",,,,
10.1016/j.envsoft.2016.10.005,A new approach to evaluate spatiotemporal dynamics of controlling parameters in distributed environmental models (2017),The difference between them can be used to assess the influence of parameter constraints on the results of sensitivity analyses.,We applied this holistic approach to an existing distributed karst watershed model.,"To comprehensively evaluate the spatiotemporal dynamics of model controls, we propose a novel multi-step approach based on Sobol's method to evaluate parameter sensitivity as well as interactions with respect to different model outlet points, using different objective functions to assess different hydrodynamic conditions; all varying through time.",Distributed environmental models are usually high-dimensional and non-linear.,"The results demonstrated that ) a limited number of spatially-distributed parameters control the varying flow pattern, ) the model is nonlinear and the influential parameters are highly correlated in the model domain and ) the spatial patterns of identified parameter sensitivity and interactions are strongly influenced by the specified parameter bounds."
10.1007/s00158-013-0894-9,Simultaneous shape and topology optimization of shell structures (2013),The currently practiced technology for optimization is to find the topology first and then to refine the shape of structure.,"Since the MMA optimization method requires derivatives of the objective function and the volume constraint with respect to the design variables, a sensitivity analysis is performed.","In this paper, the design parameters of shape and topology are optimized simultaneously in one go.",It is shown that this approach is well matched with the large number of topology and shape design variables.,"In order to model and control the shape of free form shells, the NURBS (Non Uniform Rational B-Spline) technology is used."
10.1016/S0021-9991(03)00186-4,Perturbation-based moment equation approach for flow in heterogeneous porous media: applicability range and analysis of high-order terms (2003),Formulations based on equations written explicitly in terms of permeability (K-based) and log-transformed permeability (Y-based) are considered.,We combined MCS computations with full discrete SME equations to quantify the importance of the various terms that make up the moment equations.,These differences (model errors) are due to embedded assumptions and differences in implementing the discrete forms of the equations.,"We show that second-moment solutions obtained using a low-order Y-based SME formulation are significantly better than those from K-based formulations, especially when sigma(y)() > .","Thus, while the moment equations are exact, they are not closed."
10.1016/j.envsoft.2015.04.001,Multi-objective model auto-calibration and reduced parameterization: Exploiting gradient-based optimization tool for a hydrologic model (2015),"Two sets of roughness coefficients for main channels, one assigned and calibrated according on soil types and one determined via empirical equations, were examined for stream discharge simulation.",The time-series processor TSPROC was used to combine multiple objectives into the auto-calibration process.,"Model-independent software Parameter ESTimation (PEST) was used to auto-calibrate ISWAT, a modified version of the distributed hydrologic model Soil and Water Assessment Tool (SWAT), in the Shenandoah River watershed.","Multi-objective model optimization methods have been extensively studied based on evolutionary algorithms, but less on gradient-based algorithms.",
10.1016/S0045-7825(00)00306-6,Accurate displacement derivatives for structural optimization using approximate reanalysis (2001),The solution procedure is based on results of a single exact analysis at an initial design.,A unified approach for accurate approximations of displacements and displacement derivatives with respect to design variables is presented.,"Rather, approximations of displacements are used to evaluate displacement derivatives at various modified designs.","Unlike common approximations of the structural response, the approach presented is nut based on calculation of derivatives.",
10.1007/s00158-015-1300-6,Non-parametric stochastic subset optimization for design problems with reliability constraints (2015),The RBDO problem is then solved using this approximation for evaluating the reliability constraints over the entire design domain and identifying the feasible region satisfying them.,NP-SSO is based on simulation of samples from this density and approximation of this reliability through kernel density estimation (KDE) using these samples.,A second refinement stage after initial convergence is also proposed to further improve the accuracy of the identified feasible region.,A non-parametric characterization of the search space using a framework based on multivariate boundary KDE and support vector machine is established.,This paper discusses its extension to reliability-based design optimization (RBDO) applications involving reliability criteria as a design constraint.
10.1016/j.cma.2012.01.001,Simplified CSP analysis of a stiff stochastic ODE system (2012),The analysis is then used to guide the application of a simplified CSP formalism that is based on relating the slow and fast manifolds of the uncertain system to those of a nominal deterministic system.,"Numerical experiments are conducted to demonstrate the results of the stochastic eigenvalue and eigenvector analysis, and illustrate the effectiveness of the simplified CSP algorithms in addressing the stiffness of the system dynamics.","We restrict our attention to a system that exhibits distinct timescales, and that tends to a deterministic steady state irrespective of the random inputs.",,
10.1016/j.envost.2007.02.004,Uncertainty in the environmental modelling process - A framework and guidance (2007),"Instead uncertainty should be seen as a red thread throughout the modelling study starting from the very beginning, where the identification and characterisation of all uncertainty sources should be performed jointly by the modeller, the water manager and the stakeholders.",,,,
10.1016/j.cma.2004.03.019,A survey of non-probabilistic uncertainty treatment in finite element analysis (2005),The objective of this paper is to critically review the emerging non-probabilistic approaches for uncertainty treatment in finite element analysis.,The paper discusses general theoretical and practical aspects of both the interval and fuzzy finite element analysis.,The second part of the paper focuses on numerical aspects of the interval finite element method.,"The necessary conditions for a useful application of the non-probabilistic concepts are determined, and are proven to be complementary rather than competitive to the classical probabilistic approach.","First, the applicability of the non-probabilistic concepts for numerical uncertainty analysis is discussed from a theoretical viewpoint."
10.1016/j.envsoft.2010.04.011,Identification and classification of uncertainties in the application of environmental models (2010),The presented method improves the comparability of uncertainty analyses in different model studies and leads to a coherent overview of uncertainties affecting model outcomes.,"Because of the multiplicity of frameworks available for uncertainty analysis, the outcomes of such analyses are rarely comparable.","To provide decision makers with realistic information about these model outcomes, uncertainty analysis is indispensable.","In the support of environmental management, models are frequently used.",
10.1016/j.jcp.2017.06.026,Sequential data assimilation with multiple nonlinear models and applications to subsurface flow (2017),"Meanwhile, available but limited observations of system state could further complicateone's prediction choices.","Based on an earlier study of Multi-model Kalman filter, we propose a novel framework to assimilate multiple models with observation data for nonlinear systems, using extended Kalman filter, ensemble Kalman filter and particle filter, respectively.",,,
10.1016/j.jhydrol.2007.05.027,Application of linear programming and differential evolutionary optimization methodologies for the solution of coastal subsurface water management problems subject to environmental criteria (2007),Then the classical linear programming optimization algorithm of the Simplex method is used to solve the groundwater management problem where the main objective is the hydraulic control of the saltwater intrusion.,"Finally, a sensitivity analysis is employed in order to examine the influence of the active pumping wells in the evolution of the seawater intrusion front along the coastline.",The solution of the non-linear management problem is also obtained using a heuristic algorithm.,A comparison of the results obtained by the two different optimization approaches is presented.,In the past optimization techniques have been combined with simulation models to determine cost-effective solutions for various environmental management problems.
10.1007/s00158-006-0069-z,Analytical derivatives technology for structural shape design (2007),"The classical design of experiments (DOE)-based approach that is motivated from statistics (for physical experiments) is one of the possible approaches for the evaluation of the component response with respect to design parameters [Myers, Montgomery.",Shape design or optimization in the context of finite element modeling is challenging because the evaluation of the response for different shape requires the need for a meshing consistent with the new geometry.,"In this paper, we explore an alternate sensitivity-analysis-based technique where a deterministic parametric response is constructed using exact derivatives of the complex finite-element (FE)-based computer models to design parameters.",This paper examines the differences in the nature and performance ( accuracy and efficiency) of the analytical derivatives approach against other existing approaches with validation on several benchmark structural applications.,"The ability to perform and evaluate the effect of shape changes on the stress and modal responses of components is an important ingredient in the ""design"" of aircraft engine components."
10.1007/s00158-015-1261-9,Topology and shape optimization methods using evolutionary algorithms: a review (2015),"Topology optimization has evolved rapidly since the late s. The optimization of the geometry and topology of structures has a great impact on its performance, and the last two decades have seen an exponential increase in publications on structural optimization.","Both fields have been researched in great detail over the last two decades, to the point where structural topology optimization has been applied to real world structures.","There are two main fields in structural topology optimization, gradient based, where mathematical models are derived to calculate the sensitivities of the design variables, and non gradient based, where material is removed or included using a sensitivity function.","Previous methods suffered from mathematical complexity and a limited scope for applicability, however with the advent of increased computational power and new techniques topology optimization has grown into a design tool used by industry.",The article concludes with new applications of topology optimization and applications in various engineering fields.
10.1016/j.cma.2011.11.005,Topological layout design of electro-fluid-thermal-compliant actuator (2012),"To efficiently solve four sets of nonlinearly coupled equations, a sequence of iterative solutions to the equations is proposed and a nonlinear sensitivity analysis without consideration of the iterative solution sequence is derived based on the adjoint sensitivity analysis method.","Thus, the goal of this research is to develop a new and rigorous monolithic analysis and optimization framework for an electro-fluid-thermal-compliant (EFTC) microactuator.",Several three-dimensional examples are also examined in order to demonstrate the validity and potential of the present formulations for analysis and TO.,"To accommodate the coupling effect of the fluid and thermal domains, a modified incompressible Navier-Stokes equation with Darcy's force and a heat transfer equation coupled with fluid motion are additionally formulated in the present research.","Using the solid isotropic material with penalization (SIMP) approach to interpolate seven material properties (Young's modulus, electrical conductivity, heat conductivity, heat capacity, mass density, heat capacity, and Darcy's force coefficient) with respect to a density design variable, it is possible to achieve topology optimization (TO) upon consideration of the strong nonlinear couplings of the EFTC actuator."
10.1007/s00158-017-1734-0,Matrix-free algorithm for the optimization of multidisciplinary systems (2017),"The Krylov method also needs to be preconditioned, and a key contribution of this work is a novel and effective preconditioner that is based on approximating a monolithic solution of the (linearized) multidisciplinary system.",We demonstrate the efficacy of the algorithm by comparing it with the popular multidisciplinary feasible formulation on two test problems.,IDF achieves modularity by introducing optimization variables and constraints that effectively decouple the disciplinary solvers during each optimization iteration.,"The Krylov method requires matrix-vector products, which can be evaluated in a matrix-free manner using second-order adjoints.","Furthermore, limited-memory quasi-Newton approximations, commonly used for large-scale problems, exhibit linear convergence rates that can struggle with the large number of design variables introduced by the IDF formulation."
10.1016/j.jcp.2016.07.040,Manifold learning for the emulation of spatial fields from computational models (2016),"For Gaussian process (GP) emulation, approximations of the correlation structure and/or dimensionality reduction are necessary.","Although emulators can be used to find faithful and computationally inexpensive approximations of computer models, there are few methods for handling high-dimensional output spaces.",Manifold learning can overcome the limitations of linear methods if an accurate inverse map is available.,,
10.1007/s00158-009-0450-9,An SLP filter algorithm for probabilistic analytical target cascading (2010),"Decision-making under uncertainty is particularly challenging in the case of multidisciplinary, multilevel system optimization problems.","By linearizing and solving a problem successively, the strategy takes advantage of the simplicity and ease of uncertainty propagation for a linear system under the assumption that inputs are normally distributed or can be transformed into equivalent normal distributions.","A suspension strategy, developed for a deterministic SLP coordination strategy for ATC, is applied to reduce computational cost by suspending the analyses of subsystems that do not need considerable redesign.",The accuracy and effectiveness of the proposed coordination strategy is demonstrated with several numerical examples.,Analytical target cascading (ATC) is a deterministic optimization method for multilevel hierarchical system design that has been extended to probabilistic formulations.
10.1016/j.envsoft.2011.09.010,Numerical assessment of metamodelling strategies in computationally intensive optimization (2012),Numerical results show that metamodelling is not always an efficient and reliable approach to optimizing computationally intensive problems.,"Some studies refer to the metamodelling approach as function approximation, surrogate modelling, response surface methodology or model emulation.","There is a sizeable body of literature developing and applying a variety of metamodelling strategies to various environmental and water resources related problems including environmental model calibration, water resources systems analysis and management, and water distribution network design and optimization.","This paper initially develops a comparative assessment framework which presents a clear computational budget dependent definition for the success/failure of the metamodelling strategies, and then critically evaluates metamodelling strategies, through numerical experiments, against other common optimization strategies not involving metamodels.","For simpler response surfaces, metamodelling can be very efficient and effective."
10.1016/j.cma.2016.08.023,Addressing the curse of dimensionality in SSFEM using the dependence of eigenvalues in KL expansion on domain size (2016),It has been reported in the literature that for few covariance kernels a lower domain size leads to a faster convergence of the KL eigenvalues.,This reduction hinges on some new mathematical results on domain size dependence of the Karhunen-Loeve (KL) expansion.,This is achieved via developing a bound on eigenvalues as a function of the domain size.,The cost saving increases with the stochastic dimensionality in the global domain.,"In this work first we mathematically show the generalization of this faster convergence, that is, for any arbitrary covariance kernel."
10.1016/j.cma.2015.06.012,Shape optimization of Dirichlet boundaries based on weighted B-spline finite cell method and level-set function (2015),"Meanwhile, the computing accuracy is ensured within the framework of fixed grid owing to the quadtree refinements of boundary cells.","As both the structure and Dirichlet boundaries are described in the form of LSF, any modification of Dirichlet boundaries can be made in a straightforward way as easily as free boundaries by changing continuous design variables.","Unlike traditional FEM, the weighted B-spline finite cell method (FCM) is applied as structural analysis tool and combined with the level-set function (LSF) to take into account Dirichlet boundary condition (DBC) automatically through penalization of the displacement field.",,
10.1016/j.jcp.2017.09.024,An efficient algorithm for building locally refined hp - adaptive H-PCFE: Application to uncertainty quantification (2017),"In order to address this apparent void, this paper presents an improved H-PCFE, referred to as locally refined hp - adaptiveH-PCFE.","Furthermore, as compared to hp - adaptivePCFE, significantly less number of actual function evaluations are required for obtaining results of similar accuracy.",It is observed that the proposed approach yields highly accurate results.,"The proposed framework computes the optimal polynomial order and important component functions of PCFE, which is an integral part of H-PCFE, by using global variance based sensitivity analysis.",Hybrid polynomial correlated function expansion (H-PCFE) is a novel metamodel formulated by coupling polynomial correlated function expansion (PCFE) and Kriging.
10.1016/j.jhydrol.2013.11.016,Combining hydraulic knowledge and uncertain gaugings in the estimation of hydrometric rating curves: A Bayesian approach (2014),"In addition to providing the rigorous statistical framework necessary to uncertainty analysis, the main advantage of the Bayesian analysis of rating curves arises from the quantitative assessment of (i) the hydraulic controls that govern the stage-discharge relation, and of (ii) the individual uncertainties of available gaugings, which often differ according to the discharge measurement procedure and the flow conditions.","In this paper, we introduce the BaRatin method for the Bayesian analysis of stationary rating curves and we apply it to three typical cases of hydrometric stations with contrasted flow conditions and variable abundance of hydraulic knowledge and gauging data.",,,
10.1016/j.envsoft.2016.10.004,Addressing factors fixing setting from given data: A comparison of different methods (2017),This paper deals with global sensitivity analysis of computer model output.,"Then, they are applied to two different responses of a soil drainage model.",The results show that the polynomial chaos expansion for estimating Sobol' indices is the most efficient approach.,,
10.1007/s00158-014-1075-1,Sensitivity analysis of structural response to position of external applied load: in plane stress condition (2014),"Apart from the structural response evaluation, the finite element method is employed in this work for the sensitivity analysis implementation of a plane stress continuum structure.","Then, the relevant sensitivities of the structural responses aforementioned are formulated readily with the discrete method.",,,
10.1016/j.cma.2015.12.016,A fuzzy-stochastic multiscale model for fiber composites A one-dimensional study (2016),We study mathematical and computational models for computing the deformation of fiber-reinforced polymers due to external forces.,"We first show that the present uncertainties/variabilities, which are of both random and non-random types, cannot be accurately characterized by current stochastic multiscale models based on precise probability theory, such as stationary random fields.","Next, we present a new hybrid fuzzy-stochastic model, which can more accurately describe uncertainties/variabilities in fiber composites.","A thorough study requires an understanding of both micro-structural effects and uncertainty/variability in the manufacturing process, such as uncertainty in the size and distribution of fibers and variability in material properties and fracture parameters.",The algorithm utilizes the concept of representative volume elements and homogenization and constructs a global solution to compute a local approximation that captures the microscale features of the problem.
10.1016/j.jcp.2016.02.046,Emulation of dynamic simulators with application to hydrology (2016),Increasing the number of design data sets is a computationally demanding way of improving the accuracy of emulation.,An emulator is a fast approximation to a simulator that interpolates between design input-output pairs of the simulator.,This stochastic model is then conditioned to the design data so that it mimics the behavior of the nonlinear simulator as a function of the parameters.,The goal of this paper is to compare the gain in accuracy of these emulators by enlarging the design data set and by varying the degree of simplification of the linear model.,"However, the transition to a spatially continuous linear model leads again to a similarly large gain in accuracy as the transition from the non-mechanistic emulator to that based on one reservoir."
10.1016/j.jcp.2010.08.038,Level set method for the inverse elliptic problem in nonlinear electromagnetism (2010),The gradient directions are evaluated using the sensitivity equation and the adjoint variable method.,The reconstruction is realized by the minimization of a cost function using the steepest descent method.,,,
10.1016/j.jcp.2013.11.019,An adaptive ANOVA-based PCKF for high-dimensional nonlinear inverse modeling (2014),The probabilistic collocation-based Kalman filter (PCKF) is a recently developed approach for solving inverse problems.,"Also, for sequential data assimilation problems, the basis functions kept in PCE expression remain unchanged in different Kalman filter loops, which could limit the accuracy and computational efficiency of classic PCKF algorithms.","Thus, instead of expanding the original model into PCE, we implement the PCE expansion on these low-dimensional functions, which is much less costly.","To address this issue, we present a new algorithm that adaptively selects PCE basis functions for different problems and automatically adjusts the number of basis functions in different Kalman filter loops.","In classic PCKF algorithms, the PCE basis functions are pre-set based on users' experience."
10.1016/j.jcp.2016.07.036,A hybrid anchored-ANOVA - POD/Kriging method for uncertainty quantification in unsteady high-fidelity CFD simulations (2016),"As a result, global accuracy can be achieved with a reasonable number of samples allowing computationally expensive CFD-UQ analysis.","As unsteady high-fidelity CFD simulations are becoming the standard for industrial applications, reducing the number of required samples to perform sensitivity (SA) and uncertainty quantification (UQ) analysis is an actual engineering challenge.","To significantly increase the contribution of numerical computational fluid dynamics (CFD) simulation for risk assessment and decision making, it is important to quantitatively measure the impact of uncertainties to assess the reliability and robustness of the results.",A comparison of the three methods is given for each application.,
10.1016/j.cma.2014.06.025,Adaptive importance sampling for optimization under uncertainty problems (2014),"Therefore, the IS density is only constructed for the most important parameters, with the exact number also a variable that is optimally selected based on the anticipated accuracy.",The characteristics of the proposal density are optimally selected to minimize the anticipated coefficient of variation for the objective function if such a proposal density is used as IS distribution.,"The proposed formulation relies only on available information (i.e., function evaluations) from the current iteration of the optimization process to improve estimation accuracy in subsequent iterations, and therefore corresponds to a IS selection with a small additional computational burden.",Design-under-uncertainty problems where a probabilistic performance is adopted as objective function and its estimation is obtained through stochastic simulation are discussed.,The focus is on reducing the computational burden associated with the stochastic simulation through adaptive implementation of importance sampling (IS) across the iterations of the optimization algorithm.
10.1007/s00158-016-1552-9,Estimation of measurement errors in orthotropic elastic moduli determined from natural frequencies (2017),This paper proposes an efficient method to estimate the errors in the elastic moduli caused by the measurement errors in the natural frequencies.,The approximation is then used to estimate the variability of the identified elastic moduli due to the measurement errors.,"However, due to measurement errors contained in the measured natural frequencies and mode shapes, the process of elastic moduli identification is error-prone.",It is shown that the aspect ratio of the test specimen greatly affects the standard deviation of the identified elastic moduli.,"Second, using the first-order approximation, the effects of aspect ratio of the test specimen as well as the values of the elastic moduli are further investigated."
10.1016/j.jcp.2016.03.065,Fast simulations of patient-specific haemodynamics of coronary artery bypass grafts based on a POD-Galerkin method and a vascular shape parametrization (2016),"In particular, a reduced-order simulation takes only a few minutes to run, resulting in computational savings of % of CPU time with respect to the full-order discretization.","This computational framework allows to characterize blood flows for different physical and geometrical variations relevant in the clinical practice, such as stenosis factors and anastomosis variations, in a rapid and reliable way.",POD-Galerkin reduced-order models are employed to cut down large computational costs.,We combine several efficient algorithms to face at the same time both the geometrical complexity involved in the description of the vascular network and the huge computational cost entailed by time dependent patient-specific flow simulations.,In this work a reduced-order computational framework for the study of haemodynamics in three-dimensional patient-specific configurations of coronary artery bypass grafts dealing with a wide range of scenarios is proposed.
10.1007/s00158-003-0362-z,Conceptual design of aeroelastic structures by topology optimization (2004),"The fluid-structure interaction problem is modeled by a three-field formulation that couples the structural displacements, the flow field, and the motion of the fluid mesh.",The optimization results show the significant influence of the design dependency of the loads on the optimal layout of flexible structures when compared with results that assume a constant aerodynamic load.,The proposed methodology is illustrated by the conceptual design of wing structures.,"The topology of the wet surface, that is, the fluid-structure interface, is not varied.",A topology optimization methodology is presented for the conceptual design of aeroelastic structures accounting for the fluid-structure interaction.
10.1016/j.cma.2016.10.042,Sequential approximate optimization for design under uncertainty problems utilizing Kriging metamodeling in augmented input space (2017),At each SAO cycle a sub-region of the design space is defined and a kriging metamodel is built exploiting information from the previous SAO cycle to improve accuracy.,"This information is subsequently used to search for a local optimum within the considered design sub-region till convergence to an interior point or the boundary of the region is established, prompting the termination of the current SAO cycle.","This setting facilitates a great modeling flexibility but has an associated high computational burden, and a framework relying on kriging surrogate modeling is proposed here to address this challenge.","Through this approach an adaptive control for the accuracy of the metamodel is achieved, minimizing the number of simulations for the expensive system model.","The metamodel is formulated to approximate the system response (metamodel output) with respect to both the design variables and the uncertain model parameters (augmented metamodel input), so that it can simultaneously support the uncertainty propagation and the design optimization, adopting a sequential approximate optimization (SAO) strategy for the latter."
10.1016/j.envsoft.2012.03.014,Estimating Sobol sensitivity indices using correlations (2012),Sensitivity analysis is a crucial tool in the development and evaluation of complex mathematical models.,"This paper introduces new notation that describes the Sobol indices in terms of the Pearson correlation of outputs from pairs of runs, and introduces correction terms to remove some of the spurious correlation.",Sobol's method is a variance-based global sensitivity analysis technique that has been applied to computational models to assess the relative importance of input parameters on the output.,A variety of estimation techniques are compared for accuracy and precision using the G function as a test case.,
10.1016/j.cma.2016.12.026,A rapid and efficient isogeometric design space exploration framework with application to structural mechanics (2017),A surrogate model to the design space solution manifold is constructed through either an interpolating polynomial or pseudospectral expansion.,"Moreover, this framework enables the visualization of a full system response, including the displacement and stress fields throughout the domain, by providing an approximation to the system solution vector.","In this paper, we present an isogeometric analysis framework for design space exploration.",,
10.1007/s00158-016-1542-y,Two-scale topology design optimization of stiffened or porous plate subject to out-of-plane buckling constraint (2016),This paper studies maximum out-of-plane buckling load design of thin bending plates for a given amount of material.,The volume preserving nonlinear density filter is applied to obtain the black-white optimum topology and comparison of its different sensitivities is made to show the reason for oscillation during optimization process in Appendix.,"The new numerical implementation of asymptotic homogenization method (NIAH, Cheng (Acta Mech Sinica (): -, ) and Cai (Int J Solids Struct (), -, ) is applied to homogenization of periodic plate structures and analytic sensitivity analysis of effective stiffness with respect to the topological design variables in both macro-scale and micro-scale.",One is made of periodic homogeneous porous material.,Two kinds of plates are considered.
10.1016/j.cma.2016.06.024,Adaptive reduced-basis generation for reduced-order modeling for the solution of stochastic nondestructive evaluation problems (2016),The first case study considered characterization of an unknown localized reduction in stiffness of a structure from simulated frequency response function based nondestructive testing.,A novel algorithm for creating a computationally efficient approximation of a system response that is defined by a boundary value problem is presented.,"Then, the second case study considered characterization of an unknown temperature-dependent thermal conductivity of a solid from simulated thermal testing.","More specifically, the approach presented is focused on substantially reducing the computational expense required to approximate the solution of a stochastic partial differential equation, particularly for the purpose of estimating the solution to an associated nondestructive evaluation problem with significant system uncertainty.","Overall, the surrogate modeling approach was shown through both simulated examples to provide accurate solution estimates to inverse problems for systems represented by stochastic partial differential equations with a fraction of the typical computational cost."
10.1016/j.jcp.2014.09.014,Enhancing adaptive sparse grid approximations and improving refinement strategies using adjoint-based a posteriori error estimates (2015),We use adjoint-based a posteriori error estimates of the physical discretization error and the interpolation error in the sparse grid to enhance the sparse grid approximation and to drive adaptivity of the sparse grid.,In this paper we present an algorithm for adaptive sparse grid approximations of quantities of interest computed from discretized partial differential equations.,Throughout this paper we also provide and test a framework for balancing the physical discretization error with the stochastic interpolation error of the enhanced sparse grid approximation.,,
10.1007/s00158-008-0298-4,Adhesive surface design using topology optimization (2009),A methodology is introduced for designing adhesive interfaces between structures using topology optimization.,Varying simultaneously both adhesive and geometric parameters yields a wider range of reachable target load-displacement curves than in the case varying adhesive energy alone.,Structures subjected to external loads that lead to delamination are studied for situations where displacements and deformations are small.,Two- and three dimensional design optimization problems are presented in which adhesive force distributions are designed such that load-displacement curves of delaminating structures match target responses.,"The design variables describe the adhesive energy per area of the interface between the surfaces, as well as the geometry of the delaminating structure."
10.1016/j.jhydrol.2009.11.047,An urban drainage stormwater quality model: Model development and uncertainty quantification (2010),A possible to this problem may be the adoption of simplified parsimonious models that generally require shorter computational times.,"To date, several detailed mathematical models are available to predict stormwater quantity-quality characteristics in urban drainage systems.",The cohesive properties of sewer sediments were carefully considered.,"The evaluation of urban stormwater quality is of relevant importance for urban drainage, and mathematical models may be of great interest in this respect.","Nevertheless, only few studies have been carried out in the urban drainage field, and very few deal with water quality issues."
10.1016/j.jcp.2011.04.012,"Computationally efficient solution to the Cahn-Hilliard equation: Adaptive implicit time schemes, mesh sensitivity analysis and the 3D isoperimetric problem (2011)","This strategy - coupled with a domain decomposition based parallel implementation let us notably augment the efficiency of a numerical Cahn-Hillard solver, and open new venues for its practical applications, especially when three dimensional problems are considered.",We use this framework to address the isoperimetric problem of identifying local solutions in the periodic cube in three dimensions.,We analyze the error fluctuations using these test problems on the split form of the Cahn-Hilliard equation solved using the finite element method with basis functions of different orders.,Our findings show that linear basis functions have superior error-to-cost properties.,
10.1016/j.cma.2017.06.015,Topology optimization of continuum structures subjected to filtered white noise stochastic excitations (2017),The algorithm is demonstrated on design problems of minimizing the variance of stochastic response under a volume constraint and several numerical examples are provided to show the effectiveness of the method.,"To reduce the computational cost and maintain high accuracy, closed-form solutions are utilized for evaluating the response variance and modal truncation is adopted to reduce dimension (the effect of which is investigated).","The Solid Isotropic Material with Penalization Method is used together with the Heaviside Projection Method to achieve a clear distinction between solid and void regions in the structure, and the gradient-based optimizer Method of Moving Asymptotes informed by sensitivities of the real and complex eigenvectors is used to evolve the design.",The objective is to manipulate the variance of the stochastic dynamic response of a linear continuum structure through design.,This work addresses the challenge of topology optimization for continuum structures subjected to non-white noise stochastic excitations.
10.1016/j.cma.2017.03.007,CutFEM topology optimization of 3D laminar incompressible flow problems (2017),Species transport is modeled by an advection diffusion equation.,"Numerical results for D, steady-state and transient problems demonstrate that the CutFEM analyses are sufficiently accurate, and the optimized designs agree well with results from prior studies solved in D or by density approaches.",This paper studies the characteristics and applicability of the CutFEM approach of Burman et al.,The fluid behavior is modeled by the incompressible Navier-Stokes equations.,An auxiliary indicator field is modeled to identify these volumes and to impose a constraint on the average pressure.
10.1016/j.jhydrol.2017.04.052,The effect of coupling hydrologic and hydrodynamic models on probable maximum flood estimation (2017),"However, runoff processes are probably not stationary in the case of a probable maximum flood (PMF) where discharge greatly exceeds observed flood peaks.","Deterministic rainfall-runoff modelling usually assumes stationary hydrological system, as model parameters are calibrated with and therefore dependant on observed data.","The resulting hydrographs, the resulting peak discharges as well as the reliability and the plausibility of the estimates are evaluated.",Developing hydrodynamic models and using them to build coupled hydrologic hydrodynamic models can potentially improve the plausibility of PMF estimations.,"The discussion of the results shows that coupling hydrologic and hydrodynamic models substantially improves the physical plausibility of PMF modelling, although both modelling approaches lead to PMF estimations for the catchment outlet that fall within a similar range."
10.1016/j.cma.2016.03.046,Gradient based design optimization under uncertainty via stochastic expansion methods (2016),"However, the evaluation of the failure probabilities of the cost and constraint functions and their gradients, requires integrations over failure regions.",Guidelines to assess the computational costs associated with both polynomial chaos approaches are also presented.,,,
10.1007/s00158-015-1322-0,Reliability based optimization in aeroelastic stability problems using polynomial chaos based metamodels (2016),This new modified method is applied on a rectangular unswept cantilever wing model.,Two new modifications are made to this method in this work.,"Second, to increase this computational gain further, a non-uniform grid is chosen instead of a uniform one, based on relative importance of the design parameters.","The optimization process requires repeated evaluation of reliability, which is a major contributor to the total computational cost.",
10.1016/j.jcp.2015.03.071,"A Bayesian framework for adaptive selection, calibration, and validation of coarse-grained models of atomistic systems (2015)","Algorithms for computing output sensitivities to parameter variances, model evidence and posterior model plausibilities for given data, and for computing what are referred to as Occam Categories in reference to a rough measure of model simplicity, make up components of the overall approach.",,,,
10.1016/j.envsoft.2017.05.005,An adaptive surrogate modeling-based sampling strategy for parameter optimization and distribution estimation (ASMO-PODE) (2017),The results demonstrated that the ASMO-PODE method is an economic way for parameter optimization and distribution estimation.,(C)  The Authors.,,,
10.1016/j.jcp.2016.04.013,Stochastic Galerkin methods for the steady-state Navier-Stokes equations (2016),We also propose a preconditioner for solving the linear systems of equations arising at each step of the stochastic (Galerkin) nonlinear iteration and demonstrate its effectiveness for solving a set of benchmark problems.,We study the steady-state Navier-Stokes equations in the context of stochastic finite element discretizations.,,,
10.1016/j.cma.2013.07.007,Dual-primal domain decomposition method for uncertainty quantification (2013),The spectral stochastic finite element method (SSFEM) may offer an efficient alternative to the traditional Monte Carlo simulations (MCS) for uncertainty quantification of large-scale numerical simulations.,"In this paper, we report a probabilistic version of the dual-primal domain decomposition method for the intrusive SSFEM in order to exploit high performance computing platforms for uncertainty quantification.","In particular, we formulate a probabilistic version of the dual-primal finite element tearing and interconnect (FETI-DP) technique to solve the large-scale linear systems in the intrusive SSFEM.","In the framework of the intrusive SSFEM, the main computational challenge involves solving a coupled set of deterministic linear systems.",
10.1007/s00158-010-0588-5,"A Krylov-Arnoldi reduced order modelling framework for efficient, fully coupled, structural-acoustic optimization (2011)","For the fully coupled, vibro-acoustic, unconstrained optimization problem, the design variables take the form of stacking sequences of a composite structure enclosing the acoustic cavity.",The goal of the optimization is to reduce sound pressure levels at the driver's ear location.,"The method could prove as a valuable tool to analyze and optimize complex coupled structural-acoustic systems, where, in addition to fast analysis, a fine frequency resolution is often required.","This new method does not require the solution of traditional eigen value based problems to reduce computational time during optimization, but are instead based on computation of Arnoldi vectors belonging to the induced Krylov Subspaces.","In a unified approach, the validity of the optimization framework is demonstrated on a constrained composite plate/prism cavity coupled system."
10.1016/j.jcp.2010.05.007,Intrusive Galerkin methods with upwinding for uncertain nonlinear hyperbolic systems (2010),A finite volume scheme with a Roe-type solver is used for discretization of the spatial and time variables.,A Galerkin projection is used to derive a system of deterministic equations for the stochastic modes of the solution.,The stochastic spectral method relies on multi-resolution schemes where the stochastic domain is discretized using tensor-product stochastic elements supporting local polynomial bases.,,
10.1007/s00158-008-0329-1,Continuum topology optimization with non-probabilistic reliability constraints based on multi-ellipsoid convex model (2009),The proposed method can be regarded as an attractive supplement to the stochastic reliability-based topology optimization.,The problem is formulated as a double-loop optimization one.,Numerical investigations illustrate the applicability and the validity of the present problem statement as well as the proposed numerical techniques.,The computational results also reveal that non-probabilistic reliability-based topology optimization may yield more reasonable material layouts than conventional deterministic approaches.,"In the present formulation, the uncertain-but bounded uncertain variations of material properties, geometrical dimensions and loading conditions can be realistically accounted for."
10.1016/j.jhydrol.2006.07.012,Multi-period and multi-criteria model conditioning to reduce prediction uncertainty in an application of TOPMODEL within the GLUE framework (2007),The predictions of Monte Carlo realisations of TOP-MODEL parameter sets are evaluated using a number of performance measures calibrated for both global (annual) and seasonal ( day) periods.,The approach is consistent with the equifinality thesis and is developed within the Generalised Likelihood Uncertainty Estimation (GLUE) framework.,"The model shows good performance on a classical efficiency measure at the global level, but no model realizations were found that were behavioural over all multi-period clusters and all performance measures, raising questions about what should be considered as an acceptable model performance.",,
10.1016/j.jcp.2006.01.026,Uncertainty quantification for porous media flows (2006),Predicting flows of oil and water through oil reservoirs is an example of a complex system where accuracy in prediction is needed primarily for financial reasons.,"Uncertainty quantification is an increasingly important aspect of many areas of computational science, where the challenge is to make reliable predictions about the performance of complex physical systems in the absence of complete or reliable data.",This paper examines a Bayesian Framework for uncertainty quantification in porous media flows that uses a stochastic sampling algorithm to generate models that match observed data.,,
10.1007/s00158-008-0260-5,Multidisciplinary design optimization of a small solid propellant launch vehicle using system sensitivity analysis (2009),"Suitable design variables, technological, and functional constraints are considered.",These results are basis for optimization.,,,
10.1016/j.jcp.2015.12.034,Simplex-stochastic collocation method with improved scalability (2016),"In addition, we address the issue of ill-conditioned sample matrices, and we present an analytical map to facilitate uniformly-distributed simplex sampling.","In order to do so, we propose an alternative interpolation stencil technique based upon the Set-Covering problem, and we integrate the SSC method in the High-Dimensional Model-Reduction framework.","However, it becomes prohibitively expensive for problems with dimensions higher than .",,
10.1016/S0045-7825(00)00374-1,Numerical solution of three-dimensional crack problem by using hypersingular integral equation (2001),"Therefore, the hypersingular integral equation for the three-dimensional crack problem can be solved immediately.",The hypersingular integrals can be evaluated numerically by using a known result.,,,
10.1007/s00158-009-0435-8,Multidisciplinary optimization of injection molding systems (2010),normalized sensitivity) highlighting the importance of the feeding subsystem on overall quality.,"This paper presents a framework, based on a Multidisciplinary Design Optimization (MDO) methodology, which tackles the design of an injection mold by integrating the structural, feeding, ejection and heat-exchange sub-systems to achieve significant improvements.",,,
10.1016/j.envsoft.2014.01.004,"A framework for propagation of uncertainty contributed by parameterization, input data, model structure, and calibration/validation data in watershed modeling (2014)","IPEAT is an innovative tool to investigate and explore the significance of uncertainty sources, which enhances watershed modeling by improved characterization and assessment of predictive uncertainty.","Accounting for the major sources of uncertainty associated with watershed modeling produces more realistic predictions, improves the quality of calibrated solutions, and consequently reduces predictive uncertainty.",,,
10.1016/j.jcp.2012.07.041,A semi-intrusive deterministic approach to uncertainty quantification in non-linear fluid flow problems (2013),This reconstruction is then used to formulate a scheme on the numerical approximation of the solution from the deterministic scheme.,This new approach is said semi-intrusive because it requires only a limited amount of modification in a deterministic solver to quantify uncertainty on the state when the solver includes uncertain variables.,One of the tools is a tessellation of the random space as in finite volume methods for the space variables.,"Then, using these conditional expectancies and the geometrical description of the tessellation, a piece-wise polynomial approximation in the random variables is computed using a reconstruction method that is standard for high order finite volume space, except that the measure is no longer the standard Lebesgue measure but the probability measure.","The effectiveness of this method is illustrated for a modified version of Kraichnan-Orszag three-mode problem where a discontinuous pdf is associated to the stochastic variable, and for a nozzle flow with shocks."
10.1016/j.jhydrol.2016.06.037,Data-worth analysis through probabilistic collocation-based Ensemble Kalman Filter (2016),We focus on dynamically evolving plumes of dissolved chemicals migrating in randomly heterogeneous aquifers.,"Integration of the Ensemble Kalman Filter method within a data-worth analysis framework enables us to assess data worth sequentially, which is a key desirable feature for monitoring scheme design in a contaminant transport scenario.",We propose a new and computationally efficient data-worth analysis and quantification framework keyed to the characterization of target state variables in groundwater systems.,Our results demonstrate the computational efficiency of our approach and its ability to quantify the impact of the design of the monitoring network on the reduction of uncertainty associated with the characterization of a migrating contaminant plume.,() so that we take advantage of the ability to assimilate data sequentially in time through a surrogate model constructed via the polynomial chaos expansion.
10.1007/s00158-017-1702-8,Parametric shape optimization techniques based on Meshless methods: A review (2017),"At the end, promising future research directions in shape optimization field based on MMs are presented along with concluding remarks.","Based on the review, the article presents some critical observations including Design Sensitivity Analysis (DSA) in meshless environment, numerical integration techniques in MMs and benefits of coupled FEM-MM approach in shape optimization.","In last two decades, MMs have been explored for structural shape optimization along with various deterministic and stochastic optimization algorithms.","However, structural performance greatly depends on its geometric shape and hence structural shape optimization has remained one of the most active research areas since early s. Conventional parametric shape optimization technique employs grid-based numerical tools like FEM and BEM for structural analysis, which experiences some innate limitations like mesh distortion and frequent remeshing, element locking and poor approximation while dealing with large shape changes during the optimization process.",
10.1007/s00158-010-0496-8,Physics-based modeling and simulation of human walking: a review of optimization-based and other approaches (2010),"Features of various methods are discussed, and their advantages and disadvantages are delineated.",This review focuses on physics-based human walking simulations in the robotics and biomechanics literature.,A review of human walking modeling and simulation is presented.,,
10.1016/j.cma.2004.05.033,The continuum sensitivity method for the computational design of three-dimensional deformation processes (2006),The present D developments include a novel regularized approach to the contact sensitivity problem that addresses the non-differentiability of the contact constraints.,A typical design problem at each optimization iteration involves simultaneous solution of a direct problem and a number of sensitivity problems corresponding to each of the design variables.,"In this work, the continuum sensitivity method (CSM) is extended to three-dimensions (D) to accurately compute sensitivity fields and in particular changes in the design objectives as a result of infinitesimal perturbations to the design parameters.",The computed sensitivity fields are used in a gradient-based optimization framework for process design (optimization) in D metal forming applications.,
10.1016/j.jhydrol.2016.11.051,Calibration of an agricultural-hydrological model (RZWQM2) using surrogate global optimization (2017),"Therefore, only a limited number of simulations can be allowed in any attempt to find a near-optimal solution within an affordable time, which greatly restricts the successful application of the model.","However, calibration of the agricultural-hydrological system models is challenging because of model complexity, the existence of strong parameter correlation, and significant computational requirements.","Results indicate that an accurate surrogate model can be created for the RZWQM with a relatively small number of SG points (i.e., RZWQM runs).","To this end, we propose a computationally efficient global optimization procedure using sparse-grid based surrogates.",
10.1016/j.cma.2008.01.005,Stochastic modeling of coupled electromechanical interaction for uncertainty quantification in electrostatically actuated MEMS (2008),"The stochastic analysis is based on a stochastic Lagrangian approach, where, in addition to uncertain input parameters and unknown field variables, the random deformed configuration is expanded in terms of GPC basis functions.","This work proposes a stochastic framework based on generalized polynomial chaos (GPC), to handle uncertain coupled electromechanical interaction, arising from variations in material properties and geometrical parameters such as gap between the microstructures, applicable to the static analysis of electrostatic MEMS.","The proposed framework comprises of two components - a stochastic mechanical analysis, which quantifies the uncertainty associated with the deformation of MEM structures due to the variations in material properties and/or applied traction, and a stochastic electrostatic analysis to quantify the uncertainty in the electrostatic pressure due to variations in geometrical parameters or uncertain deformation of the conductors.",The spectral modes for the unknown field variables are finally obtained using Galerkin projection in the space spanned by GPC basis functions.,The results obtained using the proposed method are verified using rigorous Monte Carlo simulations.
10.1016/j.envsoft.2013.01.004,A model-independent Particle Swarm Optimisation software for model calibration (2013),"This work presents and illustrates the application of hydroPSO, a novel multi-OS and model-independent R package used for model calibration.",hydroPSO implements several state-of-the-art enhancements and fine-tuning options to the Particle Swarm Optimisation (PSO) algorithm to meet specific user needs.,"Although we limit the application of hydroPSO to hydrological models, flexibility of the package suggests it can be implemented in a wider range of models requiring some form of parameter optimisation.","We further illustrate the application of hydroPSO in two real-world case studies: we calibrate, first, a hydrological model for the Ega River Basin (Spain) and, second, a groundwater flow model for the Pampa del Tamarugal Aquifer (Chile).",
10.1016/j.cma.2013.07.011,Virtual model validation of complex multiscale systems: Applications to nonlinear elastostatics (2013),We assert that microscale information drawn from molecular models of the fabrication of the body provides a valuable source of prior information on parameters as well as a means for estimating model bias and designing virtual validation experiments to provide information gain over calibration posteriors.,One example is given by models of elastomeric solids fabricated using polymerization processes.,,,
10.1016/j.jhydrol.2012.05.053,A toy model for monthly river flow forecasting (2012),"The toy model is based on water balance, easy to use and reproduce, and robust to calibrate with a short period of data.","River flow forecasting depends on land-atmosphere coupled processes, and is relevant to hydrological applications and land-ocean coupling.",A toy model is developed here for monthly river flow forecasting using the river flow and river basin averaged precipitation in prior month.,Model coefficients are calibrated for each month using historical data.,"Its prediction uncertainty can be quantified using the model's error statistics or using a dynamic approach, but not by the dispersion of , ensemble members with different sets of coefficients in the model."
10.1016/j.jcp.2010.03.005,A method for stochastic constrained optimization using derivative-free surrogate pattern search and collocation (2010),Our method extends the previously developed surrogate management framework (SMF) to allow for uncertainties in both simulation parameters and design variables.,This approach is tested on four numerical optimization problems and is shown to have significant improvement in efficiency over traditional Monte-Carlo schemes.,A large computational overhead is associated with computing the cost function for most practical problems involving complex physical phenomena.,Such problems are also plagued with uncertainties in a diverse set of parameters.,
10.1016/j.jhydrol.2014.07.056,Assessment of SMOS soil moisture retrieval parameters using tau-omega algorithms for soil moisture deficit estimation (2014),Soil Moisture and Ocean Salinity (SMOS) is the latest mission which provides flow of coarse resolution soil moisture data for land applications.,"However, the efficient retrieval of soil moisture for hydrological applications depends on optimally choosing the soil and vegetation parameters.","In tau-omega, the soil moisture is retrieved using the Horizontal (H) polarisation following Hallikainen dielectric model, roughness parameters, Fresnel's equation and estimated Vegetation Optical Depth (tau).",The performance obtained after all those changes indicate that SCA-H using WRF-NOAH LSM downscaled ECMWF LST produces an improved performance for SMD estimation at a catchment scale.,
10.1007/s00158-013-0912-y,Level-set methods for structural topology optimization: a review (2013),This review paper provides an overview of different level-set methods for structural topology optimization.,"Level-set methods can be categorized with respect to the level-set-function parameterization, the geometry mapping, the physical/mechanical model, the information and the procedure to update the design and the applied regularization.",The importance of numerical consistency for understanding and studying the behavior of proposed methods is highlighted.,This review concludes with recommendations for future research.,
10.1016/j.cma.2015.03.006,Ensemble Kalman Filters and geometric characterization of sensitivity spaces for uncertainty quantification in optimization (2015),These ingredients are illustrated on an history matching problem.,One goes beyond DES with Ensemble Kalman Filters (EnKF) after the multi-point optimization algorithm is cast into an ensemble simulation environment.,This formulation accounts for the variability in large dimension.,A final interest of the approach is that it provides an indication of the size of the ensemble which must be considered in the EnKF.,The approach is merely geometric.
10.1016/j.jcp.2012.07.030,Uncertainty quantification in kinematic-wave models (2012),"In contrast to PDF equations, which are often used in other contexts, CDF equations allow for straightforward and unambiguous determination of boundary conditions with respect to sample variables.",,,,
10.1016/j.jcp.2016.04.062,Stabilized FE simulation of prototype thermal-hydraulics problems with integrated adjoint-based capabilities (2016),"A critical aspect of applying modern computational solution methods to complex multi-physics systems of relevance to nuclear reactor modeling, is the assessment of the predictive capability of specific proposed mathematical models.","In this respect the understanding of numerical error, the sensitivity of the solution to parameters associated with input data, boundary condition uncertainty, and mathematical models is critical.",Initial results are presented that show the promise of these computational techniques in the context of nuclear reactor relevant prototype thermal-hydraulics problems.,,
10.1016/j.jcp.2014.12.006,Pi 4U: A high performance computing framework for Bayesian uncertainty quantification of complex models (2015),The optimization tasks associated with the asymptotic approximations are treated via the Covariance Matrix Adaptation Evolution Strategy (CMA-ES).,The framework accommodates scheduling of multiple physical model evaluations based on an adaptive load balancing library and shows excellent scalability.,"In addition to the software framework, we also provide guidelines as to the applicability and efficiency of Bayesian tools when applied to computationally demanding physical models.",,
10.1016/j.jhydrol.2014.09.052,A qualitative model structure sensitivity analysis method to support model selection (2014),"Traditionally, model sensitivity is evaluated for model parameters.","By comparing the effect of changes in model structure for different model objectives, model selection can be better evaluated.","Similarly to the one-factor-at-a-time (OAT) methods for parameter sensitivity, this method varies the model structure components one at a time and evaluates the change in sensitivity towards the output variables.","the modeling objective, the characteristics and the scale of the system under investigation and the available data.","Flexible environments for model building are available, but need to be assisted by proper diagnostic tools for model structure selection."
10.1016/j.cma.2015.02.012,Stress constrained topology optimization with free-form design domains (2015),"Second, the implementation of the finite cell method (FCM) ensures the stress computing accuracy in the fixed mesh due to the use of high-order shape functions and adaptive integration scheme.","Compared with the existing level set based method, the important sensitivity property of design domain preserving makes it possible to avoid automatically the boundary violation of the design domain caused by the zero level set movement and both the topology and boundary shape of the free-form design domain can be simultaneously optimized.","Finally, representative examples are presented to illustrate the conveniences and effectiveness of the proposed method.",Such an operation is mathematically realized by means of the so-called R-functions in the form of implicit LSFs.,This paper aims at dealing with realistic and challenging design problems of stress constrained topology optimization with freeform design domains.
10.1016/j.jcp.2007.04.030,A stochastic particle-mesh scheme for uncertainty propagation in vortical flows (2007),"Thus, the method combines the advantages of particles discretizations with the efficiency of PC representations.","It is also shown that it is possible to apply solution algorithms used in deterministic setting, including particle-mesh techniques and particle remeshing.",,,
10.1007/s00158-009-0402-4,Structural design sensitivity using boundary elements and polynomial response function (2010),The essential difference with respect to the previous approaches like the Direct Differentiation Method or the Adjoint Variable Method is in discrete evaluation of the structural response using the response polynomials of some state parameters and design variable as the independent parameter.,This main issue of this paper is a conjunction of the structural design sensitivity analysis using the Boundary Element Method with the polynomial response function determination.,"Such a determination is carried out via the several solutions of the given boundary value problem, where design parameter mean value is regularly perturbed in each of the solutions to cover the closest neighborhood of this mean value.","Those few solutions make it possible to recover the polynomial response function from node-to node within the boundary elements, so that further symbolic differentiation using MAPLE returns the sensitivity gradients particular values.",
10.1007/s00158-007-0200-9,Aero-structural optimization using adjoint coupled post-optimality sensitivities (2008),The resulting coupled post-optimality sensitivity approach is used to guide a gradient-based optimization algorithm.,"The new approach simplifies the system-level problem, thereby reducing the number of calls to a potentially costly aerodynamics solver.",A new subspace optimization method for performing aero-structural design is introduced.,The method relies on a semi-analytic adjoint approach to the sensitivity analysis that includes post-optimality sensitivity information from the structural optimization subproblem.,
10.1007/s00158-017-1699-z,Variance-based sensitivity analysis for models with correlated inputs and its state dependent parameter solution (2017),"Based on the characteristics of these general expressions, a universal framework for estimating the various variance contributions of the correlated inputs is developed by taking the efficient state dependent parameter (SDP) method as an illustration.","To explore the contributions of correlated inputs to the uncertainty in a model output, the universal expressions of the variance contributions of the correlated inputs are first derived in the paper based on the high dimensional model representation (HDMR) of the model function.","Then by analyzing the composition of these variance contributions, the variance contributions by an individual correlated input to the model output are further decomposed into independent contribution by the individual input itself, independent contribution by interaction between the individual input and the others, contribution purely by correlation between the individual input and the others, and contribution by interaction associated with correlation between the individual input and the others.",The general expressions of these components are also derived.,The efficiency and accuracy of the SDP-based method for estimating the various variance contributions of the correlated inputs are also demonstrated by the examples.
10.1007/s001580050183,Shape sensitivity analysis using a fixed basis function finite element approach (2001),"The evaluation of sensitivity matrices and force vectors requires only modest calculations beyond those of the reference problem finite element analysis; that is, certain boundary integrals and reaction forces on the reference location of the moving boundary are required.",An approach is presented for the determination of solution sensitivity to changes in problem domain or shape.,"A finite element displacement formulation is adopted and title point of view is taken that the finite element basis functions and grid are fixed during the sensitivity analysis; therefore, the method is referred to as a ""fixed basis function"" finite clement shape sensitivity analysis.",This approach avoids the requirement of explicit or approximate differentiation of finite clement matrices and vectors and the difficulty or errors resulting from such calculations.,
10.1016/j.cma.2015.06.019,An efficient design sensitivity analysis using element energies for topology optimization of a frequency response problem (2015),"NASTRAN, ANSYS, and ABAQUS), a substantial understanding of the codes and additional post-processing work is required.","However, to obtain internal information on the general commercial FEA codes (e.g., MSC.","In this paper, to overcome these difficulties, element energy-based DSA of a frequency response is developed using the polarization identity.","In this study, an efficient design sensitivity analysis (DSA) method is proposed for topology optimization of a frequency response problem.","DSA of frequency response is an essential procedure for gradient-based topology optimization, which is used for noise and vibration control of structures."
10.1016/j.jhydrol.2006.05.010,Towards a Bayesian total error analysis of conceptual rainfall-runoff models: Characterising model error using storm-dependent parameters (2006),Acceptance that CRR models are intrinsically stochastic paves the way for a more rational characterisation of model error.,The characterisation of model error in CRR modelling has been thwarted by the convenient but indefensible treatment of CRR models as deterministic descriptions of catchment dynamics.,"It provides a very general framework for calibration and prediction, as well as for testing hypotheses regarding model structure and data uncertainty.","A Bayesian hierarchical model is then formulated to explicitly differentiate between forcing, response and model error.",Allowing storm-dependent variation in just two model parameters (with one of the parameters characterising model error and the other reflecting input uncertainty) yields a substantially improved model fit raising the Nash-Sutcliffe statistic from .
10.1016/j.jhydrol.2007.05.023,Estimation of soil boundary-layer resistance in sparse semiarid stands for evapotranspiration modelling (2007),"Furthermore it allows qualitative interpretation of the effect of non-transpirable vegetative elements, as well as the architecture of the vegetation and its distribution in the field, neither of,which are considered in the turbulent diffusion theory.","The aim of this work was first, to compare two methods for obtaining soil boundary-layer resistance, one based on the turbulent diffusion theory (TD) and another based on the energy balance of heated and unheated sensors (EB), and secondly, to analyse how the results obtained from both methods are affected by canopy structure parameters in typical sparse vegetation.","In contrast, for the TD method, quantitative attributes of the vegetation (average vegetation height, h, leaf area index, L, fractional.","The study was carried out in stands of three different species characteristic of the semiarid South East of Spain (Retama sphaerocarpa, Anthyllis cytisoides and Stipa tenacissima).",The advantages of using the EB method are both practical and theoretical.
10.1016/j.envsoft.2014.06.002,A computer program for uncertainty analysis integrating regression and Bayesian methods (2014),"Ready access allows users to select methods best suited to their work, and to compare methods in many circumstances.",The MCMC capability in UCODE_ is based on the FORTRAN version of the differential evolution adaptive Metropolis (DREAM) algorithm of Vrugt et al.,"(), which estimates the posterior probability density function of model parameters in high-dimensional and multimodal sampling problems.","This paper tests and demonstrates the MCMC capability using a -dimensional multimodal mathematical function, a -dimensional Gaussian function, and a groundwater reactive transport model.",This work develops a new functionality in UCODE_ to evaluate Bayesian credible intervals using the Markov Chain Monte Carlo (MCMC) method.
10.1016/j.cma.2006.10.048,Fast methods for determining the evolution of uncertain parameters in reaction-diffusion equations (2007),This derivative information is used in turn to produce an error estimate for the information computed from the sample points.,It employs random sampling of the input space in order to produce a pointwise representation of the output.,"Unfortunately, it generally requires sampling the operator very many times at a significant cost, especially when the model is expensive to evaluate.","In this paper, we present an alternative approach for ascertaining the effects of variations and uncertainty in parameters in a reaction diffusion equation on the solution.","After describing the new methodology in detail, we apply the new method to analyze the parameter sensitivity of a predator-prey model with a Holling II functional response that has six parameters."
10.1007/s00158-014-1161-4,Integrated topology and controller optimization of motion systems in the frequency domain (2015),In this article a framework is presented which allows the simultaneous and integrated design of a structure and controller.,The structure is designed using topology optimization and the objectives and constraints are related to the closed-loop control performance and defined in the frequency domain.,"For simple examples it is shown that this approach leads to at least as good performance as a sequential approach consisting of eigenfrequency optimization followed by controller tuning, and leads to lighter designs.",,
10.1016/j.jhydrol.2016.06.030,An optimization based sampling approach for multiple metrics uncertainty analysis using generalized likelihood uncertainty estimation (2016),"The effectiveness of epsilon-NSGAII based sampling is demonstrated compared with Latin hypercube sampling (LHS) through analyzing sampling efficiency, multiple metrics performance, parameter uncertainty and flood forecasting uncertainty with a case study of flood forecasting uncertainty evaluation based on Xinanjiang model (XAJ) for Qing River reservoir, China.",This paper investigates the use of an epsilon-dominance non-dominated sorted genetic algorithm II (epsilon-NSGAII) as a sampling approach with an aim to improving sampling efficiency for multiple metrics uncertainty analysis using Generalized Likelihood Uncertainty Estimation (GLUE).,The flood forecasting uncertainty is also reduced a lot with epsilon-NSGAII based sampling.,,
10.1016/j.envost.2007.01.002,An appropriateness framework for the Dutch Meuse decision support system (2007),"One important component of this decision support system, flood safety, is used in this paper to demonstrate how this approach works.",The approach is applied to a decision support system for the Dutch Meuse River.,Models are essential in a decision support system for river basin management.,Potential applications of the approach in other decision support systems are discussed.,The approach presented in this paper is designed as a tool to stimulate the communication between decision makers and modelers and to promote the use of models in decision-making for river basin management.
10.1016/j.jcp.2014.12.034,A Bayesian mixed shrinkage prior procedure for spatial-stochastic basis selection and evaluation of gPC expansions: Applications to elliptic SPDEs (2015),"The method offers a number of advantages over existing compressive sensing methods in gPC literature, such that it recovers possible sparse structures in both stochastic and spatial domains while the resulting expansion can be re-used directly to economically obtain results at any spatial input values.","We propose a new fully Bayesian method to efficiently obtain the spectral representation of a spatial random field, which can conduct spatial-stochastic basis selection and evaluation of generalized Polynomial Chaos (gPC) expansions when the number of the available basis functions is significantly larger than the size of the training data-set.","MSP involves assigning a prior probability to the gPC structure and assigning conjugate priors to the expansion coefficients that can be thought of as mixtures of Ridge-LASSO shrinkage priors, in augmented form.","We demonstrate the good performance of the proposed method, and compare it against other existing compressive sensing ones on elliptic stochastic partial differential equations.",A unique highlight of the MSP procedure is that it can address heterogeneous sparsity in the spatial domain for different random dimensions.
10.1016/j.jhydrol.2016.12.008,Assessing the weighted multi-objective adaptive surrogate model optimization to derive large-scale reservoir operating rules with sensitivity analysis (2017),billion kW h) and ecological index (.)),The optimization of large-scale reservoir system is time-consuming due to its intrinsic characteristics of non-commensurable objectives and high dimensionality.,with  simulations and computational time reduced by % (from  h to  h) with  simulations.,"billion kWh), and the median of ecological index, optimized by .% (from .","Therefore, the proposed method is proved to be more efficient and could provide better Pareto frontier."
10.1016/j.jcp.2006.06.029,An extended level set method for shape and topology optimization (2007),"Numerical examples show its accuracy, convergence speed and insensitivity to initial designs in shape and topology optimization of two-dimensional (D) problems that have been extensively investigated in the literature.",The normal velocities are chosen to perform steepest gradient-based optimization by using shape sensitivity analysis and a bi-sectioning algorithm.,The RBF multiquadric splines are used to construct the implicit level set function with a high level of accuracy and smoothness and to discretize the original initial value problem into an interpolation problem.,,
10.1016/j.jcp.2013.12.024,Low-rank separated representation surrogates of high-dimensional stochastic functions: Application in Bayesian inference (2014),"The computational cost of the model construction is quadratic in the number of random inputs, which potentially tackles the curse of dimensionality in high-dimensional stochastic functions.",The required number of random realizations to achieve a successful approximation linearly depends on the function dimensionality.,"This study introduces a non-intrusive approach in the context of low-rank separated representation to construct a surrogate of high-dimensional stochastic functions, e.g., PDEs/ODEs, in order to decrease the computational cost of Markov Chain Monte Carlo simulations in Bayesian inference.",,
10.1016/j.jcp.2012.04.047,Multi-output local Gaussian process regression: Applications to uncertainty quantification (2012),The tree is adaptively constructed using information conveyed by the observed data about the length scales of the underlying process.,"We develop an efficient, Bayesian Uncertainty Quantification framework using a novel treed Gaussian process model.","The constructed surrogate can provide analytical point estimates, as well as error bars, for the statistics of interest.",,
10.1016/j.envsoft.2013.07.009,Global sensitivity analysis in wastewater applications: A comprehensive comparison of different methods (2013),"In particular, the Standardised Regression Coefficients, Morris Screening and Extended-FAST methods are applied to a complex integrated membrane bioreactor (MBR) model considering  model outputs and  model factors.",Three global sensitivity analysis (GSA) methods are applied and compared to assess the most relevant processes occurring in wastewater treatment systems.,The main objective considered is to classify important factors (factors prioritisation) as well as non-influential factors (factors fixing).,"This means that to obtain reliable variance decomposition and to detect and quantify interactions among the factors, the use of the Extended-FAST is recommended.",Regarding the comparison between Morris screening and Extended-FAST a poor agreement was found.
10.1007/s00158-016-1607-y,Robust topology optimization for dynamic compliance minimization under uncertain harmonic excitations with inhomogeneous eigenvalue analysis (2016),Numerical examples are presented to illustrate the effectiveness and efficiency of the proposed framework.,This paper investigates robust topology optimization of structures subjected to uncertain dynamic excitations.,This formulation ensures that the strictsense worst-case combination of the uncertain excitations for each intermediate design be located without resorting to a time-consuming global search algorithm.,"To tackle the inherent difficulties associated with such an originally nested formulation, we convert the inner-loop into an inhomogeneous eigenvalue problem using the optimality condition.",
10.1016/j.jhydrol.2016.01.058,Evaluating two sparse grid surrogates and two adaptation criteria for groundwater Bayesian uncertainty quantification (2016),"While our numerical study suggests building state-variable surrogates and using the relative error indicator for building log-likelihood surrogates, selecting appropriate type of surrogates and error indicators depends on the shapes of response surfaces.",The shapes should be approximated and examined before building sparse grid surrogates.,"Using a synthetic groundwater flow model, this study evaluates the log-likelihood and head surrogates in terms of the computational cost of building them, the accuracy of the surrogates, and the accuracy of the distributions of model parameters and predictions obtained using the surrogates.","For both log-likelihood and head surrogates, adaptive sparse grids are built using two indicators: absolute error and relative error.","The head surrogates outperform the log-likelihood surrogates for the following four reasons: () the shape of the head response surface is smoother than that of the log-likelihood response surface in parameter space, () the head variation is smaller than the log-likelihood variation in parameter space, () the interpolation error of the head surrogates does not accumulate to be larger than the interpolation error of the log-likelihood surrogates, and () the model simulations needed for building one head surrogate can be recycled for building others."
10.1007/s00158-015-1376-z,Structural topology optimization with design-dependent pressure loads (2016),Four numerical examples are presented to show the validity and advantages of the proposed scheme.,A new optimization framework is also proposed to avoid the load sensitivity analysis.,"During the topology evolution, the intermediate topologies obtained by using the SIMP (Solid Isotropic Material with Penalization) method actually can be regarded as gray scale images, for which the paper proposes a new material boundary identification scheme based on image segmentation technique.",,
10.1016/j.envsoft.2017.01.006,"Flood inundation modelling: A review of methods, recent advances and uncertainty analysis (2017)","It explores their advantages and limitations, highlights the most recent advances and discusses future directions.","This paper reviews state-of-the-art empirical, hydrodynamic and simple conceptual models for determining flood inundation.",It addresses how uncertainty is analysed in this field with the various approaches and identifies opportunities for handling it better.,,
10.1007/s00158-010-0616-5,Shape optimization for 2-D mixed-mode fracture using Extended FEM (XFEM) and Level Set Method (LSM) (2011),"Two different approaches-a batch-mode, gradient-based, nonlinear algorithm and an interactive what-if analysis-are used for optimization.","As a result, this method does not require highly refined mesh around the crack tip nor re-mesh to conform to the geometric shape of the crack when it propagates, which makes the method extremely attractive for crack propagation analysis.",An engine connecting rod example is used to demonstrate the feasibility of the proposed method.,"Fracture parameters, such as crack growth rate and crack growth direction are computed using extended finite element method (XFEM) and level set method (LSM).","This research incorporates a novel crack propagation analysis technique into shape optimization framework to support design of -D structural components under mixed-mode fracture for: () maximum service life, subject to an upper limit on volume, and () minimum weight subject to specified minimum service life."
10.1016/j.jcp.2016.12.041,Geometric MCMC for infinite-dimensional inverse problems (2017),"In this work, we combine geometric methods on a finite-dimensional subspace with mesh-independent infinite-dimensional approaches.",(C)  The Authors.,"However, few of them take into account the geometry of the posterior informed by the data.","Recently, a new class of MCMC methods with mesh-independent convergence times has emerged.","Traditional Markov chain Monte Carlo (MCMC) algorithms are characterized by deteriorating mixing times upon mesh-refinement, when the finite dimensional approximations become more accurate."
10.1007/s00158-016-1601-4,Interval prediction of responses for uncertain multidisciplinary system (2017),"Considering that numerous sample data points are required in the probabilistic method, a non-probabilistic interval analysis method can be an alternative when the information is insufficient.",Both IA-IUAMs are able to evaluate the bounds of responses accurately and quickly.,The validity and efficiency of the new methods are demonstrated by two numerical examples and two engineering examples.,The presented methods are compared with general sensitivity analysis based interval uncertainty analysis method (SIUAM) and conventional Monte Carlo simulation approach (MCS).,"In the paper, new strategies, which are iterative algorithm based interval uncertainty analysis methods (IA-IUAMs), are developed to acquire the bounds of the responses in multidisciplinary system."
10.1007/s00158-016-1475-5,Structural optimization using global stress-deviation objective function via the level-set method (2017),The optimization procedure is based on the domain boundary evolution via the level-set method.,The Hamilton-Jacobi equation is solved using the streamline diffusion finite element method.,"The results of the structural optimization problem, in terms of maximum von Mises stress corresponding to the obtained optimal shapes, are compared for the commonly used global stress measure and the novel global stress-deviation measure, used as the stress-related objective functions.",The paper deals with minimum stress design using a novel stress-related objective function based on the global stress-deviation measure.,The use of finite element based methods allows a unified numerical approach with only one numerical framework for the mechanical problem as also for the boundary evolution stage.
10.1016/j.envsoft.2015.09.006,Setting up a hydrological model of Alberta: Data discrimination analyses prior to calibration (2015),The model was used to quantify the causes and extents of biases in predictions due to different types of input data.,"To build a model with accurate accounting of hydrological processes, a data discrimination procedure was applied in this study.",,,
10.1016/S0045-7825(03)00379-7,A response surface approach for the static analysis of stochastic structures with geometrical nonlinearities (2003),A response surface approach for the finite element analysis of uncertain structures undergoing large displacements is presented.,,,,
10.1016/j.envsoft.2014.11.010,Addressing the ability of a land biosphere model to predict key biophysical vegetation characterisation parameters with Global Sensitivity Analysis (2015),"The sensitivity of the following model outputs was evaluated: the ambient CO concentration, the rate of CO uptake by the plant, the ambient O- concentration, the flux of O- from the air to the plant/soil boundary and the flux of O- taken up by the plant alone.",The influence of the external CO on the leaf and O- concentration in the air as input parameters was also significant.,,,
10.1016/j.envsoft.2014.11.006,Model bias and complexity - Understanding the effects of structural deficits and input errors on runoff predictions (2015),Oversimplified models and erroneous inputs play a significant role in impairing environmental predictions.,We test the approach in an urban catchment with five drainage models.,Our method consists of formulating alternative models with increasing detail and flexibility and describing their systematic deviations by an autoregressive bias process.,Our results show that a single bias description produces reliable predictions for all models.,To assess the contribution of these errors to model uncertainties is still challenging.
10.1016/j.envsoft.2005.12.019,Evaluation of uncertainty propagation into river water quality predictions to guide future monitoring campaigns (2007),A global sensitivity analysis shows the importance of the different uncertainty sources.,"The practical case study is the river Dender in Flanders, Belgium.",The aim of the research reported in this paper is to guide these measurement campaigns based on an uncertainty analysis.,"Because of the complexity of process based river water quality models, it is best to investigate this problem according to the origin of the uncertainty.","However, the uncertainty on the model predictions is sometimes too high to draw proper conclusions."
10.1016/j.envsoft.2013.07.010,A sensitivity analysis of the SimSphere SVAT model in the context of EO-based operational products development (2013),This study performs a Global Sensitivity Analysis (GSA) on the SimSphere land surface model aiming to further extend our understanding of the model structure and establish its coherence.,"In general, our results provided further evidence supporting the model coherence and correspondence to the behaviour of a natural system.","Yet, in absolute terms, the statistical parameters measuring the sensitivity of the model inputs were notably different.",It builds on previous works conducted on the model to which a sophisticated and cutting edge GSA meta-modelling method adopting Bayesian theory is implemented.,"The implications of the main findings are discussed in the framework of the model use either as a stand-alone tool or synergistically with EO data, particularly so towards the operational development of such products."
10.1016/S0045-7825(99)00353-9,Shape sensitivity analysis for energy release rate evaluation and its application to the study of three-dimensional cracked bodies (2000),The energy release rate is an important parameter for the analysis of cracked bodies in linear elastic fracture mechanics.,"This parameter, usually denoted by G, is equivalent to Pi, the rate of change with respect to crack change of the energy available for fracture.","In this paper, crack growth is simulated by an action of change of the shape of the body characterized by an appropriate known smooth velocity field v defined over the domain of the body.",A general (integral) expression for Pi using shape sensitivity analysis based on distributed parameters is also obtained in this paper.,An adaptive finite element analysis is performed in order to ensure a good accuracy during the numerical evaluation of Pi.
10.1016/j.cma.2008.03.012,Rapid inverse parameter estimation using reduced-basis approximation with asymptotic error estimation (2008),A genetic algorithm (GA) is then used in the inverse search procedure for parameter estimation.,The genetic algorithm is used to search these parameters of the crack inside cantilever beam that minimize the objective function.,It is found that the estimated results are very accurate and reliable due to the use of REM forward model with an effective and robust error estimation and detailed sensitivity analysis.,A reduced-basis model is first developed with asymptotic error estimation and is used for fast computation of solving forward mechanics problems of solids and structures.,This paper presents a rapid and reliable approach to solve inverse problems of parameter estimation for structural systems using reduced-basis method (RBM).
10.1007/s00158-008-0239-2,Reliability-based robust design optimization using the eigenvector dimension reduction (EDR) method (2009),"In general, the EDR requires N +  or N +  simulation runs where N is the total number of random variables.","First, an approximate response surface facilitates sensitivity calculation of reliability and quality where the response surface is constructed using the eigenvector samples.",The use of the EDR method provides three benefits to RBRDO.,This paper presents an effective methodology for reliability-based robust design optimization (RBRDO).,
10.1016/j.envsoft.2015.10.005,"How agent heterogeneity, model structure and input data determine the performance of an empirical ABM - A real-world case study on residential mobility (2016)","While partly answered using simple and abstract models, the question of the role of different aspects of model detail for controlling model outcomes still has not been explored with empirical ABMs.","Our diverse results indicate that a good data basis is crucial, heterogeneity strongly controls small-scale patterns and different design aspects must be tested thoroughly.","Evaluation is done by measuring the ability to predict empirical patterns for different topics, population, relocations and vacancies at different scales.",,
10.1007/s00158-013-1043-1,Principal angles between subspaces and reduced order modelling accuracy in optimization (2014),The application of these concepts is illustrated in the design of the shape of an aircraft robust over a range of transverse winds.,The question of interest is the impact of such approximations on the search subspace in the multi-point optimization problem.,,,
10.1007/s00158-007-0133-3,Design sensitivity and reliability-based structural optimization by univariate decomposition (2008),This paper presents a new univariate decomposition method for design sensitivity analysis and reliability-based design optimization of mechanical systems subject to uncertain performance functions in constraints.,The evaluation of these one-dimensional integrations requires calculating only conditional responses at selected deterministic input determined by sample points and Gauss-Hermite integration points.,"Numerical results indicate that the proposed method provides accurate and computationally efficient estimates of the sensitivity of failure probability, which leads to accurate design optimization of uncertain mechanical systems.","The method involves a novel univariate approximation of a general multivariate function in the rotated Gaussian space for reliability analysis, analytical sensitivity of failure probability with respect to design variables, and standard gradient-based optimization algorithms.",
10.1007/s00158-013-0982-x,Numerical instabilities in level set topology optimization with the extended finite element method (2014),"In this paper, a generalized Heaviside enrichment strategy is presented that adapts the set of enrichment functions to the material layout and consistently interpolates the state variable fields, bypassing the limitations of the traditional approach.",The traditional XFEM approach augments the approximation of the state variable fields with a fixed set of enrichment functions.,"These defects can lead to numerical instabilities in the optimized material layout, similar to checker-board patterns found in density methods.","The numerical results suggest that the generalized formulation of the XFEM resolves numerical instabilities, but regularization techniques are still required to control the optimized geometry.",
10.1007/s00158-017-1722-4,Unified uncertainty representation and quantification based on insufficient input data (2017),The Kriging metamodel and random sampling method are used to reduce the computational complexity.,The interval variables are represented with evidence theory.,Maximum likelihood function and Akaike information criterion (AIC) methods are used to identify the best-fitted distribution types and distribution parameters of sparse variables.,"A new uncertain identification and quantification methodology is proposed considering the strong statistical variables, sparse variables, and interval variables simultaneously.","Finally, a unified uncertainty quantification framework considering the three types of uncertain design variables is put forward, and then the failure probability of system performance is quantified with belief and plausibility measures."
10.1016/j.envsoft.2011.03.003,"Probabilistic uncertainty specification: Overview, elaboration techniques and their application to a mechanistic model of carbon flux (2012)","In particular, we introduce the generic technique of elaboration and present a variety of forms of elaboration, illustrated with a series of examples.",There is therefore a growing interest in quantifying the uncertainties in model predictions.,It is widely recognised that the appropriate representation for expert judgements of uncertainty is as a probability distribution for the unknown quantity of interest.,"We provide an overview of this field, including an outline of the process of eliciting knowledge from experts in probabilistic form.","They are used to predict, understand and control those processes, and increasingly play a role in national and international policy making."
10.1016/j.cma.2014.08.011,Dynamic topology optimization of piezoelectric structures with active control for reducing transient response (2014),"In the mathematical formulation of the considered topology optimization model, the time integral of the displacement response over a specified time interval of interest is taken as the objective function.","The proposed method can be used for providing useful guidance to the layout design of the actuator/sensor layers attached to a thin-shell structure subject to dynamic excitations, in particular impact forces.","Also, the influences of the control gain and the integration time intervals in the objective function on the optimal solutions are discussed.","The adjoint-variable sensitivity analysis scheme for a general integral function within a given time interval is derived, which facilitates a gradient-based mathematical programming solution of the optimization problem.",The constant gain velocity feedback (CGVF) control algorithm is considered and the structural dynamic response under the corresponding active damping effect is evaluated with a direct time integration method.
10.1016/j.cma.2013.02.012,Boosting iterative stochastic ensemble method for nonlinear calibration of subsurface flow models (2013),ISEM employs directional derivatives within a Gauss-Newton iteration for efficient gradient estimation.,The proposed algorithm combining ISEM and l() Boosting is evaluated on several nonlinear subsurface flow parameter estimation problems.,This regularization method is very attractive in terms of performance and simplicity of implementation.,The resulting update equation relies on the inverse of the output covariance matrix which is rank deficient.,A novel parameter estimation algorithm is proposed.
10.1016/S0022-1694(01)00476-0,On the parametric and NEXRAD-radar sensitivities of a distributed hydrologic model suitable for operational use (2001),The availability of such spatially distributed data brings into focus the question of the utility of hydrologic models with spatially distributed parameters and input in an operational environment.,This framework allows the incorporation of parametric and radar-rainfall uncertainties in the analysis and illustrates their effects on the results of the sensitivity.,The present study discusses a methodology for addressing this issue based on a sensitivity analysis of event streamflow to parameter and radar input within a Monte Carlo framework for the Illinois River basin in Oklahoma and Arkansas.,Sensitivity analysis of soil water estimates to parameters and radar rainfall input is also a natural extension of this work.,"The main conclusions are that: (a) the distributed model forced by NEXRAD data produces results comparable to those produced by the operational spatially-lumped models using raingauge data, (b) sensitivity of flow statistics on various spatial scales to parameters and radar-rainfall input that are uncertain is scale dependent; and (c) in view of parametric and input uncertainty, in several cases, a spatially lumped model has response that cannot be statistically distinguished from that of the distributed model."
10.1016/j.cma.2013.10.015,The Vertex Morphing method for node-based shape optimization (2014),This method introduces a control field and a map that relates it to the geometry field.,The optimization problem is solved in the control space and the map is defined such that both surface smoothness and mesh regularity criteria are satisfied simultaneously and synchronously in the geometry field.,"The Vertex Morphing method, a consistent surface control approach for shape optimization is presented.",,
10.1016/j.jhydrol.2003.09.030,Impact of imperfect potential evapotranspiration knowledge on the efficiency and parameters of watershed models (2004),"First, Penman PE estimates were regionalized in the Massif Central highlands of France, a mountainous area where PE is known to vary greatly with elevation, latitude, and longitude.",This paper attempts to assess the impact of improved estimates of areal potential evapotranspiration (PE) on the results of two rainfall-runoff models.,"In terms of model efficiency, in both models it was found that very simple assumptions on watershed PE input (the same average input for all watersheds) yield the same results as more accurate input obtained from regionalization.",The detailed evaluation of the GRJ model calibrated with different PE input scenarios showed that the model is clearly sensitive to PE input.,"A network of  PE stations was used for a sample of  watersheds and two watershed models of different complexity (the four-parameter GRJ model and an eight-parameter modified version of TOPMODEL), to test how sensitive rainfall-runoff models were to watershed PE estimated with the Penman equation."
10.1016/j.jcp.2017.03.021,Uncertainty propagation of p-boxes using sparse polynomial chaos expansions (2017),"In this context, a typical workflow includes the characterization of the uncertainty in the input variables.",They show that the proposed two level approach allows for an accurate estimation of the statistics of the response quantity of interest using a small number of evaluations of the exact computational model.,The capabilities of the proposed approach are illustrated through applications using a benchmark analytical function and two realistic engineering problem settings.,"A two-level meta-modelling approach is proposed using non-intrusive sparse polynomial chaos expansions to surrogate the exact computational model and, hence, to facilitate the uncertainty quantification analysis.",The propagation of p-boxes leads to p-boxes of the output of the computational model.
10.1016/j.jcp.2009.06.013,Effect of randomness on multi-frequency aeroelastic responses resolved by Unsteady Adaptive Stochastic Finite Elements (2009),"Results for multi-frequency responses and continuous structures show a three orders of magnitude reduction of computational costs compared to crude Monte Carlo simulations in a harmonically forced oscillator, a flutter panel problem, and the three-dimensional transonic AGARD .","In this paper, the UASFE framework is extended to multi-frequency responses and continuous structures by employing a wavelet decomposition pre-processing step to decompose the sampled multi-frequency signals into single-frequency components.",The Unsteady Adaptive Stochastic Finite Elements (UASFE) method resolves the effect of randomness in numerical simulations of single-mode aeroelastic responses with a constant accuracy in time for a constant number of samples.,,
10.1016/j.envsoft.2013.10.001,Untangling drivers of species distributions: Global sensitivity and uncertainty analyses of MAXENT (2014),"These results are related to the SP but, in general MAXENT appears as a very non-linear model where uncertainty mostly derives from the interactions among input factors.",We consider the Snowy Plover (Charadrius alexandrinus nivosus) (SP) in Florida that is a shorebird whose habitat is affected by sea level rise due to climate change.,The importance of intrinsic and exogenous input factors to the uncertainty of the species distribution is evaluated for MAXENT.,Untangling drivers of systems and uncertainty for species distribution models (SDMs) is important to provide reliable predictions that are useful for conservation campaigns.,The large land cover variation determines a moderate decrease in habitat suitability in  and  prospecting a low risk of decline for the SP.
10.1016/j.envsoft.2016.09.020,"Uncertainty analysis and evaluation of a complex, multi-specific weed dynamics model with diverse and incomplete data sets (2016)","FLORSYS satisfactorily predicted weed seed bank, plant densities and crop yields, at daily and multi-annual scales, at well monitored sites.","We adapted existing validation methodologies and uncertainty analyses to account for multi-specific, multi-annual and diverse outputs, focusing on missing input data, incomplete and imprecise weed time series.",It overestimated plant biomass and underestimated total flora density.,"Here, we evaluated the FLORSYS model which quantifies the effects of cropping systems and pedoclimate on multispecific weed dynamics with a daily time step.","Weed dynamics models are needed to test prospective cropping systems but are rarely evaluated with independent data (""validated"")."
10.1016/j.jhydrol.2015.10.021,A polynomial chaos ensemble hydrologic prediction system for efficient parameter inference and robust uncertainty assessment (2015),"The PCEHPS is developed through a two-stage factorial polynomial chaos expansion (PCE) framework, which consists of an ensemble of PCEs to approximate the behavior of the hydrologic model, significantly speeding up the exhaustive sampling of the parameter space.","Multiple hypothesis testing is then conducted to construct an ensemble of reduced-dimensionality PCEs with only the most influential terms, which is meaningful for achieving uncertainty reduction and further acceleration of parameter inference.","A detailed comparison between the HYMOD hydrologic model, the ensemble of PCEs, and the ensemble of reduced PCEs is performed in terms of accuracy and efficiency.","Results reveal temporal and spatial variations in parameter sensitivities due to the dynamic behavior of hydrologic systems, and the effects (magnitude and direction) of parametric interactions depending on different hydrological metrics.","This paper presents a polynomial chaos ensemble hydrologic prediction system (PCEHPS) for an efficient and robust uncertainty assessment of model parameters and predictions, in which possibilistic reasoning is infused into probabilistic parameter inference with simultaneous consideration of randomness and fuzziness."
10.1016/j.jhydrol.2016.04.032,Tools for investigating the prior distribution in Bayesian hydrology (2016),The results of the application of this toolkit suggest the prior distribution can have a significant impact on the posterior distribution and should be more routinely assessed in hydrologic studies.,"The tools described here consist of two measurements, the Kullback-Leibler Divergence (KLD) and the prior information elasticity.",The prior information elasticity is then used to quantify the responsiveness of the KLD values to the change of prior distributions and length of available data.,This paper describes tools for the evaluation of parameter sensitivity to the prior distribution to provide guidelines for defining meaningful priors.,
10.1016/j.cma.2004.04.011,Finite element response sensitivity analysis: a comparison between force-based and displacement-based frame element models (2005),The two methodologies for displacement-based and force-based element sensitivity computations are compared.,Significant benefits are found in using force-based frame element models for both response and response sensitivity analysis in terms of trade-off between accuracy and computational cost.,This paper focuses on a comparison between displacement-based and force-based elements for static and dynamic response sensitivity analysis of frame type structures.,"Previous research has shown that force-based frame elements are superior to classical displacement-based elements enabling, at no significant additional computational costs, a drastic reduction in the number of elements required for a given level of accuracy in the simulated response.",
10.1016/j.cma.2012.05.003,A fast Monte-Carlo method with a reduced basis of control variates applied to uncertainty propagation and Bayesian estimation (2012),"We also numerically demonstrate that it can be useful to some parametric frameworks in Uncertainty Quantification, in particular (i) the case where the parametrized expectation is a scalar output of the solution to a Partial Differential Equation (PDE) with stochastic coefficients (an Uncertainty Propagation problem), and (ii) the case where the parametrized expectation is the Bayesian estimator of a scalar output in a similar PDE context.",We provide here a more complete analysis of the method including precise error estimates and convergence results.,"The reduced-basis control-variate Monte-Carlo method was introduced recently in [S. Boyaval, T. Lelievre, A variance reduction method for parametrized stochastic differential equations using the reduced basis paradigm, Commun.","Moreover, in each case, a PDE has to be solved many times for many values of its coefficients.",
10.1016/j.jhydrol.2015.06.018,Uncertainty of climate change impact on groundwater reserves - Application to a chalk aquifer (2015),"In this study, the uncertainties around impact projections from several sources (climate models, natural variability of the weather, hydrological model calibration) are calculated and compared for the Geer catchment ( km()) in Belgium.",The total uncertainty associated with the prediction of groundwater levels remains large.,"By the end of the century, however, the uncertainty becomes smaller than the predicted decline in groundwater levels.",Recent studies have evaluated the impact of climate change on groundwater resources for different geographical and climatic contexts.,This integrated model provides a more realistic representation of the water exchanges between surface and subsurface domains and constrains more the calibration with the use of both surface and subsurface observed data.
10.1016/j.envsoft.2014.09.005,Plant Modelling Framework: Software for building and running crop models on the APSIM platform (2014),The PMF contains a top-level Plant class that provides an interface with the APSIM model environment and controls the other classes in the plant model.,Four examples are included to demonstrate the flexibility of application of the PMF; .,(C)  The Authors.,A plant configuration file specifies which mid-level and Function classes are to be included and how they are to be arranged and parameterised to represent a particular crop model.,These examples show the PMF can be used to develop models of different complexities and allows flexibility in the approach for implementing crop physiology concepts into model set up.
10.1016/j.jhydrol.2012.02.047,Does increased hydrochemical model complexity decrease robustness? (2012),"The results highlighted the most complex structure as the most appropriate, providing the best representation of the non-linear patterns observed in the flow and streamwater nitrate concentrations between  and .",Water quality data help constrain the hydrological representation in process-based models.,The results confirm the importance of the riparian zone in controlling the short-term (daily) streamwater nitrogen dynamics in this catchment but not the overall flux of nitrogen from the catchment.,,
10.1016/j.jcp.2013.05.016,A probabilistic graphical model approach to stochastic multiscale partial differential equations (2013),Both the stochastic input and model responses are treated as random variables in this framework.,"Finally, we make predictions from the probabilistic graphical model using the belief propagation algorithm.",,,
10.1016/j.jcp.2010.12.021,Adaptive sparse polynomial chaos expansion based on least angle regression (2011),of Galerkin type) or non intrusive) unaffordable when the deterministic finite element model is expensive to evaluate.,Then the method is illustrated on three stochastic finite element problems.,Then an adaptive algorithm based on least angle regression (LAR) is devised for automatically detecting the significant coefficients of the PC expansion.,The convergence of the algorithm is shown on an analytical function.,"The first model features  input random variables, whereas the two others involve an input random field, which is discretized into  and - random variables, respectively."
10.1016/j.jcp.2017.04.012,Combining multiple surrogate models to accelerate failure probability estimation with expensive high-fidelity models (2017),"The key property of our MMFIS estimator is that it can leverage multiple surrogate models for the construction of the biasing distribution, instead of a single surrogate model alone.",We present a mixed multifidelity importance sampling (MMFIS) approach that leverages computationally cheap but erroneous surrogate models for the construction of the biasing distribution and that uses the original high-fidelity model to guarantee unbiased estimates of the failure probability.,"In particular, our MMFIS approach avoids the problem of selecting the surrogate model that leads to the estimator with the lowest mean-squared error, which is challenging if the approximation quality of the surrogate models is unknown.","We demonstrate our MMFIS approach on numerical examples, where we achieve orders of magnitude speedups compared to using the high-fidelity model only.",
10.1016/j.envsoft.2012.12.010,Using a Bayesian framework and global sensitivity analysis to identify strengths and weaknesses of two process-based models differing in representation of autotrophic respiration (2013),In this work two versions of a process-based model that differed in the autotrophic respiration modelling were analysed.,The Morris method in combination with the Bayesian framework helped to identify key parameters and gave a deeper understanding of model behaviour.,"Bayesian statistics and global sensitivity analysis allow to reduce uncertainties in parameters and outputs, and they provide better insight of model behaviour.",Process-based models are powerful tools for sustainable and adaptive forest management.,The Bayesian approach allowed also to identify the weaknesses and strengths of the dataset used for the analyses.
10.1007/s00158-016-1619-7,Pareto surface construction for multi-objective optimization under uncertainty (2017),A vehicle side impact problem is employed to demonstrate the proposed methodology.,The proposed approach is formulated in the context of reliability-based design optimization (RBDO).,"Samples from the conditional distributions are used to evaluate the objectives and constraints, which are fed back to the optimizer for further iteration.","In each design iteration, the optimizer provides the values of the design variables to the BN, and copula-based sampling is used to rapidly generate samples of the output variables conditioned on the input values.",The joint probability of multiple objectives and constraints is included in the formulation.
10.1016/j.jhydrol.2008.01.028,Evaluating the parameter identifiability and structural validity of a probability-distributed model for soil moisture (2008),The objective of this study is to evaluate the performance of a model that simulates local and spatial average soil moisture in a watershed.,"Third, a new method is developed that uses the sensitivities of soil moisture to precipitation and PET to assess the impacts of parameter uncertainty and structural errors on forecasts for unobserved conditions.","First, the model's ability to reproduce observed local and spatial average soil moisture through calibration is examined.",This result implies that parameter uncertainty and model structural errors contribute substantially to model uncertainty for unobserved conditions.,"Second, the identifiability and stability of the parameter values are considered to assess uncertainty in the parameter values and errors in the model's mathematical structure."
10.1007/s00158-014-1126-7,Application of topological derivative to accelerate genetic algorithm in shape optimization of coupled models (2015),"The expansion with respect to small parameter of the shape functional for nonlinear component and the expansion of Steklov-Poincar, operator for linear component are derived in order to determine the form of topological derivative for shape functional defined for coupled model.",The linear and nonlinear components are connected by the transmission conditions on the interface boundary.,,,
10.1016/j.envsoft.2005.09.010,Grid sensitivity analysis for the calibration of a prognostic meteorological model in complex terrain by a screening experiment (2007),A total of five simulations was performed for a grid configuration study that aimed to calibrate The Air Pollution Model.,In this study we present an application of a sensitivity analysis to identify a set of important factors that are allowed to be calibrated in the grid setup of a prognostic meteorological model for laboratory-based simulations.,,,
10.1007/s00158-007-0218-z,Uncertainty analysis of structural systems by perturbation techniques (2008),Results remain accurate for non-linear design functions if they can be approximated by a linear combination of the basic random variables.,The formulation of an efficient method to evaluate the uncertainty of the structural response by applying perturbation techniques is described.,"The implemented computational program allows, in only one structural analysis, to evaluate the mean value and the standard deviation of the structural response, defined in terms of displacements or forces.",It is also presented the procedure used to implement this method in a structural finite element framework.,
10.1016/S1364-8152(02)00026-9,Uncertainty analysis in air dispersion modeling (2002),The Taylor series approach for uncertainty analyses is advanced as an efficient method of producing a probabilistic output from air dispersion models.,The Taylor series uncertainty estimates are a function of the variance in input parameters (wind speed and temperature) and the model sensitivities to input parameters.,The results of the combined ISCST and uncertainty calculations are then validated with traditional Monte Carlo (MC) simulations.,"In this work, the Industrial Source Complex Short Term (ISCST) model is used as an analytical model to predict pollutant transport from a point source.","Since the Taylor series approach is simple and time-efficient compared to the MC method, it provides an attractive alternative."
10.1016/j.envsoft.2005.07.014,Decision making under uncertainty in a decision support system for the Red River (2007),"In order to support policy makers to make a strategic selection between different measures in a DSS while taking uncertainty into account, a methodology for the ranking of measures has been developed.",The methodology consists of a Monte Carlo uncertainty analysis employing Latin Hypercube Sampling and a ranking procedure based on the significance of the difference between output distributions for different measures.,The mean flood damage in the base situation is about .,The methodology has been applied to a pilot DSS for flood control in the Red River basin in Vietnam and China.,"Selected applications of the measures reforestation, dike heightening and the construction of a retention basin reduce the flood damage by about ,  and  million US$, respectively."
10.1016/j.envsoft.2017.02.006,Appraisal of data-driven and mechanistic emulators of nonlinear simulators: The case of hydrodynamic urban drainage models (2017),"Herein we compare the performance of two kinds of emulators: mechanistic emulators that use knowledge of the simulator's equations, and purely data-driven emulators using matrix factorization.",We also point to advances in Machine Learning that have not permeated yet into the environmental science community.,Results suggest that naive data-driven emulation outperforms mechanistic emulation.,"Fast emulators provide a solution to this efficiency demand, sacrificing unneeded accuracy for speed.",Accurate simulators are too slow for these applications.
10.1007/s00158-016-1493-3,A systematic approach for model refinement considering blind and recognized uncertainties in engineered product development (2016),"However, it is challenging to build the highly accurate computational models for virtual testing.",These uncertainties consequently decrease the predictive capability of the models.,"It sequentially lists and screens potential candidate issues for model refinement at the stages of conceptual, mathematical, and computational modeling.",Blind and recognized uncertainties are often unintentionally incorporated.,"Finally, the ISA quantifies the effect of incorporating updates in the model to address potential candidate issues with the goal of reducing the impact of the blind and recognized uncertainties."
10.1016/j.jcp.2015.09.043,A multilevel finite element method for Fredholm integral eigenvalue problems (2015),"The main motivation for such studies is to compute the Karhunen-Loeve expansions of random fields, which play an important role in the applications of uncertainty quantification.",It is noticed that the total computational work of our method is comparable with a single integration step in the finest mesh.,"The error estimates are provided, and the computational complexity is analyzed.",,
10.1016/j.jcp.2008.11.024,Dimensionality reduction and polynomial chaos acceleration of Bayesian inference in inverse problems (2009),"We seek a solution of this problem using Galerkin projection on a polynomial chaos basis, and use the solution to construct a reduced-dimensionality surrogate posterior density that is inexpensive to evaluate.","We address these challenges by introducing truncated Karhunen-Loeve expansions, based on the prior distribution, to efficiently parameterize the unknown field and to specify a stochastic forward problem whose solution captures that of the deterministic forward model over the support of the prior.",,,
10.1016/j.envsoft.2016.02.026,Modeling metal-sediment interaction processes: Parameter sensitivity assessment and uncertainty analysis (2016),The delineation of periods related to different river flow regimes allowed optimizing the characterization of cohesive sediment parameters and effectively reducing the overall model uncertainty.,"In this study, our objective is to elucidate the uncertainty pertaining to micropollutant modeling in the sediment-water column interface.",Bayesian Monte Carlo is used to quantify the propagation of parameter uncertainty through the model and obtain the posterior parameter probabilities.,,
10.1016/j.jhydrol.2015.11.052,Quantifying dynamic sensitivity of optimization algorithm parameters to improve hydrological model calibration (2016),"It is widely recognized that optimization algorithm parameters have significant impacts on algorithm performance, but quantifying the influence is very complex and difficult due to high computational demands and dynamic nature of search parameters.","The Shuffled Complex Evolution method developed at the University of Arizona algorithm (SCE-UA) is selected as an optimization algorithm for investigation, and two criteria, i.e., convergence speed and success rate, are used to measure the performance of SCE-UA.",The overall aim of this paper is to develop a global sensitivity analysis based framework to dynamically quantify the individual and interactive influence of algorithm parameters on algorithm performance.,"Interactions between algorithm parameters have significant impacts on SCE-UA performance, which has not been reported in previous research.",
10.1016/j.jcp.2017.01.034,On the variational data assimilation problem solving and sensitivity analysis (2017),"We present a computing approach to solve the main computational kernel at the heart of the VarDA problem, which outperforms the technique nowadays employed by the oceanographic operative software.","We consider the Variational Data Assimilation (VarDA) problem in an operational framework, namely, as it results when it is employed for the analysis of temperature and salinity variations of data collected in closed and semi closed seas.",,,
10.1007/s00158-013-0915-8,Batch sequential design of optimal experiments for improved predictive maturity in physics-based modeling (2013),"Given the limited resources, it is therefore crucial to design validation experiments to maximize the improvement in the predictive capability of the physics-based numerical models.",This limitation poses difficulties especially if the model is to be executed to predict at different settings and/or regimes within a domain.,"Our focus is on the Batch Sequential Design methods, which for a given set of initial experiments and a selection criteria, iteratively select a batch of future experiments.","The focus of nuclear fuel design and maintenance has been shifting from a primarily empirical endeavor to that of highly advanced simulations characterized by experiment-based calibration, validation and uncertainty quantification.",
10.1007/s00158-012-0832-2,On compliance and buckling objective functions in topology optimization of snap-through problems (2013),Different compliance and buckling criterion functions are studied and applied for topology optimization of a point loaded curved beam problem with the aim of maximizing the snap-through buckling load.,"The typical remedy applied for linear buckling does not have a natural extension to nonlinear problems, and we propose an alternative approach.",This paper deals with topology optimization of static geometrically nonlinear structures experiencing snap-through behaviour.,We finally discuss and pinpoint some of the issues related to buckling topology optimization that remains unsolved and demands further research.,A well-known issue in buckling topology optimization is artificial buckling modes in low density regions.
10.1016/j.cma.2016.12.036,Design sensitivity analysis for shape optimization based on the Lie derivative (2017),"any function of the solution of the problem) with respect to a given design variable can be represented mathematically as a Lie derivative, i.e.",There is some freedom in the definition of the auxiliary flow that represents the shape modification.,"Theoretical formulae to express sensitivity analytically are demonstrated in detail in the paper, and applied to a nonlinear magnetostatic and a linear elastic problem, following both the direct and the adjoint approaches.",All sensitivity calculations are checked with a finite difference in order to validate the analytic approach.,The paper presents a theoretical framework for the shape sensitivity analysis of systems governed by partial differential equations.
10.1007/s00158-009-0405-1,A parametric level-set approach for topology optimization of flow domains (2010),"While the parametric level-set approach leads to similar optimal designs, the present study reveals no general improvements of the convergence of the optimization process and of the robustness of the nonlinear flow analyses when compared to the traditional material distribution approach.","Instead, our numerical experiment suggests that a continuation method operating on the volume constraint is needed to achieve optimal designs at higher Reynolds numbers.","Using a hydrodynamic lattice Boltzmann method, we study the performance of our level-set approach in comparison to a traditional material distribution approach.",Non-smooth material distributions are suspected to trigger premature onset of instationary flows which cannot be treated by steady-state flow models.,"Traditional methods based on an element-wise parameterization of the material distribution applied to the topology optimization of fluidic systems often suffer from slow convergence of the optimization process, as well as robustness issues at increased Reynolds numbers."
10.1016/j.jhydrol.2016.02.029,Efficient fuzzy Bayesian inference algorithms for incorporating expert knowledge in parameter estimation (2016),Bayesian inference has traditionally been conceived as the proper framework for the formal incorporation of expert knowledge in parameter estimation of groundwater models.,"In this paper, a novel approach of accelerating the fuzzy Bayesian inference algorithm is proposed which is based on using approximate posterior distributions derived from surrogate modeling, as a screening tool in the computations.",One of these extensions is 'fuzzy Bayesian inference' which is the result of integrating fuzzy techniques into Bayesian statistics.,An expert elicitation methodology is developed and applied to the real-world test case in order to provide a road map for the use of fuzzy Bayesian inference in groundwater modeling applications.,"It is shown that for this synthetic test case, the proposed approach decreases the number of required numerical simulations by an order of magnitude."
10.1016/j.envsoft.2006.06.017,Numerical and visual evaluation of hydrological and environmental models using the Monte Carlo analysis toolbox (2007),"In addition to research applications, the MCAT can be used as a teaching tool in courses that include the use of mathematical models.","The MCAT contains tools for the evaluation of performance, identitiability, sensitivity, predictive uncertainty and also allows for the testing of hypotheses with respect to the model structure used.","The MCAT can be used off-line, i.e.","The detailed evaluation of mathematical models and the consideration of uncertainty in the modeling of hydrological and environmental systems are of increasing importance, and are sometimes even demanded by decision makers.","At the same time, the growing complexity of models to represent real-world systems makes it more and more difficult to understand model behavior, sensitivities and uncertainties."
10.1016/j.envsoft.2014.08.012,A universal Model-R Coupler to facilitate the use of R functions for model calibration and analysis (2014),"However, it is a challenge to make a model utilize the open and growing functions (e.g., model inversion) on the R platform due to the requirement of accessing and revising the model's source code.","The developed tool (Model-R Coupler) is promising because users of any model can connect an external algorithm (written in R) with their model to implement various model behavior analyses (e.g., parameter optimization, sensitivity and uncertainty analysis, performance evaluation, and visualization) without accessing or modifying the model's source code.","To overcome this barrier, we developed a universal tool that aims to convert a model developed in any computer language to an R function using the template and instruction concept of the Parameter ESTimation program (PEST) and the operational structure of the R-Soil and Water Assessment Tool (R-SWAT).",Mathematical models are useful in various fields of science and engineering.,
10.1016/j.cma.2007.07.003,Stochastic design optimization: Application to reacting flows (2007),Gradient descent and simulated annealing optimization techniques are successfully tested on the kinetic energy surrogate model of the device inner parts.,The geometric configuration is assumed to be uncertain.,The surrogate model can then be put to use within an appropriate optimization algorithm and provides fast approximations at new design points.,A stochastic optimization framework combining stochastic surrogate model representation and optimization algorithm is proposed.,A generalized Polynomial Chaos stochastic representation is used as the surrogate model.
10.1016/j.envsoft.2014.06.006,Uncertainty and sensitivity analyses using GLUE when modeling inhibition and pharmaceutical cometabolism during nitrification (2014),The influence of uncertainties in biokinetic parameters for ammonia and nitrite oxidizing bacteria on the performance of a two-step nitrification model was evaluated using the Generalized Uncertainty Estimation (GLUE) technique.,"Use of a competitive inhibition model for ammonia oxidation (i.e., correction of the model structural error), however, enables GLUE to generate meaningful uncertainty intervals.",Results suggest that the AOB-growth related transformation coefficient of atenolol is relatively insensitive to variation in ammonia and nitrite oxidizing biokinetic parameters.,Results suggest that GLUE cannot account for model structural error arising when ammonia oxidation is competitively inhibited.,Sensitivity was assessed by computing nonparametric elasticities of the cometabolism transformation coefficients to biokinetic parameters selected to describe nitrification in a novel application of a generalized nonparametric analysis.
10.1016/j.cma.2005.11.012,A cascade optimization methodology for automatic parameter identification and shape/process optimization in metal forming simulation (2006),"In this paper, we will focus on two categories of such inverse problems.",The second category consists of shape/process optimization inverse problems.,The first category consists of parameter identification inverse problems.,"Computer simulations of metal forming processes using the finite element method (FEM) are, today, well established.","These involve determining the initial geometry of the specimen and/or the shape of the forming tools, as well as some parameters of the process itself, in order to provide the desired final geometry after the forming process."
10.1016/j.cma.2007.07.035,NASA Langley's approach to the Sandia's structural dynamics challenge problem (2008),"For example, one key technical challenge is related to the fact that there is limited data on the target configurations.","Moreover, in this challenge problem, additional constraints, in the form of ground rules, have been added.","Although deterministic analyses of this type are routinely performed and representative of issues faced in real-world system design and integration, there are still several key technical challenges that must be addressed when analyzing the uncertainties of interconnected systems.","The other two approaches worked solutions in physical space where the uncertain parameter set is made of masses, stiffnessess, and damping coefficients; one matches the confidence intervals of low order moments of the statistics via optimization while the second one uses a Kernel density estimation approach.",The objective of this challenge is to develop a data-based probabilistic model of uncertainty to predict the acceleration response of subsystems (payloads) by themselves and while coupled to a primary (target) system.
10.1007/s00158-005-0575-4,A review of optimization of structures subjected to transient loads (2006),"The main themes of the paper are treatment of time-dependent constraints, calculation of design sensitivity, and approximation.",It takes advantage of the well-established static response optimization.,The structural optimization in flexible multibody dynamic systems is reviewed in the viewpoint of the above three themes.,The approximation concept mainly focuses on the response surface method in crashworthiness and local approximation with the intermediate variables.,Each subject is reviewed with corresponding papers that have been published since the s. The treatment of time-dependent constraints in both the direct method and the transformation method is discussed.
10.1007/s00158-016-1423-4,A variable-accuracy metamodel-based architecture for global MDO under uncertainty (2016),"Two analytical test problems are shown, along with the design of a racing-sailboat keel fin subject to the stochastic variation of the yaw angle.","The challenging aspects of simulation-based MRDO are both algorithmic and computational, since the solution of a MRDO problem typically requires simulation-based multidisciplinary analyses (MDA), uncertainty quantification (UQ) and optimization.","The method is validated versus a standard MDF approach to MRDO, taken as a benchmark and solved by fully coupled MDA, fully converged UQ, without metamodels.","Herein, the identification of the optimal design is achieved by a variable-accuracy, metamodel-based optimization, following a multidisciplinary feasible (MDF) architecture.",A method for simulation-based multidisciplinary robust design optimization (MRDO) of problems affected by uncertainty is presented.
10.1016/j.envsoft.2015.06.007,Employing statistical model emulation as a surrogate for CFD (2015),In a second step the calibrated emulator is used as surrogate for the simulator in the otherwise prohibitively expensive application.,,,,
10.1016/j.jcp.2017.08.008,Topology optimisation of micro fluidic mixers considering fluid-structure interactions with a coupled Lattice Boltzmann algorithm (2017),"Furthermore, the topology optimisation method outperforms a Tabu Search algorithm in designing the baffle to maximise the mixing of the two fluids.",The multidisciplinary topology optimisation framework presented in this article is shown to increase the stiffness of the structure from the datum case and produce physically acceptable designs.,"The ultimate aim of this research is to couple two key disciplines, fluids and structures, into a topology optimisation framework, which shows fast convergence for multidisciplinary optimisation problems.","In this work, twin physical situations, whereby optimal fluid mixing in the form of vorticity maximisation is accompanied by the requirement that the casing in which the mixing takes place has the best structural performance in terms of the greatest specific stiffness, are considered.","In the steady state of mixing this also means that the stresses in the casing are as uniform as possible, thus giving a desired operating life with minimum weight."
10.1016/j.jhydrol.2015.03.025,Skill of remote sensing snow products for distributed runoff prediction (2015),"The simulated discharge is subjected to five criteria for validation, while the GLUE methodology is used for uncertainty analysis of the ten model variants.","However, no clear relation was observed between the prediction confidence interval and the two model structures.","It is concluded that the skill of the remote sensing snow cover data for the model is positive, although, strongly varying with the data source used.",With increasing availability of remote sensing snow cover products we aim to evaluate the skill of these datasets with regard to hydrological discharge simulation.,"However, other evaluation measures indicate that the following data sources performed better than the standard model: MODA, observed snow depth and GLOBSNOW for Kling-Gupta efficiency and for high flows; IMS and MODA for bias; GLOBSNOW and MODA for coefficient of determination."
10.1007/s00158-011-0668-1,Shape optimisation of preform design for precision close-die forging (2011),The results suggest that the developed topology optimisation method is an efficient approach for preform design optimisation.,Preform design is an essential stage in forging especially for parts with complex shapes.,Two D case problems including forging of an aerofoil shape and forging of rail wheel are evaluated using the developed method.,,
10.1016/j.jhydrol.2015.12.045,Uncertainty and sensitivity assessments of an agricultural-hydrological model (RZWQM2) using the GLUE method (2016),Quantitatively ascertaining and analyzing the effects of model uncertainty on model reliability is a focal point for agricultural-hydrological models due to more uncertainties of inputs and processes.,"Parameters on soil saturated hydraulic conductivity, nitrogen nitrification and denitrification, and urea hydrolysis played an important role in crop yield component.","In this study, the generalized likelihood uncertainty estimation (GLUE) method with Latin hypercube sampling (LHS) was used to evaluate the uncertainty of the RZWQM-DSSAT (RZWQM) model outputs responses and the sensitivity of  parameters related to soil properties, nutrient transport and crop genetics.",This new and successful application of the GLUE method for determining the uncertainty and sensitivity of the RZWQM could provide a reference for the optimization of model parameters with different emphases according to research interests.,"The results of uncertainty analysis using of GLUE method showed T-NIT was sensitive to parameters relative to nitrification coefficient, maize growth characteristics on seedling period, wheat vernalization period, and wheat photoperiod."
10.1016/j.cma.2015.07.024,A gradient-based shape optimization scheme using an interface-enriched generalized FEM (2015),"Due to the fixed nature of the mesh, the so-called design velocity field only needs to be computed on the structure boundary/interface.","Finally, we solve various numerical examples to demonstrate the capability of the method including the computational design of particulate and microvascular composites.",,,
10.1016/j.cma.2007.01.006,Interval sensitivity theory and its application to frequency response envelope analysis of uncertain structures (2007),The interval sensitivities represent a measure for the individual influence of uncertain interval inputs on the range of the obtained interval outcome of the analysis.,"The approach differs from the classical sensitivity analysis in the fact that it does not focus on local first or second-order behaviour of the output function in a design point, but rather provides the analyst with information on the sensitivity of the full range of the result with respect to the defined finite interval uncertainties.","Next, the procedure is applied to the envelope frequency response function analysis of uncertain mechanical structures, yielding the sensitivity of the bounds defining the response range to the width of each individual uncertain input parameter interval.","After introduction of the concept, it is shown how interval sensitivities are calculated in the framework of general numerical interval analysis.",This paper introduces the new concept of interval sensitivities applicable in the general context of numerical interval analysis.
10.1016/j.jcp.2013.05.006,A nonparametric belief propagation method for uncertainty quantification with applications to flow in random porous media (2013),The proposed framework can be used as a surrogate model to predict the responses for new input realizations as well as our confidence on these predictions.,Model reduction techniques are used locally in the graph to represent the random permeability.,Numerical examples are presented to demonstrate the accuracy and efficiency of the proposed framework for solving uncertainty quantification problems in flows through porous media using stationary and non-stationary permeability fields.,A probabilistic graphical model approach to uncertainty quantification for flows in random porous media is introduced.,We develop a nonparametric belief propagation method for uncertainty quantification by employing the loopy belief propagation algorithm.
10.1016/j.envsoft.2015.10.014,Incorporation of extended neighborhood mechanisms and its impact on urban land-use cellular automata simulations (2016),"Here, we quantify neighborhood effects in a relatively large cellular space and analyze their role in the performance of an urban land use model.",Urban cellular automata (CA) models are broadly used in quantitative analyses and predictions of urban land-use dynamics.,Simulations with the Logistic-LNCA model raised the accuracies of built-up land by .%-.% in two simulation periods compared with the Logistic-CA model with a  x  kernel.,"The extracted neighborhood rules were integrated into a commonly used logistic regression urban CA model (Logistic-CA), resulting in a large neighborhood urban land use model (Logistic-LNCA).",(C)  The Authors.
10.1016/j.cma.2010.05.014,Total pressure losses minimization in turbomachinery cascades using the exact Hessian (2010),"To compute the Hessian, the direct differentiation of the viscous flow equations is used for the first-order sensitivities of the functional and the flow-related constraints, followed by the discrete adjoint method.","An ""exactly"" initialized quasi-Newton method was also programmed and tested.","The comparison of the efficiency of the aforementioned methods depends on the number of design variables used; the ""exactly"" initialized quasi-Newton method constantly outperforms its conventional variant in terms of CPU cost, particularly in non-convex and/or constrained optimization problems.","It is based on the Newton-Lagrange method which requires the computation of first- and second-order sensitivities of the objective function and the constraints, with respect to the design variables.","The computation of the exact Hessian of the function which expresses the difference in total pressure between the inlet to and the outlet from the cascade, is new in the literature."
10.1016/j.envsoft.2013.08.008,"Towards optimal allocation of computer resources: Trade-offs between uncertainty quantification, discretization and model reduction (2013)",Controlling these resolutions allows keeping the computational cost at a tractable level whilst still aiming at accurate and robust predictions.,We illustrate our approach with three examples from subsurface hydrogeology and show that the computational costs can be substantially reduced when allocating computational resources wisely and in a situation-specific and task-specific manner.,"As a pragmatic way to proceed, we propose running small cost-efficient pre-investigations in order to estimate the joint cost-to-error surface, then fit underlying complexity and error models, decide upon a computational design for the full simulation, and finally to perform the designed simulation at near-optimal costs-to-accuracy ratio.",,
10.1016/j.jcp.2008.02.003,A semi-implicit level set method for structural shape and topology optimization (2008),"In the present study, the Hamilton-Jacobi partial differential equation (PDE) is solved numerically using a semi-implicit additive operator splitting (AOS) scheme rather than explicit schemes in conventional level set methods.","The main feature of the present method is it does not suffer from any time step size restriction, as all terms relevant to stability are discretized in an implicit manner.","Hence, the present scheme for the level set equations is stable for any practical time steps and numerically easy to implement with high efficiency.",This paper proposes a new level set method for structural shape and topology optimization using a semi-implicit scheme.,Structural boundary is represented implicitly as the zero level set of a higher-dimensional scalar function and an appropriate time-marching scheme is included to enable the discrete level set processing.
10.1016/j.cma.2007.12.010,Formulation of the static frame problem (2008),"The challenge problem has clear engineering character, is simple to state and allows many different approaches to solve it.",,,,
10.1007/s00158-014-1160-5,Probabilistic measures for assessing appropriateness of robust design optimization solutions (2015),"This work introduces a new robustness measure, termed probability of dominance, for assessing the appropriateness of each candidate design.","RDO can lead to a wide range of different candidate designs, establishing a different compromise between these competing objectives.","For enhancing the robustness in these comparisons the impact of prediction errors, introduced to address potential differences between the real (i.e.","Furthermore, a multi-stage implementation is introduced to facilitate increased versatility/confidence in the decision-making process by considering the comparison among smaller subsets within the initial larger set of candidate designs.","as built) system and the numerical model adopted for it, is also addressed."
10.1016/j.cma.2007.11.021,Multi-element stochastic reduced basis methods (2008),Stochastic reduced basis methods (SRBMs) are employed in each random element to evaluate the response statistics.,This paper presents multi-element stochastic reduced basis methods (ME-SRBMs) for solving linear stochastic partial differential equations.,"In ME-SRBMs, the domain of definition of the random inputs is decomposed into smaller subdomains or random elements.",,
10.1016/j.jcp.2014.12.028,Uncertainty propagation using infinite mixture of Gaussian processes and variational Bayesian inference (2015),This non-trivial extension involves an infinite mixture of MGP's that is trained using variational Bayesian inference.,The automatic detection of the mixture components by the variational inference algorithm is able to capture discontinuities and localized features without adhering to ad hoc constructions.,"Prior to observing any data, a Dirichlet process is used to generate the components of the MGP mixture.","The Bayesian nature of the model allows for the quantification of the uncertainties due to the limited number of simulations, i.e., we can derive error bars for the statistics of interest.","However, the construction of the surrogate surface is hampered by various aspects such as the limited number of model evaluations that one can afford, the curse of dimensionality, multi-variate responses with non-trivial correlations, potential localized features of the response and/or discontinuities."
10.1016/j.cma.2008.04.019,Structural optimization of ferromagnetic materials based on the magnetic reluctivity for magnetic field problems (2008),Numerical examples are focused on magnetic actuators to maximize the magnetic force attracting an armature.,Topology optimization of ferromagnetic materials in magnetic fields using the homogenization method and the density method has been attempted from an angle of the interpolation scheme based on the magnetic permeability.,This study intends to verify that the interpolation scheme using the magnetic permeability may cause problems in the sensitivity analysis for the structural optimization in magnetic fields and suggests a novel interpolation scheme based on the magnetic reluctivity.,"However, optimization results based on such methods may have poor convergence history in comparison with the structural topology optimization of an elastic problem.",
10.1007/s00158-016-1427-0,Validation and updating in a large automotive vibro-acoustic model using a P-box in the frequency domain (2016),The framework introduces a p-box approach with an efficient quantification scheme of uncertainty sources and a new area metric which is relevant to the responses in the frequency domain.,"In this paper, a model validation framework is proposed and applied to a large vibro-acoustic finite element (FE) model of a passenger car.",A color map and the u-pooling of the p-boxes over the frequency band as well as the p-box at different frequencies are introduced to assess the model error and quantitative contributions of the aleatory and the epistemic input uncertainties to the overall variability of the ROIs in the frequency domain.,,
10.1016/S0022-1694(01)00509-1,Uncertainty in hydrograph separations based on geochemical mixing models (2002),The model uncertainty is investigated by the comparison of four different mixing models all based on the same tracers but considering for each component alternative hypotheses about their concentration and their spatio-temporal variability.,"Two types of uncertainty are distinguished: the 'model uncertainty', which is affected by model assumptions, and the 'statistical uncertainty', which is due to temporal and spatial variability of chemical tracer concentrations of components.",A detailed uncertainty analysis of three-component mixing models based on the Haute-Mentue watershed (Switzerland) is presented.,,
10.1016/j.envsoft.2008.09.011,More efficient PEST compatible model independent model calibration (2009),"Using the secant LM method for local search, MICUT also supports global optimization through the use of a slightly modified version of a stochastic global search technique called Multi-Level Single Linkage [Rinnooy Kan, A.H.G., Timmer, G., a. Stochastic global optimization methods, part : clustering methods.","Comparison studies with three environmental models suggest that the stochastic global optimization algorithm in MICUT is at least as, and sometimes more efficient and reliable than the global optimization algorithms available in PEST.","Efficiency studies on three distinct environmental model structures (HSPF, FASST and GSSHA) show that we can find comparable local minima with -% fewer model calls than a conventional model independent LM application.",", -; Rinnooy Kan, A.H.G., Timmer, G., b. Stochastic global optimization methods, part ii: multi level methods.",
10.1007/s00158-005-0540-2,On the enhancement of computation and exploration of discretization approaches for meshless shape design sensitivity analysis (2006),The effectiveness of the enhanced RKPM is also verified by comparison of consumption of computer time between the classical method and the improved method.,"Comparison of these two approaches is made, and the equivalence of these two superficially different approaches is demonstrated through two elastostatics problems.",,,
10.1016/j.jcp.2016.07.027,A unified framework for mesh refinement in random and physical space (2016),In this manuscript we focus on the application to random space mesh refinement.,That work relied on the explicit knowledge of an accurate reduced model which is used to monitor the transfer of activity from the large to the small scales of the solution.,We also provide some results from the application of the new framework to physical space mesh refinement.,In recent work we have shown how an accurate reduced model can be utilized to perform mesh refinement in random space.,"Moreover, the current framework can be applied for refinement in both random and physical space."
10.1016/j.jcp.2012.04.044,Sampling-free linear Bayesian update of polynomial chaos representations (2012),"We present a fully deterministic approach to a probabilistic interpretation of inverse problems in which unknown quantities are represented by random fields or processes, described by possibly non-Gaussian distributions.","The description of the introduced random fields is given in a ""whitenoise"" framework, which enables us to solve the stochastic forward problem through Galerkin projection onto polynomial chaos.",,,
10.1016/j.jhydrol.2014.05.027,Constructive epistemic modeling of groundwater flow with geological structure and boundary condition uncertainty under the Bayesian paradigm (2014),"Third, the hierarchical representation of the between-model variance facilitates the prioritization of the contribution of each uncertain model component to the overall model uncertainty.",We consider four uncertain model components.,"Second, systemic model dissection is imperative for understanding the individual contribution of each uncertain model component to the model prediction and variance.","Using hierarchical Bayesian model averaging (BMA), this study shows that segregating different uncertain model components through a BMA tree of posterior model probability, model prediction, within-model variance, between-model variance and total model variance serves as a learning tool.","Through combinatorial design, these four uncertain model components with their candidate propositions result in  base models."
10.1016/j.jcp.2016.03.018,Bayesian analysis of rare events (2016),"In many areas of engineering and science there is an interest in predicting the probability of rare events, in particular in applications related to safety and security.","It ensures a consistent probabilistic treatment of uncertainty, which is central in the prediction of rare events, where extrapolation from the domain of observation is common.",Bayesian analysis is the ideal method to include the data into the probabilistic model.,"We present a framework for performing Bayesian updating of rare event probabilities, termed BUS.","By drawing upon these methods, the framework makes use of their computational efficiency."
10.1016/j.jhydrol.2015.12.031,Spatial probabilistic multi-criteria decision making for assessment of flood management alternatives (2016),"The framework employs a probabilistic rainfall-runoff transformation model, a two-dimensional flood model and a spatial MCDM technique.",Overall the best at each grid cell is the alternative with the mode parameter of this PDF.,"While the deterministic framework fails to provide the uncertainty of selecting an alternative, the SPMCDM framework showed that in overall, selection of flood management alternatives in the watershed is ""moderately uncertain"".",It is thus important to incorporate the uncertainty of flood parameters into the decision making frameworks.,"Thereby, the uncertainty of decision making can be determined alongside the best alternative."
10.1016/j.envsoft.2013.09.016,"Reducing the impact of model scale on simulated, gridded switchgrass yields (2014)","Spatial bias of the regional mean is relatively consistent for resolutions <=  arcsec (similar to  km) (AMAY bias <%), and larger AMAY biases (-%) at coarse resolutions indicate poorly characterized spatial heterogeneity.",Spatial bias of the regional mean significantly increases with increasing cell size for  of  measurement dates.,"Results of gridded ecosystem simulations of bioenergy crops are used for estimating economic viability, environmental impacts, and potential land use change.",The range of RMSEBC for -year Average Mature August Yield (AMAY) is - g C m(-) across - to -arcsec resolution (similar to  m- similar to  km) with biases from  to  g C m(-).,"Including the % confidence interval around bias-corrected values, AMAY ranges from  to  g C m(-) across a -arsec grid, which is similar to the range reported for  eastern United States field sites."
10.1016/j.cma.2011.03.016,"A comprehensive framework for verification, validation, and uncertainty quantification in scientific computing (2011)",The different steps in the predictive uncertainty framework are illustrated using a simple example in computational fluid dynamics applied to a hypersonic wind tunnel.,"The framework is comprehensive in the sense that it treats both types of uncertainty (aleatory and epistemic), incorporates uncertainty due to the mathematical form of the model, and it provides a procedure for including estimates of numerical error in the predictive uncertainty.",An overview of a comprehensive framework is given for estimating the predictive uncertainty of scientific computing applications.,"Finally, methods for conveying the total predictive uncertainty to decision makers are presented.",Approaches for propagating both types of uncertainties through the model to the system response quantities of interest are briefly discussed.
10.1007/s00158-010-0537-3,Parallel solution of contact shape optimization problems based on Total FETI domain decomposition method (2010),Theoretical results which prove asymptotically linear complexity of the solution are reported and documented by numerical experiments.,"A unique feature of the TFETI algorithm is its capability to solve large contact problems with optimal, i.e., asymptotically linear complexity.",The results of numerical solution of a D contact shape optimization problem confirm the high degree of parallelism of the algorithm.,We show that the algorithm is even more efficient for the solution of the contact shape optimization problems as it can exploit effectively a specific structure of the auxiliary problems arising in the semi-analytic sensitivity analysis.,
10.1016/j.envsoft.2016.10.011,Combined analysis of time-varying sensitivity and identifiability indices to diagnose the response of a complex environmental model (2017),"In this study, we performed a temporal global sensitivity analysis using the variance-based method of Sobol' and a temporal identifiability analysis of model parameters using the dynamic identifiability method (DYNIA).",We found that identifiability of a parameter does not necessarily reduce output uncertainty.,"Overall, the study highlights the role of combined temporal diagnostic tools for improving our understanding of model behavior.",,
10.1007/s00158-016-1623-y,Topology optimization considering fracture mechanics behaviors at specified locations (2017),"Based on the linear elastic fracture mechanics model (LEFM), the stress intensity of initial cracks in the structure is analyzed by using singularity finite elements positioned at the crack tip to describe the near-tip stress field.",This method provides an applicable framework incorporating linear fracture mechanics criteria into topology optimization for conceptual design of crack insensitive or easily detachable structures for particular applications.,Numerical examples are given to demonstrate effectiveness of the proposed method on generating structures with desired overall stiffness and fracture strength property.,,
10.1016/j.envsoft.2016.06.029,Development and preliminary evaluation of an integrated field scale model for perennial bioenergy grass ecosystems in lowland areas (2016),The model also accurately predicted temporal dynamics of daily soil moisture and temperature with Nash-Sutcliffe coefficients of .,Results showed that the model accurately predicted  -year (-) biomass yield.,"This study developed an integrated, field scale, and process-based ecosystem model (DRAINMOD-GRASS) for simulating hydrological processes, soil carbon and nitrogen cycling, and plant growth in cropping systems for producing bioenergy grasses in lowland areas.",,
10.1016/j.jcp.2010.03.003,Numerical approach for quantification of epistemic uncertainty (2010),Aleatory uncertainty can be characterised by known probability distributions whilst epistemic uncertainty arises from a lack of knowledge of probabilistic information.,We discuss solution strategies for solving the encapsulation problem and the sufficient conditions under which the numerical solution can serve as a good estimator for capturing the effects of the epistemic uncertainty.,Several numerical examples are presented to demonstrate the procedure and properties of the proposed methodology.,"In this paper, we propose a numerical framework for quantification of epistemic uncertainty.","To quantify the epistemic uncertainty, we solve an encapsulation problem, which is a solution to the original governing equations defined on the estimated range of the input variables."
10.1007/s00158-010-0530-x,Technical overview of the equivalent static loads method for non-linear static response structural optimization (2011),An analysis that is not linear static is carried out to evaluate the displacement field.,The ESL is defined as the static load that generates the same displacement field by an analysis which is not linear static.,"In this paper, the methods are completely overviewed.","The disciplines include linear dynamic response optimization, structural optimization for multi-body dynamic systems, structural optimization for flexible multi-body dynamic systems, nonlinear static response optimization and nonlinear dynamic response optimization.","ESLs are evaluated from the displacement field, linear static response optimization is performed by using the ESLs, and the design is updated."
10.1007/s00158-016-1467-5,An immersed boundary approach for shape and topology optimization of stationary fluid-structure interaction problems (2016),"Numerical results indicate that the proposed treatment of free-floating volumes introduces a discontinuity in the design evolution, yet the method is still successful in converging to meaningful designs.",The design sensitivities are computed by the adjoint method and the optimization problem is solved by a gradient-based algorithm.,"This approach allows for topological changes of the fluid-structure interface, but free-floating volumes of solid material can emerge in the course of the optimization process.",The characteristics of this optimization framework are studied with two-dimensional problems at steady state.,The free-floating volumes are tracked and modeled as fluid in the FSI analysis.
10.1016/j.jcp.2005.08.024,Fast and reliable methods for determining the evolution of uncertain parameters in differential equations (2006),"For example, such variations may describe the effect of experimental error or may arise as part of a sensitivity analysis of the model.","It does, however, require many evaluations of the operator and it is difficult to extract precise information about the accuracy of any particular result.",A very common problem in science and engineering is the determination of the effects of uncertainty or variation in parameters and data on the output of a deterministic nonlinear operator.,These techniques employ the generalized Green's function to describe how variation propagates into the solution around localized points in the parameter space.,"In this paper, we borrow techniques from a posteriori error analysis for finite element methods to compute information about the derivative of an operator with respect to its parameters."
10.1016/j.cma.2005.03.015,Inverse analysis for identification of rheological and friction models in metal forming (2006),"It is shown in the paper that, in general, when inverse analysis is applied the results of identification are insensitive to the type of the test, sample dimensions etc.",It is observed that the plane strain compression test is the least sensitive to the errors in evaluation of the friction coefficient.,It is emphasized that drawing the general conclusion regarding the best optimization strategy for the inverse analysis is difficult.,"On the other hand, when friction coefficient is identified, the ring compression is almost not sensitive to the evaluation of the flow stress of the material.","The second aspect of the analysis focused on evaluation of sensitivity of the results of the inverse analysis with respect to the coefficients, which are assumed in the calculations."
10.1016/j.cma.2006.08.005,A level set method for topology optimization of heat conduction problem under multiple load cases (2007),This framework is based on the theories of topological derivative and shape derivative for elliptic system.,The shape of material domain is treated as the design variable and the final result is achieved by updating level set function gradually.,In this paper we present a numerical approach of topology optimization under multiple load cases for heat conduction problem.,Numerical examples demonstrate that our proposed approach is effective and robust for topology optimization of heat conduction problem.,
10.1016/j.jcp.2014.10.020,A heterogeneous stochastic FEM framework for elliptic PDEs (2015),We also provide a sampling method to construct the local stochastic basis for this framework using the randomized range finding techniques.,"The resulting HSFEM involves two stages and suits the multi-query setting: in the offline stage, the local stochastic structure of the solution space is identified; in the online stage, the equation can be efficiently solved for multiple forcing functions.",,,
10.1007/s00158-017-1664-x,Piecewise point classification for uncertainty propagation with nonlinear limit states (2017),"In PPC, the first-order reliability method (FORM) is initially employed to search the most probable point.","With all the points evaluated during the search process, a distance-based piecewise point classification method is developed as a classifier to predict failure events.",,,
10.1016/j.cma.2009.06.015,Goal-oriented r-adaptivity based on variational arguments in the physical and material spaces (2009),We propose a goal-oriented mesh optimization algorithm which ends in an optimized mesh with respect to a chosen quantity of interest.,These residuals are error indicators for the discretization error on the current mesh.,The error in a local quantity of interest depends on the error in the corresponding dual solution or generalized Green's function.,"The minimization of the energy of the primal problem as well as the minimization of the energy of the dual problem with respect to a design function lead to the primal and dual material residuals, respectively.",This fact is used in dual-weighted based goal-oriented error estimation techniques and h- or p-adaptive algorithms.
10.1016/j.jhydrol.2015.12.001,Pareto-based efficient stochastic simulation-optimization for robust and reliable groundwater management (2016),"The primary objective of optimization is maximization of the total volume of water injected into a confined aquifer, subject to the constraints that the resulting increases in hydraulic head in a set of control bores are below specified target levels.",Results of the comparison indicate potential gains in efficiency of the stochastic multi-objective formulation to identify robust and reliable groundwater management strategies.,Simulation-optimization methods are used to develop optimal solutions for a variety of groundwater management problems.,"Reliability analysis using post optimization Monte Carlo analysis proved that while a stochastic single objective optimization failed to provide reliable solutions with a stack size of , the proposed method resulted in many robust solutions with high reliability close to ..","In this study, we present a stochastic multi-objective formulation of the otherwise single objective groundwater optimization problem by considering minimization of prediction uncertainty as an additional objective."
10.1016/j.envsoft.2016.02.008,Sensitivity analysis of environmental models: A systematic review with practical workflow (2016),Sensitivity Analysis (SA) investigates how the variation in the output of a numerical model can be attributed to variations of its input factors.,(C)  The Authors.,"The paper aims at delivering an introduction to SA for non-specialist readers, as well as practical advice with best practice examples from the literature; and at stimulating the discussion within the community of SA developers and users regarding the setting of good practices and on defining priorities for future research.",,
10.1007/s00158-015-1328-7,Dynamic response topology optimization in the time domain using model reduction method (2016),"So for practical applications, when the problem needs many time steps, the MAM based approach is preferred and otherwise, the direct integration based approach is suggested.","The dynamic response topology optimization problems are usually computationally expensive, so it is necessary to employ the model reduction methods to reduce computational cost.",This work will investigate the effectiveness of the mode displacement method(MDM) and mode acceleration method(MAM) for time-domain response problems within the framework of density-based topology optimization.,,
10.1016/j.jcp.2016.03.026,Adaptive surrogate modeling by ANOVA and sparse polynomial dimensional decomposition for global sensitivity analysis in fluid simulation (2016),surrogate model) by employing the sparse PDD approach with its coefficients computed by regression.,"Unfortunately, the number of PDD terms grows exponentially with respect to the size of the input random vector, which makes the computational cost of standard methods unaffordable for real engineering applications.","In order to address the problem of the curse of dimensionality, this work proposes essentially variance-based adaptive strategies aiming to build a cheap metamodel (i.e.",,
10.1016/j.jcp.2017.01.047,Multi-fidelity Gaussian process regression for prediction of random fields (2017),"Our method builds upon recent work on recursive Bayesian techniques, in particular recursive co-kriging, and extends it to vector-valued fields and various types of covariances, including separable and non-separable ones.",We propose a new multi-fidelity Gaussian process regression (GPR) approach for prediction of random fields based on observations of surrogate models or hierarchies of surrogate models.,"Specifically, we study the stochastic Burgers equation and the stochastic Oberbeck-Boussinesq equations describing natural convection within a square enclosure.",We demonstrate the effectiveness of the proposed recursive GPR techniques through various examples.,
10.1016/j.jhydrol.2005.04.010,Sensitivity analysis of a catchment-scale nitrogen model (2005),"The results indicate the general, difficulty of reconciling the questions which catchment nutrient models are expected to answer with typically limited data sets and limited knowledge about suitable model structures.",There are now considerable expectations that semi-distributed models are useful tools for supporting catchment water quality management.,"uncertainty in initial conditions, residence times and nitrogen transformation parameters, and long-term historic data are needed so that key responses to changes in land-use management can be assimilated.","However, insufficient attention has been given to evaluating the uncertainties inherent to this type of model, especially those associated with the spatial disaggregation of the catchment.",
10.1007/s00158-008-0316-6,Optimization of dynamic response using a monolithic-time formulation (2009),"Furthermore, the response is captured in a higher order manner to increase analysis accuracy.","In this paper, we investigate the application of a temporal spectral element method to the optimization of transient and time-periodic responses of fundamental engineering systems.","The first application, a one-degree-of-freedom, linear, impact absorber, is selected from the auto industry, and tests the ability of the method to treat transient constraints over a large-time interval.",The design of systems for dynamic response may involve constraints that need to be satisfied over an entire time interval or objective functions evaluated over the interval.,Two applications of the coupling of dynamic response optimization with the temporal spectral element method are demonstrated.
10.1007/s00158-015-1234-z,Predictive quantification of surrogate model fidelity based on modal variations with sample density (2015),The median and the maximum errors estimated over the remaining points are used to determine the respective error distributions at each iteration.,"This paper introduces a new model-independent approach to quantify surrogate model fidelity, called Predictive Estimation of Model Fidelity (PEMF).",It is generally challenging to quantify the fidelity of surrogate models without additional system evaluations.,These regression functions are then used to predict the expected median and maximum errors in the final surrogate model (trained using all available sample points).,"The estimated modes of the error distributions are represented as functions of the density of intermediate training points through nonlinear regression, assuming a smooth decreasing trend of errors with increasing sample density."
10.1007/s00158-013-0935-4,A critical comparative assessment of differential equation-driven methods for structural topology optimization (2013),Implicit level-set methods are one such set of approaches in which the design domain is represented in terms of implicit functions and generally (but not necessarily) use the Hamilton-Jacobi equation as the evolution equation.,"In this work, we exhaustively analyze four level-set methods and one phase-field method, which are representative of the literature.","In such methods, the design is evolved using special differential equations.","Another set of approaches are referred to as phase-field methods; which generally use a reaction-diffusion equation, such as the Allen-Cahn equation, for topology evolution.",
10.1016/j.cma.2003.09.007,Sensitivity evaluation in seismic reliability analysis of structures (2004),Most of these works concentrate on sensitivity analysis of static and dynamic structural responses under deterministic forcing function.,The present paper deals with the important issue of response sensitivity evaluation of structures in seismic reliability evaluation.,Sensitivity evaluation of response under static and dynamic load is proved to be an essential part of the optimization and reliability analysis of structure.,The formulation has been developed in double frequency domain to tackle non-stationary earthquake motion for obtaining the analytical sensitivity statistics of various dynamic response quantities with respect to structural parameters.,A multistoried building frame has been studied to elucidate the proposed algorithm.
10.1007/s001580050083,A simulation-based comparison of multidisciplinary design optimization solution strategies using CASCADE (2000),"IDF assures that each individual discipline is feasible on every design cycle, while driving the entire system (all disciplines) towards multidisciplinary feasibility.","This design cycle is standard in the field of Multi-disciplinary Design Optimization (MDO) and has of ten been referred to in the literature as the ""Multiple-Discipline-Feasible"" (MDF) approach.",The name stems from the fact that complete multidisciplinary feasibility is maintained in each and every design cycle.,"One such solution procedure has been referred to both as ""Simultaneous Analysis and Design"" (SAND) and ""All-at-Once"" (AAO), and treats the entire multidisciplinary design cycle as one large optimization problem, Another alternate solution procedure has been referred to as ""Individual-Discipline-Feasible"" (IDF); this procedure exhibits characteristics which lie in between the two extremes exemplified by MDF and AAO.",The present work will present a rigorous numerical comparison of these solution strategies over a wide variety of problem sizes and complexities.
10.1016/j.envsoft.2017.06.015,Performance evaluation of real time control in urban wastewater systems in practice: Review and perspective (2017),"In a case study for a combined sewer system with limited discharge to aWWTP, it is demonstrated that the successful application of RTC and the possibility to determine a significant effect is very much dependent on the goal.","A general methodology to evaluate the performance of RTC in practice, that takes into account these deficiencies, is proposed.",It also clearly illustrates the need for taking uncertainties into account and that careful consideration in the chosen evaluation period is required.,A literature review on the performance evaluation of RTC demonstrated a lack of consensus on how to do this.,
10.1016/j.jcp.2017.09.040,Topology optimization of hyperelastic structures using a level set method (2017),"Soft rubberlike materials, due to their inherent compliance, are finding widespread implementation in a variety of applications ranging from assistive wearable technologies to soft material robots.","As the design velocity enters into the shape derivative in terms of its gradient and divergence terms, we develop a discrete velocity selection strategy.","In this paper, we present an effective level set-based topology optimization method for the design of hyperelastic structures that undergo large deformations.",Structural design of such soft and rubbery materials necessitates the consideration of large nonlinear deformations and hyperelastic material models to accurately predict their mechanical behaviour.,"To demonstrate the validity and effectiveness of the proposed method, three compliance minimization problems are studied and their optimized solutions present significant mechanical benefits of incorporating the nonlinearities, in terms of remarkable enhancement in not only the structural stiffness but also the critical buckling load."
10.1016/j.jcp.2004.10.011,Adjoint sensitivity analysis of regional air quality models (2005),The task of providing an optimal analysis of the state of the atmosphere requires the development of efficient computational tools that facilitate an efficient integration of observational data into models.,"In this paper, we discuss the mathematical foundations of the adjoint sensitivity method applied to air pollution models, and present a complete set of computational tools for performing three-dimensional adjoint sensitivity studies.",Adjoint sensitivity is a complementary approach which efficiently calculates the derivatives of a functional with respect to a large number of parameters.,,
10.1016/j.jcp.2010.06.016,Hierarchical Bayesian inference for Ill-posed problems via variational method (2010),"The framework is of variational type, and it can deliver the inverse solution and regularization parameter together with their uncertainties calibrated.","Two approximations are derived within the framework, and some theoretical properties, e.g.",A hierarchical formulation which determines automatically the regularization parameter and the noise level together with the inverse solution is adopted.,It approximates the posteriori probability distribution by separable distributions based on Kullback-Leibler divergence.,
10.1016/j.envsoft.2007.09.014,Development and testing of a terrain-based hydrologic model for spatial Hortonian Infiltration and Runoff/On (2008),"The model can handle input rainfall, soil parameters, and other properties that vary in space and time.","The coefficients of efficiency for runoff volume, peak flow, and time to peak flow with respect to calibration/validation are ./., ./., and ./., respectively.",Computation of ponding time was included to handle variable run-on and rainfall intensity.,A routing hierarchy was defined over the watershed using the D-infinity contributing area algorithm.,The open-source model is provided for space-time simulation and scaling of event-based Hortonian runoff and infiltration.
10.1016/j.envsoft.2008.12.006,Estimating storm discharge and water quality data uncertainty: A software tool for monitoring and modeling applications (2009),"For storm loads, the uncertainty was typically least for discharge (+/- -%), greater for sediment (+/- -%) and dissolved N and P (+/- -%) loads, and greater yet for total N and P (+/- -%).",Hydrologic and water quality data are too important for scientists to continue to ignore the inherent uncertainty.,"With these benefits in mind, the Data Uncertainty Estimation Tool for Hydrology and Water Quality (DUET-H/WQ) was developed from an existing uncertainty estimation framework for small watershed discharge, sediment, and N and P data.",When these uncertainty estimates for individual values were aggregated within study periods (i.e.,"DUET-H/WQ lists published uncertainty information for data collection procedures to assist the user in assigning appropriate data-specific uncertainty estimates and then calculates the uncertainty for individual discharge, concentration, and load values."
10.1016/j.jhydrol.2017.02.053,Representing radar rainfall uncertainty with ensembles based on a time-variant geostatistical error modelling approach (2017),The errors are estimated using a network of  tipping bucket rain gauges from the Environment Agency.,The method is developed to meet the requirement of operational applications to large datasets.,(C)  The Authors.,"Although radar errors have been widely studied and techniques have been developed to correct most of them, residual errors are still intrinsic in radar QPE.",A suitable tool for this purpose is the generation of radar rainfall ensembles.
10.1016/j.jhydrol.2006.03.033,Water quality modeling under hydrologic variability and parameter uncertainty using erosion-scaled export coefficients (2006),Water quality modeling is important to assess the health of a watershed and to make necessary management decisions to control existing and future pollution of receiving water bodies.,Here sediment discharge was introduced into the export coefficient model as a surrogate for hydrologic variability.,"Application of this approach to model P in the Fishtrap Creek of Washington State showed the superiority of this approach compared to the traditional export coefficient approach, white maintaining its simplicity and low data requirement characteristics.","This work also showed through a joint variability-uncertainty analysis the importance of separate consideration of hydrologic variability and parameter uncertainty, as these represent two independent and important characteristics of the overall model uncertainty.","The existing export coefficient approach is attractive due to minimum data requirements; however, this method does not account for hydrologic variability."
10.1016/j.envsoft.2015.11.001,Robust global sensitivity analysis under deep uncertainty via scenario analysis (2016),The influence of this deep (i.e.,We then developed sensitivity indicators that were robust to this deep uncertainty using four criteria from decision theory.,"Using a variance-based global sensitivity analysis method (eFAST), we produced comprehensive model diagnostics of a complex social-ecological systems model under deep uncertainty characterised by four global change scenarios.",Complex social-ecological systems models typically need to consider deeply uncertain long run future conditions.,"incalculable, uncontrollable) uncertainty on model parameter sensitivities needs to be understood and robustly quantified to reliably inform investment in data collection and model refinement."
10.1007/s00158-003-0336-1,Order-(n plus m) direct differentiation determination of design sensitivity for constrained multibody dynamic systems (2004),The algorithm determines the derivatives of generalized accelerations in O(n+m) operations overall.,"Most current direct differentiation approaches suffer from prohibitive computational cost, which may be as great as O(n()+n()m()+nm()) (for systems with n generalized coordinates and m algebraic constraints).",,,
10.1016/j.envsoft.2014.11.013,A multi-criteria trajectory-based parameter sampling strategy for the screening method of elementary effects (2015),"The SU performed better than some trajectory-based benchmark strategies across the evaluation criteria, underlining the effectiveness of multi-criteria based sampling and the need to focus future efforts on exploring other combinations of sampling criteria.",Environmental models are inherently complex and often characterized by high dimensionality.,The method of elementary effects (EE) is one of the most widely used parameter screening technique implemented to reduce burden on computational resources required for thorough model evaluation.,This paper presents a new sampling strategy - Sampling for Uniformity (SU) - based on the principles of meeting close-to-theoretical parameter distributions and maximizing trajectory spread.,
10.1016/j.envsoft.2014.09.017,An overview of methods to evaluate uncertainty of deterministic models in decision support (2015),The best way to evaluate the uncertainty depends on the definitions of the source models and the amount and quality of information available to the modeller.,(C)  The Authors.,We review various methods that have been or could be applied to evaluate the uncertainty related to deterministic models' outputs.,"To achieve this, efficient decision support integrates the results of pre-existing models.","There is an increasing need for environmental management advice that is wide-scoped, covering various interlinked policies, and realistic about the uncertainties related to the possible management actions."
10.1007/s00158-002-0213-3,Efficient optimization of a noise transfer function by modification of a shell structure geometry - Part I: Theory (2002),"In the early stages of vehicle body development trends for the acoustic behaviour of the whole vehicle are, on the one hand, of great importance, but difficult to achieve.",This paper starts with a review of structural acoustic sensitivity analysis and optimization.,Part II presents the design optimization of a sedan dashboard.,"Geometry based, parametric model descriptions and optimization techniques enable the engineer to find out these trends.","Finally, a section on sensitivity analysis presents a numerical and a semianalytic method."
10.1016/j.jhydrol.2008.05.012,Comparing uncertainty analysis techniques for a SWAT application to the Chaohe Basin in China (2008),"As these techniques are different in their philosophies and leave the user some freedom in formulating the generalized likelihood measure, objective function, or likelihood function, a literal comparison between these techniques is not possible.","We compared the results with respect to the posterior parameter distributions, performances of their best estimates, prediction uncertainty, conceptual bases, computational efficiency, and difficulty of implementation.",For this reason it is important that these models pass through a careful calibration and uncertainty analysis.,,
10.1016/j.jcp.2015.03.045,Numerical method of characteristics for one-dimensional blood flow (2015),Theoretical analysis of the algorithm is given along with a comparison of our method to a discontinuous Galerkin implementation.,We address both cost and stability by presenting an efficient and unconditionally stable method for approximating solutions to diagonal nonlinear hyperbolic systems.,,,
10.1007/s00158-017-1651-2,Temporal and spatial multi-parameter dynamic reliability and global reliability sensitivity analysis based on the extreme value moments (2017),"Secondly, three-point estimation is used to evaluate the global dynamic reliability sensitivity by combining with the dynamic failure probability method.",This issue is efficiently addressed by solving the differential equations satisfying the extreme value condition.,One strategy is combining sparse grid technique for the extreme value moments with the fourth-moment method for the dynamic failure probability.,Another is combining dimensional reduction method for fractional extreme value moments and the maximum entropy for dynamic failure probability.,The significance and the effectiveness of the proposed methods for estimating the temporal and spatial multi-parameter dynamic reliability and global sensitivity indices are demonstrated with several examples.
10.1016/S0022-1694(02)00138-5,Advanced flood forecasting in Alpine watersheds by coupling meteorological observations and forecasts with a distributed hydrological model (2002),The Alpine Ticino-Verzasca-Maggia basin ( km()) is located directly to the south of the main Alpine ridge embracing a great part of the drainage area of Lago Maggiore.,"In order to evaluate the various hydrological model results as generated from the different outputs from the five NWP models, some coupled experiments with 'non-standard' NWP model outputs have been carried out.",,,
10.1016/j.envsoft.2007.06.002,Autocalibration in hydrologic modeling: Using SWAT2005 in small-scale watersheds (2008),An autocalibration- sensitivity analysis procedure was embedded in SWAT version  (SWAT) to optimize parameter processing.,"Due to many of the processes involved in the manual- or autocalibration of model parameters and the knowledge of realistic input values, calibration can become difficult.",The disparity is most likely due to the limited number of parameters that are included in this version of the autocalibration tool (i.e.,"Overall, SWAT simulated the hydrology and the water quality constituents at the subwatershed-scale more adequately when all of the available observed data were used for model simulation as evidenced by statistical measure when both the autocalibration and manually adjusted parameters were used in the simulation.",This embedded procedure is applied to six small-scale watersheds (subwatersheds) in the central Texas Blackland Prairie.
10.1007/s00158-011-0720-1,A superelement formulation for the efficient layout design of complex multi-component system (2012),"In the iterative design process, each component is modelled as a movable superelement so that the sensitivity analysis with respect to the location design variables can be largely simplified by the SEF.","By means of numerical examples, these approaches are compared to show their capability and efficiency for the system compliance minimization.","Moreover, based on the Kuhn-Tucker optimality condition, two decomposition strategies are developed as variant approaches for the simultaneous design of multi-component system.",,
10.1016/j.jcp.2016.07.038,"Quantifying and reducing model-form uncertainties in Reynolds-averaged Navier-Stokes simulations: A data-driven, physics-informed Bayesian approach (2016)","An iterative ensemble Kalman method is used to assimilate the prior knowledge and observation data in a Bayesian framework, and to propagate them to posterior distributions of velocities and other Quantities of Interest (QoIs).",Both cases are challenging for standard RANS turbulence models.,"Simulation results suggest that, even with very sparse observations, the obtained posterior mean velocities and other QoIs have significantly better agreement with the benchmark data compared to the baseline results.","As RANS models are used in the design and safety evaluation of many mission-critical systems such as airplanes and nuclear power plants, quantifying their model-form uncertainties has significant implications in enabling risk-informed decision-making.","The framework is a major improvement over existing black-box, physics-neutral methods for model-form uncertainty quantification, where prior knowledge and details of the models are not exploited."
10.1007/s00158-016-1586-z,Sensitivity reanalysis of vibration problem using combined approximations method (2017),"Especially, this method can greatly improve the efficiency of sensitivity analysis and can accelerate the gradient-based structural optimization constrained with frequencies and modal shapes.",Numerical examples demonstrate the accuracy and efficiency of the proposed reanalysis method.,This paper focuses on the analytical sensitivity reanalysis for vibration problem in the framework of combined approximations (CA) method.,Sensitivity is indispensable to structural modification and optimization.,
10.1016/j.jhydrol.2007.11.033,"Plot scale continuous modelling of runoff in a maize cropping system with dynamic soil, surface properties (2008)",The results of the model were compared with runoff measurements taken over two years on  m() runoff plots in a continuous maize cropping system with and without winter cover crop.,and poor to reasonable fits for the maize period (Nash-Sutcliffe efficiency coefficient from Less than  up to .).,,,
10.1016/j.envsoft.2016.09.022,A probabilistic framework for comparison of dam breach parameters and outflow hydrograph generated by different empirical prediction methods (2016),The multivariate analysis also indicates that lone use of breach parameters is not necessarily sufficient to characterize outflow hydrograph attributes.,"Mean values and percentiles of breach parameters and outflow hydrograph attributes are compared for hypothetical overtopping failure of Burnett Dam in the state of North Carolina, USA.",,,
10.1007/s00158-016-1405-6,Accelerated failure identification sampling for probability analysis of rare events (2016),"Critical engineering systems generally demand high reliability while considering uncertainties, which makes failure event identification and reliability analysis based on computer simulation codes computationally very expensive.",Two case studies are used to demonstrate the effectiveness of the developed AFIS approach for rare events identification and probability analysis.,"Third, the identified sample points with highest failure potentials are evaluated for the true performance and then used to update the GP model.",,
10.1016/j.cma.2016.10.030,An efficient stochastic framework to propagate the effect of the random solid-pore geometry of porous media on the pore-scale flow (2017),"A pore-scale modelling of flow through porous media samples, by simulating the incompressible Navier-Stokes equation in the pore spaces by employing the Lattice Boltzmann method has been taken up in the present study.",The proposed integrated MCS-KL approach has been utilized successfully in the present work to propagate their effect on the pore-scale velocity field.,The modelling of the input randomness also has an element of novelty in the present work as it directly captures the random solid-pore arrangement of the media geometry instead of any macro properties.,Simulating the pore-scale flow-field past porous media samples is a computationally expensive exercise.,"The resulting, process is weakly correlated and needs a very large number of input random variables to capture its higher frequency content."
10.1016/j.cma.2008.03.024,Microbeam pull-in voltage topology optimization including material deposition constraint (2008),The proposed sensitivity analysis requires only the knowledge of the microdevice pull-in state and of the first eigen-mode of the tangent stiffness matrix.,The present paper investigates the application of topology optimization to electromechanical microdevices for the purpose of delaying this unstable behavior by maximizing their pull-in voltage.,An application of the developed method is proposed and the result is compared to the one obtained using a linear compliance optimization.,,
10.1007/s00158-014-1128-5,Development and validation of a dynamic metamodel based on stochastic radial basis functions and uncertainty quantification (2015),"A dynamic radial basis function (DRBF) metamodel is derived and validated, based on stochastic RBF and uncertainty quantification (UQ).","The number of high-fidelity evaluations required to achieve prescribed error levels is considered as the efficiency metric, focusing on fitting accuracy and UQ variables.",A metric for assessing metamodel efficiency is developed and used.,"Auto-tuning based on curvature, adaptive sampling based on prediction uncertainty, parallel infill, and multiple response criteria are used.","The validation includes comparisons with a dynamic implementation of Kriging (DKG) and static metamodels for both deterministic test functions (with dimensionality ranging from two to six) and industrial UQ problems with analytical and numerical benchmarks, respectively."
10.1016/j.cma.2012.06.005,Sensitivity analysis with the modified Heaviside function for the optimal layout design of multi-component systems (2012),"As a result, analytical sensitivities with respect to location design variables are achieved as easily as for pseudo-density variables.",Two kinds of design variables.,"Due to the geometric perturbation of the finite element mesh, the latter can then be regarded as a geometric perturbation model (GPM).",The computing efficiency is thus improved because the velocity field for the mesh perturbation in the semi-analytical scheme is no longer needed.,"In this paper, we propose a material perturbation model (MPM) using fixed finite element (FE) mesh for sensitivity analysis with respect to location design variables."
10.1016/j.envsoft.2009.03.003,Urban runoff modelling uncertainty: Comparison among Bayesian and pseudo-Bayesian methods (2009),Urban stormwater quality modelling plays a central role in evaluation of the quality of the receiving water body.,The uncertainty assessment of the models enabled evaluation of the advantages and limitations of the three methodologies adopted.,"The models were then tested using the quantity-quality data gathered for the Fossolo catchment in Bologna, Italy.","Uncertainty analysis was then conducted using three different methods: the Bayesian Monte Carlo method, the GLUE pseudo-Bayesian method and the GLUE method revised by means of a formal distribution of residuals between the model and measured data (GLUE_f).",This study was conducted to assess modelling uncertainty associated with catchment surface pollution evaluation.
10.1016/j.cma.2016.10.024,Bayesian identification of the tendon fascicle's structural composition using finite element models for helical geometries (2017),We establish a link between the fiber and the fascicle tendon scale and identify an appropriate range of mechanically compatible material and geometric properties to quantify the tendon properties.,The finite element model is optimized for helical geometries to reduce the computational cost associated with the Bayesian inference.,Here we infer the structural compositions of tendons by coupling a finite element model with fascicle experimental data through a Bayesian uncertainty quantification framework.,,
10.1016/j.cma.2013.10.022,Failure mitigation in optimal topology design using a coupled nonlinear continuum damage model (2014),"The optimization problem is parameterized using SIMP variables, and failure mitigation is achieved through the enforcement of constraints on the maximum local damage intensity.",A quasi-static non-local brittle damage model is coupled to a linear finite element analysis code for modeling the structural response and the initiation and propagation of damage.,The algorithm is validated through a series of numerical examples.,,
10.1016/j.cma.2008.12.032,Optimal discretization strategy for boundary element-based shape optimization problem (2009),This paper deals with the development of a discretization strategy that minimizes the total computing time for solving shape optimization problems in linearly elastic systems.,It employs a combination of boundary elements for integration of the governing differential equations and a first-order optimization algorithm.,,,
10.1007/s00158-008-0283-y,Boundary element sensitivity evaluation for elasticity problems using complex variable method (2009),"The complex variable method is used to evaluate sensitivities in two-dimensional elasticity problems, using the BEM as numerical method.","The method shows negligible dependency on the perturbation magnitude, and can be easily incorporated to existing codes which handle complex algebra.",,,
10.1016/j.cma.2016.05.016,Multi-material topology optimization considering interface behavior via XFEM and level set method (2016),"In the topology optimization model, the normal velocities defined on the level set points are considered as design variables.",This paper presents an efficient multi-material topology optimization strategy for seeking the optimal layout of structures considering the cohesive constitutive relationship of the interface.,"This enables modeling of possible separation of material interfaces, and thus provides a more realistic model of multi-material structures.",This topology optimization technique can handle multiple constraints easily in the framework of level set method and at the same time preserve the signed distance property of the level set functions.,"In conjunction with the adjoint-variable sensitivity analysis, these design variables are updated by using the mathematical programming approach and then used to interpolate the boundary velocities."
10.1016/j.envsoft.2013.10.017,Global sensitivity analysis of yield output from the water productivity model (2014),The study rationale consisted in a comprehensive evaluation of the model and the formulation of guidelines for model simplification and efficient calibration.,"Also, a list of influential parameters was identified.","The main objectives were to distinguish the model's influential and non-influential parameters, and to examine the yield output sensitivity.",This study includes a global sensitivity analysis of the water productivity model AquaCrop.,"Instead, particular root and soil parameters, relevant in the determination of water availability, were influential under various conditions and merit attention during calibration."
10.1016/S0022-1694(01)00437-1,Impact of imperfect rainfall knowledge on the efficiency and the parameters of watershed models (2001),"These models are able to cope with imperfect rainfall input estimates, and react to improvements in rainfall input accuracy by better performance and reduced variability of efficiency.","It is crucial to analyze the sensitivity of watershed (rainfall-runoff) models to imperfect knowledge of rainfall input, in order to judge whether or not they are reliable and robust,.",especially if they are to be used for operational purposes.,"In this paper, a new approach to sensitivity analysis is proposed, based on a comparison between the efficiency ratings and parameter values of the models and the quality of rainfall input estimate (GORE and BALANCE indexes, assessing the quality of rainfall time distribution and the total depth respectively).","Although the watershed size seems to be immaterial, the smaller watersheds appear to need more precise areal rainfall estimates (a higher concentration of raingages) to ensure good modeling results."
10.1016/j.jcp.2016.04.029,Reduced basis ANOVA methods for partial differential equations with high-dimensional random inputs (2016),The ANOVA method combined with stochastic collocation methods provides model reduction in high-dimensional parameter space through decomposing high-dimensional inputs into unions of low-dimensional inputs.,"In this work, to further reduce the computational cost, we investigate spatial low-rank structures in the ANOVA-collocation method, and develop efficient spatial model reduction techniques using hierarchically generated reduced bases.",In this paper we present a reduced basis ANOVA approach for partial deferential equations (PDEs) with random inputs.,,
10.1016/j.jcp.2006.02.010,Uncertainty estimation and prediction for interdisciplinary ocean dynamics (2006),Stochastic forcing formulations are introduced and a new stochastic-deterministic ocean model is presented.,"Primary characteristics of ocean data, models and uncertainties are reviewed and quantitative data assimilation concepts defined.",Challenges involved in realistic data-driven simulations of uncertainties for four-dimensional interdisciplinary ocean processes are emphasized.,"Scientific computations for the quantification, estimation and prediction of uncertainties for ocean dynamics are developed and exemplified.","Capabilities of the ESSE system are illustrated in three data-assimilative applications: estimation of uncertainties for physical-biogeochemical fields, transfers of ocean physics uncertainties to acoustics, and real-time stochastic ensemble predictions with assimilation of a wide range of data types."
10.1016/j.jhydrol.2013.09.037,Establishing rainfall depth-duration-frequency relationships at daily raingauge stations in Hong Kong (2013),"The core components of the framework include the scaling model of rainfalls of different durations, the establishment of relationship between annual maximum daily rainfall and rolling-time  min rainfall, the quantification of statistical features of estimated annual maximum  min rainfalls, and the assessment of uncertainty of derived rainfall DDF relationships at conventional raingauges.","However, daily rainfall data with long records at conventional raingauges are of limited use to establish rainfall DDF relationships in areas with small catchment size like Hong Kong where design storm duration significantly shorter than -h are needed.","Therefore, record lengths at majority of automatic raingauges are relatively short and the derived rainfall DDF relationships on the basis of at-site frequency analysis are potentially subject to significant sampling error.","On the other hand, many conventional raingauges exist long before automatic raingauges were deployed.",This study presents a practical methodological framework to derive rainfall DDF relationships with short duration at conventional raingauge locations.
10.1016/j.envsoft.2007.10.006,Integrated modelling of risk and uncertainty underlying the cost and effectiveness of water quality measures (2008),"These different types of uncertainty are identified, quantified and analysed with the help of a risk and uncertainty model written in Excel (R) Visual Basic using Monte Carlo simulation.",The novelty of the work is that we investigate the combined effect of uncertainty in both the cost and effect assessment in a probabilistic way as a logical extension of traditional approaches to uncertainty analysis like sensitivity and scenario analysis.,"The model provides insight into the robustness of the ranking of water quality measures by explicating the probability that one measure is more cost-effective than another, applying different distributional assumptions.",We show that the interaction between environmental and economic uncertainty is not straightforward.,"The estimation of the cost-effectiveness of water quality measures is surrounded by environmental, economic and political uncertainty."
10.1016/j.cma.2005.03.013,Numerical simulation of the forging process (2006),The paper also looks at recent developments in re-meshing and its importance in realistic forging modelling.,A holistic approach to forging modelling is still awaited in which all features of the process together with the influence of aspects such as press behaviour are considered.,,,
10.1016/j.cma.2016.05.040,Isogeometric configuration design sensitivity analysis of finite deformation curved beam structures using Jaumann strain formulation (2016),"Contrary to the IGA-based DSA, the Hermite basis function explicitly depends on design in the FEA-based DSA due to its element length parameter.","In the isogeometric approach, the higher order continuity and the exact description of initial geometry are naturally embedded using NURBS basis functions.","Under the total Lagrangian formulation, large deformations considering the initial curvature of curved beams are described by geometrically exact beam theory (GEBT) and Jaumann strain formulation.",,
10.1016/j.jhydrol.2012.06.059,Adapting the coupled hydrological model ISBA-TOPMODEL to the long-term hydrological cycles of suburban rivers: Evaluation and sensitivity analysis (2013),"The underestimation seems to be caused by an unrealistic deep drainage through the soil, whereas the overestimation can be attributed to impervious surface runoff overestimation.","This model was evaluated on a French basin, located in the northwestern France, within a suburb of the city of Nantes.","Nevertheless, over the entire simulated period, the statistical criteria still indicate satisfactory results.","Impervious surfaces were taken into account assuming very low infiltration, production of runoff drained through the sewer network when the maximal surface stock capacity is exceeded and groundwater infiltration.",
10.1016/j.cma.2017.01.007,Calibration experimental design considering field response and model uncertainty (2017),Current CEDO methods only consider observation errors and focus on problems with low-dimensional response variables.,A nonlinear analytical example and a heat transfer example are used to illustrate the effectiveness of the proposed approach.,Calibration experiment design optimization (CEDO) seeks to identify the optimal values of experimental inputs in order to maximize the obtained information within testing budget constraints.,The optimal experimental input settings are obtained using the efficient global optimization (EGO) method.,"Based on the evaluation of objective function, a global sensitivity analysis (GSA)-based method is proposed to check the quality of surrogate models used in CEDO, guide the training and improvement of the surrogate models, and thus reduce the effect of surrogate model uncertainty on CEDO."
10.1016/j.jcp.2007.02.011,Adjoint-based aerodynamic shape optimization on unstructured meshes (2007),"The effect of some approximations in the discrete adjoint, which aim at reducing the complexity of the implementation, is shown in terms of optimization results rather than only in terms of gradient accuracy.",The shape-optimization method appears to be very efficient and robust.,,,
10.1016/j.jcp.2013.08.024,Improved statistical models for limited datasets in uncertainty quantification using stochastic collocation (2013),We argue that this modified KMM method tries to preserve what is known from the given data and is the better approach when the available data is limited in quantity.,This improvement in accuracy is also demonstrated for the case of UQ in electrostatic and electrothermomechanical microactuators.,We show how our framework results in the accurate computation of statistics in micromechanical systems.,"Comparing the output mean and variance estimated with the empirical moments using the raw data sample as well as the actual moments using the known PDF, we show that the KMM method performs better than KDE and AKDE in predicting these moments with greater accuracy.",This model is propagated through an appropriate response surface function that approximates the behavior of this system using stochastic collocation.
10.1016/j.envsoft.2010.12.003,Exploring vulnerability of coastal habitats to sea level rise through global sensitivity and uncertainty analyses (2011),These findings are important to implement managerial schemes in the area to protect threatened Plover birds (Charadrius sp.),"Results showed that four input factors (DEM vertical error for the lower elevation range, historic trend of sea level rise, accretion, and sedimentation rates) controlled -% of SLAMM 's output variance in predicting changes in the beach habitat of Eglin Air Force Base.",reduction in elevation due to sea level rise) and accretion/sedimentation.,The most dominant processes governing the fate of the coastline of the study area were inundation (i.e.,This generic model evaluation framework is model-independent and can be used to evaluate a wide range of environmental models.
10.1016/j.jhydrol.2016.05.025,Evaluation of TOPLATS on three Mediterranean catchments (2016),Physically based hydrological models are complex tools that provide a complete description of the different processes occurring on a catchment.,"To overcome this issue, an alternative random and discontinuous method of cal/val period selection was implemented, improving model results.",,,
10.1016/j.envsoft.2015.03.008,Partial validation of cellular automata based model simulations of urban growth: An approach to assessing factor influence using spatial methods (2015),A partial validation applied to a CA-based model for the Madrid Region (Spain) is presented as a proposal for determining the influence of given factors on the results and testing their spatial variability.,Cellular Automata (CA) based models have a high aptitude to reproduce the characteristics of urban processes and are useful to explore future scenarios.,"However, validation of their results poses a major challenge due to the absence of real future data with which to compare them.",Frequency maps showing the most frequent cells with changed land use in the results were generated.,"Main and total effects of these factors were calculated for each method, by applying a simplified Global Sensitivity Analysis approach."
10.1007/s00158-009-0420-2,Survey of modeling and optimization strategies to solve high-dimensional design problems with computationally-expensive black-box functions (2010),"The survey exposes that direct modeling and optimization strategies to address HEB problems are scarce and sporadic, partially due to the difficulty of the problem itself.",The merger of these three challenges severely aggravates the difficulty and becomes a major hurdle for design optimization.,"This paper provides a survey on related modeling and optimization strategies that may help to solve High-dimensional, Expensive (computationally), Black-box (HEB) problems.","The most eminent challenges arise from high-dimensionality of problems, computationally-expensive analysis/simulation, and unknown function properties (i.e., black-box functions).",Major contributions in each area are discussed and presented in an organized manner.
10.1016/j.envsoft.2010.10.007,Convergence and uncertainty analyses in Monte-Carlo based sensitivity analysis (2011),This paper proposes two methods to monitor the convergence and estimate the uncertainty of sensitivity analysis techniques.,These two methods are implemented to assess five different sensitivity analysis techniques applied to an environmental model.,,,
10.1016/j.cma.2008.08.014,Stochastic fracture mechanics by fractal finite element method (2008),The results show that the predicted failure probability based on the proposed formulation of the sensitivity of fracture parameter is accurate in comparison with the Monte Carlo simulation results.,This paper presents stochastic fracture mechanics analysis of linear-elastic cracked structures subjected to mixed-mode (modes I and II) loading conditions using fractal finite element method (FFEM).,"Since all gradients are calculated analytically, reliability analysis of cracks can be performed efficiently using FFEM.","The method involves FFEM for calculating fracture response characteristics; statistical models of uncertainties in load, material properties, and crack geometry; and the first-order reliability method for predicting probabilistic fracture response and reliability of cracked structures.",
10.1016/j.jhydrol.2009.01.020,A technique for the calibration of hydraulic models using uncertain satellite observations of flood extent (2009),These flood extent maps were used to perform a sensitivity analysis of a simple raster-based inundation model (LIS-FLOOD-FP).,Ten different flood extent maps were derived from the two flood images by using five different procedures to process these data.,"Finally, the study developed a novel methodology to calibrate flood inundation models by comparing the model results to a possibility of inundation map obtained by combining the ten different flood extent maps.",The sensitivity analysis enabled us to investigate the capability of the two different resolution images to calibrate the friction parameters of the flood inundation model.,This paper presents a methodology to calibrate hydraulic models using possibility of inundation maps derived from satellite imagery.
10.1016/j.jcp.2014.07.005,An optimization framework to improve 4D-Var data assimilation system performance (2014),The ability to optimize a distributed measurement network is crucial for cutting down operating costs and detecting malfunctions.,The approach formulates a continuous meta-optimization problem for parameters; the meta-optimization is constrained by the original data assimilation problem.,This paper develops a computational framework for optimizing the parameters of data assimilation systems in order to improve their performance.,,
10.1016/j.envsoft.2006.12.005,An open-book watershed model for prototyping space-borne flood monitoring systems in International River Basins (2007),"In this paper, we develop, verify and apply an open-book watershed model for demonstrating the value of a parsimonious modeling scheme in quick prototyping of satellite rainfall-based flood monitoring systems for lowermost nations in flood-prone IRBs.","Our findings, although hypothetical and very regime-specific, illustrate very clearly the feasibility of utilizing anticipated GPM data to alleviate the current flood monitoring limitations experienced by many nations in IRBs through the application of a generic and parsimonious model.","Finally, using the radar-simulated hydrograph as the benchmark, and assuming a two-nation hypothetical IRB over Oklahoma, we explored the impact of assimilating NASA's real-time satellite rainfall data (IR-BRT) over the upstream nation on the flow monitoring accuracy for the downstream nation.",We developed a relationship defining the improvement in flow monitoring that can be expected from assimilating IR-BRT over transboundary regions as a function of the relative area occupied by the downstream nation for a semi-arid region.,A new era involving both simple and complex hydrologic modeling of un-gauged river basins may now emerge with the anticipated global availability of high resolution satellite rainfall data from the proposed Global Precipitation Measurement (GPM) mission.
10.1016/j.jhydrol.2009.07.054,Development of a Simple Remote Sensing EvapoTranspiration model (Sim-ReSET): Algorithm and model test (2009),"mm/day, and the RMSE is .",W/m() under neutral or near-neutral atmospheric conditions.,"For the purposes of sensitivity analysis and performance evaluation of the Sim-ReSET model without the effect of potential uncertainties and errors from remote sensing data, the Sim-ReSET model was tested only using intensive ground observations at the Yucheng ecological station in the North China Plain from  to .","Many studies have been conducted to estimated ET using RS data, however, most of them are based partially on ground observations.",W/m() and a root mean square error (RMSE) of .
10.1016/j.jhydrol.2014.05.049,Assessing hydrologic prediction uncertainty resulting from soft land cover classification (2014),"Based on the resulting uncertainty map, guidelines for additional data collection are formulated in order to reduce the uncertainty for future model applications.","The results show that the predictions of evapotranspiration, runoff and baseflow are hardly affected by the classification uncertainty when area-averaged predictions are intended, implying that uncertainty propagation is only advisable in case a spatial distribution of the predictions is relevant for decision making or is coupled to other spatially distributed models.","Hence, an improved understanding of the quality of the estimates and the development of methods for dealing with their associated uncertainty are essential to evolve towards accurate PUB.","Because a Monte Carlo-based uncertainty analysis is computationally very demanding, especially when complex models are involved, we developed a fast indicative uncertainty assessment method that allows for generating proxies of the Monte Carlo-based result in terms of the mean prediction and its associated uncertainty based on a single model evaluation.","However, indirect estimates of the environmental characteristics are prone to uncertainty."
10.1016/j.envsoft.2013.03.011,A review of Bayesian belief networks in ecosystem service modelling (2013),A SWOT analysis highlights the advantages and disadvantages of BBNs in ESS modelling and pinpoints remaining challenges for future research.,"However, the number of applications of BBNs in ESS modelling is still limited.","The existing BBN models are suited to describe, analyse, predict and value ESS.",A wide range of quantitative and qualitative modelling research on ecosystem services (ESS) has recently been conducted.,
10.1016/j.jhydrol.2012.09.026,Analysis of the behavior of a rainfall-runoff model using three global sensitivity analysis methods evaluated at different temporal scales (2012),"For instance, it was observed that all parameters were important at least during  day a daily scale, while at a yearly scale only the parameters characterizing the soil storage and the recession constants for interflow and percolation had high sensitivities.",An analysis of the parameter sensitivity across the scales showed that the number of important parameter decreases when longer evaluation periods are considered.,The effect of  parameters on the discharge of a conceptual rainfall-runoff model was analyzed for a small Austrian catchment.,This information can be used for increasing the understanding of the mechanisms by which the parameters affect the model results.,A correlation analysis further indicated that the periods in which the parameter sensitivity rankings did not agree between the different methods are characterized by a higher impact of the parameters interactions on the modeled discharge.
10.1016/j.cma.2009.11.013,Sensitivity of optimal shapes of artificial grafts with respect to flow parameters (2010),"Finally, we employ the transformed framework to compute the sensitivity of the optimal shape of bypass grafts with respect to kinematic viscosity.","Furthermore, the robustness of the optimal shape with respect to simulation parameters is of great interest.","To compute derivatives of the optimal shapes with respect to viscosity, we transform the entire optimization framework by combining the automatic differentiation tools Adifor and TAPENADE.",We demonstrate the impact of the geometry parametrization and of geometric constraints on the optimization outcome.,The difficulties arising in the numerical solution of PDE-constrained shape optimization problems are manifold.
10.1006/jcph.2001.6882,A clustering genetic algorithm for cylinder drag optimization (2002),"The optimal belt-actuator parameters obtained by optimizing the two-dimensional case is employed in three-dimensional simulations, by extending the actuators across the span of the cylinder surface.","By means of the clustering property of the present genetic algorithm, a set of solutions producing drag reduction of up to % is identified.",The possibility of using a few strategically placed actuators to obtain a significant drag reduction is explored using the clustering diagnostics of this method.,A real coded genetic algorithm is implemented for the optimization of actuator parameters for cylinder drag minimization.,"The genetic algorithm we implement has the property of identifying minima basins,rather than single optimum points."
10.1016/j.jhydrol.2012.02.012,Regional flood frequency analysis in eastern Australia: Bayesian GLS regression-based methods within fixed region and ROI framework - Quantile Regression vs. Parameter Regression Technique (2012),"In this article, an approach using Bayesian Generalised Least Squares (BGLS) regression in a region-of-influence (ROI) framework is proposed for regional flood frequency analysis (RFFA) for ungauged catchments.",The RFFA methods developed in this paper is based on the database available in eastern Australia.,The identified optimal regression equation is then used in the ROI experiment where the ROI is chosen for a site in question as the region that minimises the predictive uncertainty.,"It is expected that availability of a more comprehensive database (in terms of both quality and quantity) will further improve the predictive performance of both the fixed and ROI based RFFA methods presented in this study, which however needs to be investigated in future when such a database is available.","To evaluate the overall performances of the quantiles estimated by the QRT and PRT, a one-at-a-time cross-validation procedure is applied."
10.1016/j.jcp.2012.08.013,Simulation-based optimal Bayesian experimental design for nonlinear systems (2013),"We propose a general mathematical framework and an algorithmic approach for optimal experimental design with nonlinear simulation-based models; in particular, we focus on finding sets of experiments that provide the most information about targeted sets of parameters.",These algorithms are demonstrated on model problems and on nonlinear parameter inference problems arising in detailed combustion kinetics.,"The optimal selection of experimental conditions is essential to maximizing the value of data for inference and prediction, particularly in situations where experiments are time-consuming and expensive to conduct.",,
10.1016/j.envsoft.2016.08.017,A python framework for environmental model uncertainty analysis (2016),Complete workflows for several types of FOSM-based and non-linear analyses are documented in example notebooks implemented using Jupyter that are available in the online pyEMU repository.,"The FOSM-based analyses can also be completed prior to parameter estimation to help inform important modeling decisions, such as parameterization and objective function formulation.","The framework implements several types of linear (first-order, second-moment (FOSM)) and non-linear uncertainty analyses.",,
10.1016/j.jcp.2013.05.035,Subcell resolution in simplex stochastic collocation for spatial discontinuities (2013),"To avoid these problems, we introduce subcell resolution into the Simplex Stochastic Collocation (SSC) method for obtaining a truly discontinuous representation of random spatial discontinuities in the interior of the cells discretizing the probability space.",,,,
10.1016/j.cma.2017.03.026,Hybrid uncertainty propagation in structural-acoustic systems based on the polynomial chaos expansion and dimension-wise analysis (2017),Hybrid uncertainties are ubiquitous in the structural-acoustic analysis and greatly affect the behaviors of the coupled system.,"a hybrid method of the polynomial chaos expansion and dimension-wise analysis (PCE-DW), is proposed in this paper.",The PCE-DW also applies to the structural-acoustic analysis with only random or interval parameters.,,
10.1016/j.cma.2012.12.013,An efficient framework for optimization and parameter sensitivity analysis in arterial growth and remodeling computations (2013),We show that an artery can achieve optimal homeostatic conditions over a range of alterations in pressure and flow; robustness of the solution is enforced by including uncertainty in loading conditions in the objective function.,"Finally, we outline several challenges to the G&R community for future work.",Accurate predictions of these responses are essential for understanding numerous disease processes.,"Such models require reliable inputs of numerous parameters, including material properties and growth rates, which are often experimentally derived, and inherently uncertain.","While earlier methods have used a brute force approach, systematic uncertainty quantification in G&R models promises to provide much better information."
10.1016/j.envsoft.2014.05.012,Toward improved calibration of watershed models: Multisite multiobjective measures of information (2014),"However, the DREAM method solution was the only one among the three single objective optimization methods considered in this study that satisfied the conditions defined for characterizing system behavior.","The proposed framework was applied for calibration of the Soil and Water Assessment Tool (SWAT) in the Eagle Creek Watershed, Indiana, USA using three single objective optimization methods [Shuffled Complex Evolution (SCE), Dynamically Dimensioned Search (DDS), and DiffeRential Evolution Adaptive Metropolis (DREAM)I, and one multi-objective optimization method.","This study demonstrates the importance of hydrologic and water quality data availability at multiple locations, and also highlights the use of multiobjective approaches for proper calibration of watershed models that are used for pollutant source identification and watershed management.",Solutions were classified into behavioral and non-behavioral using percent bias and Nash-Sutcliffe model efficiency coefficient.,"In particular, aggregation of streamflow and NOx responses undermined finding ""very good"" behavioral solutions for NOx, primarily because of the significantly larger number of observations for streamflow."
10.1016/j.jhydrol.2012.12.027,Uncertainty-based evaluation and comparison of SWAT and HSPF applications to the Illinois River Basin (2013),"This finding implies that the accuracy that the HSPF model can achieve in a modeling exercise may have more reliance on the efficacy of the calibration procedure, and the application of SWAT may have some advantage when calibration data are lacking or scarce.","Furthermore, there exist parameter sets that enable the HSPF model to generate more accurate predictions of the discharges in the main stem of the Illinois River than the SWAT model does, but when the two models were run in un-calibrated mode the distributions of the model fit summary statistics for HSPF observed in the Monte Carlo sampling during GLUE calibration are more varied than those for SWAT with heavier tails on the inferior side and SWAT would have comparable performance to HSPF on average.",The Soil and Water Assessment Tool (SWAT) and the Hydrologic Simulation Program-Fortran (HSPF) are two river basin simulation models with similar scheme of watershed delineation and functionalities.,"This paper reports results calibrating and evaluating SWAT and HSPF model to hydrologic data in the Illinois River Basin, with relative performance of two models in hydrologic simulation and model behaviors under calibration being further compared.","In this study, two different calibration approaches, the multi-criteria and the generalized likelihood uncertainty estimation (GLUE) method, were used to quantify uncertainties originated from the use of multi-site discharge observations and the presence of equifinal solutions."
10.1016/j.jhydrol.2009.09.019,Towards robust methods to couple lumped rainfall-runoff models and hydraulic models: A sensitivity analysis on the Illinois River (2012),"A similar level of performance was reached with models using point inflows only, but at the cost of more uncertain parameters and less stable model performance when changing test periods.",These strategies introduced variations in the nature of the connections between the two models using combinations of point and uniformly distributed lateral inflows.,"In this case, model performance was less sensitive to the number of tributaries used and the inclusion of two or three tributaries appeared sufficient to obtain satisfactory performance for the simulations on the main channel.",The simulations were assessed at the downstream end of the reach and at two interior points considered to be ungauged during the calibration process.,"When a river reach receives significant lateral inflows, flood inundation modelling requires the joint application of a hydrological model to calculate lateral inflows and a hydraulic model to calculate water levels along the river reach."
10.1016/j.jcp.2015.06.045,Using Raman-lidar-based regularized microphysical retrievals and Aerosol Mass Spectrometer measurements for the characterization of biomass burning aerosols (2015),Focusing on the fine mode we observed remarkable similarities between the retrieved size distribution and the one measured by the AMS.,"Finally, the dependence on relative humidity of aerosol effective radii measured on the ground and within the layers aloft show similar patterns.","A good correlation was found between the aerosol effective radius and particle age, using the ratio of lidar ratios (LR: aerosol extinction to backscatter ratios) as an indicator for the latter.",Our algorithm was tested not only for pure smoke but also for mixed smoke and urban aerosols of variable age and growth.,
10.1007/s00158-007-0198-z,Design of distributed compliant micromechanisms with an implicit free boundary representation (2008),The compliant inverter is applied to demonstrate the availability of the present method in the framework of the implicit free boundary representation.,The compactly supported radial basis function of favorable smoothness and accuracy is used to interpolate the level set function.,A level set model is developed to implicitly describe the structural boundary by embedding into a scalar function of higher dimension as zero level set.,"In this paper, a parameterization approach is presented for structural shape and topology optimization of compliant mechanisms using a moving boundary representation.","It is noted that the present method is not only capable of simultaneously addressing shape fidelity and topology changes with a smooth structural boundary but also able to avoid some of the unfavorable numerical issues such as the Courant-Friedrich-Levy condition, the velocity extension algorithm, and the reinitialization procedure in the conventional level set method."
10.1016/j.envsoft.2009.11.010,Exploring uncertainty and model predictive performance concepts via a modular snowmelt-runoff modeling framework (2010),"Such an approach can strengthen model building and address an oft ignored aspect of predictive uncertainty; namely, model structural uncertainty.","Model selection is an extremely important aspect of many hydrologic modeling studies because of the complexity, variability, and uncertainty that surrounds the current understanding of watershed-scale systems.","The case study focuses on an approach to hydrologic modeling that considers model development, selection, calibration, uncertainty analysis, and overall assessment.",,
10.1016/j.cma.2008.10.005,Sensitivity of the macroscopic thermal conductivity tensor to topological microstructural changes (2009),The classical Fourier law is assumed to hold at the scale referred to as microscopic (the RVE).,The proposed formula finds potential application in the design and optimisation of heat conducting materials.,It is derived by applying the concept of topological derivative within a variational multi-scale framework for steady-state heat conduction where the macroscopic temperature gradient and heat flux are defined as volume averages of their microscopic counterparts over a representative volume element (RVE) of material.,This paper proposes a closed form expression for the sensitivity of the macroscopic heat conductivity tensor for two-dimensional problems to topological microstructural changes of the underlying material.,The sensitivity formula is remarkably simple.
10.1016/j.cma.2013.02.017,Fast estimation of expected information gains for Bayesian experimental designs based on Laplace approximations (2013),"To deal with the issue of dimensionality in a complex problem, we use a sparse quadrature for the integration over the prior pdf.",,,,
10.1016/j.cma.2017.04.017,A computational framework for Bayesian inference in plasticity models characterisation (2017),The study presented offers at least two main contributions.,"Firstly, the design of CBPC to solve the main inference problems in plasticity, in an efficient way, is novel.","In addition, its practical application in plasticity model characterisation problems, namely hardening and anisotropy parameter inference and the model class comparison in a multi-axial state of stress is justified and demonstrated.","Selecting the material model class, the corresponding model parameter distributions are inferred simultaneously.",The purpose of the study is to set out and justify a computational framework for Bayesian inference in plasticity models characterisation (CBPC).
10.1016/j.jhydrol.2015.03.060,Identification of the best multi-model combination for simulating river discharge (2015),"Ten different multi-model ensemble methods, viz., mean, median, trimmed mean, unconstrained and constrained multiple linear regression, weighted mean based on calibration performance (two variants), linear programming, simple model average and multi model super ensemble, are compared using calibrated and validated data of eight popular hydrological models, MIKE SHE, SWAT, HEC-HMS, AWBM, SIMHYD, SACRAMENTO, SMAR and TANK.",Constrained multiple linear regression (MLR_C) method is found to be the most suitable multi-model ensemble method for the study area.,This paper focuses on the selection of the best multi-model ensemble method that is subsequently used to create an ensemble for the discharge estimation in a catchment of the Mahanadi river basin in India.,MLR_C method is subsequently used to develop  possible multi-model ensembles.,"The results show that an ensemble having five models, one physically based (SWAT) and four conceptual (AWBM, SIMHYD, SACRAMENTO and SMAR), performs the best for the chosen catchment."
10.1016/j.jcp.2006.06.041,A Mumford-Shah level-set approach for the inversion and segmentation of X-ray tomography data (2007),The use of an L--type and an H--type metric is proposed and the corresponding steepest descent flow equations are derived.,"Simultaneously, a segmentation of the reconstructed density is obtained.",A heuristic approach for the insertion of additional components of the density is presented.,It is shown that the method works especially well for large data noise (similar to % noise).,A level-set based approach for the determination of a piecewise constant density function from data of its Radon transform is presented.
10.1007/s00158-003-0287-6,Structural natural-frequency shape-sensitivity analysis: a fixed-basis-function finite-element approach (2003),The present formulation separates solution sensitivity from finite-element grid sensitivity and provides a unique representation of boundary perturbations within the context of isoparametric finite-element formulations.,The approach adopts the point of view that the finite-element grid is fixed during the sensitivity analysis; therefore it is referred to as a 'Fixed Basis Function Shape Sensitivity' finite-element analysis.,It is illustrated that the finite-element eigenvalue problem and the fixed-basis finite-element eigenvalue-sensitivity results exhibit similar accuracy and convergence characteristics.,It is shown that the evaluation of sensitivity matrices involves only modest calculations beyond those for the finite-element analysis of the reference problem; certain boundary integrals on the reference location of the moving boundary are required.,This approach avoids the requirement of explicit or approximate differentiation of finite-element matrices and vectors and the difficulty or errors resulting from such calculations.
10.1016/j.cma.2013.11.015,Adaptive stochastic Galerkin FEM (2014),"Details on the implementation with the open-source software framework ALEA are presented; it is generic, and is based on available stiffness and mass matrices of a FEM for the deterministic, nonparametric nominal problem evaluated in the FEniCS environment.",Numerical experiments in two spatial dimensions for membrane and plane stress boundary value problems on polygons are presented.,"Asynchronous mesh adaptation for different gpc coefficients is permitted, subject to a minimal compatibility requirement on meshes used for different gpc coefficients.",The reliability of the residual estimator is established.,A framework for residual-based a posteriori error estimation and adaptive mesh refinement and polynomial chaos expansion for general second order linear elliptic PDEs with random coefficients is presented.
10.1016/j.envsoft.2010.05.009,Estimating the uncertainty of modeled carbon sequestration: The GreenCert (TM) system (2010),"This paper focuses on uncertainty treatment, discussing sources of error, parameter distributions, and the Monte Carlo randomization approach, culminating in a sensitivity analysis of model parameters.",Idealized crop and grazing scenarios were used to evaluate the uncertainty of modeled soil organic carbon stocks and stock changes stemming from variability in site and management parameters.,"Normalized sensitivity coefficients and an integrated index for relative sensitivity of the model to the ensemble of the tested variables indicate that environmental factors are the most important in determining the actual size of the soil carbon stock, but that management is a much more important determinant of short- to medium-term carbon fluxes.",,
10.1016/S0045-7825(00)00310-8,A computational methodology for shape optimization of structures in frictionless contact (2001),For evaluation it has been implemented as a subsystem of a general finite element software.,"The key building blocks are: analytic sensitivity analysis, an adaptive finite element method, an accurate contact solver.",The parts connected to shape optimization are described in more detail.,The overall design and main principles of operation of this software are outlined.,This paper presents a computational methodology for shape optimization of structures in frictionless contact.
10.1016/j.envsoft.2016.10.003,"The rocky road to extended simulation frameworks covering uncertainty, inversion, optimization and control (2017)","While there is an ongoing discussion on quality assurance and reproducibility for simulation frameworks, we have not observed a similar discussion for the extended case.","Recently, the combination with tools for uncertainty quantification, inverse modelling, optimization and control started a development towards what we call extended simulation frameworks.",The resulting demand for 'intelligent software' with automated configuration can lead to a blind trust in simulation results even if they are incorrect.,Our goal is to start transferring the quality assurance discussion in the field of integrated modeling and conventional software frameworks to the area of extended simulation frameworks.,"With this, we hope to increase the reliability and transparency of (extended) frameworks, framework use and of the corresponding simulation results."
10.1007/s00158-017-1747-8,Reliability-based and deterministic design optimization of a FSAE brake pedal: a risk allocation analysis (2017),"To promote the use of probabilistic designs among engineering students and practitioners, this work solves reliability based design optimization (RBDO) and deterministic design optimization (DDO) models of a FSAE brake pedal with multiple failure modes (stress and buckling) with their relative performance evaluated through a risk allocation analysis.","Results show that when compared to DDO with alternative safety factors, for the same probability of system failure, the RBDO brake pedal designs were significantly lighter and more robust (less mass variability).",,,
10.1016/j.cma.2011.09.011,Certified reduced basis model validation: A frequentistic uncertainty framework (2012),We introduce a frequentistic validation framework for assessment - acceptance or rejection - of the consistency of a proposed parametrized partial differential equation model with respect to (noisy) experimental data from a physical system.,,,,
10.1016/j.cma.2017.01.019,Topology optimization under uncertainty via non-intrusive polynomial chaos expansion (2017),Uncertainty is introduced in loading and in geometry to address the manufacturing variability.,This paper presents a systematic approach for topology optimization under uncertainty that integrates non-intrusive polynomial chaos expansion with design sensitivity analysis for reliability-based and robust topology optimization.,Efficiency of the non-intrusive polynomial chaos approach is highlighted by comparison with the Monte Carlo method in terms of the number of simulations.,"To demonstrate the effect of uncertainty, optimized designs that consider uncertainty are compared to those that do not.",
10.1016/S1364-8152(01)00065-2,Testing the CORMIX model using thermal plume data from four Maryland power plants (2002),CORMIX results should be used with caution in evaluating the effects of a discharge and only in conjunction with information from the field.,Users of the CORMIX model need to be aware of these limitations in applying the model to complex situations.,"Historical thermal plume studies from four Maryland power plants (Calvert Cliffs, Chalk Point, Dickerson, and Wagner) were used to test the realism of the CORnell MIXing Zone Expert System (CORMIX).",Sensitivity results show that sensitivity is often dependent on model run time and discontinuities in the CORMIX flow classification scheme.,"Historical case studies were simulated, and results were compared qualitatively and quantitatively with historical measurements."
10.1016/j.jcp.2014.11.010,Limitations of polynomial chaos expansions in the Bayesian solution of inverse problems (2015),"We show, by analysis and example, that when the data contain significant information beyond what is assumed in the prior, the surrogate posterior can be very different from the posterior, and the resulting estimates become inaccurate.",,,,
10.1016/j.jhydrol.2005.07.013,Calibration of conceptual hydrological models revisited: 2. Improving optimisation and analysis (2006),Conceptual hydrological modelling has under-utilised classical parameter analysis techniques (for both optimisation and uncertainty assessment) due to the prohibitively complicated nonsmooth geometry of typical parameter distributions.,"Here, this framework is exploited to enable parameter estimation using powerful and well-established techniques including: (i) Newton-type optimisation and (ii) principal-component-type (Hessian-based) uncertainty analysis.","The impact of extreme model nonlinearity on model and parameter stability is also discussed, focusing on model identification aspects.",,
10.1016/j.jhydrol.2015.06.034,Variance-based global sensitivity analysis for multiple scenarios and models with implementation using sparse grid collocation (2015),This is particularly true when the sensitivity indices and model/scenario probabilities vary substantially.,"Based on a hierarchical structure of parameter, model, and scenario uncertainties and on recently developed techniques of model- and scenario-averaging, this study derives new global sensitivity indices for multiple models and multiple scenarios.",This problem is resolved by using the new indices defined for multiple models and/or multiple scenarios.,"Sensitivity analysis is a vital tool in hydrological modeling to identify influential parameters for inverse modeling and uncertainty analysis, and variance-based global sensitivity analysis has gained popularity.","The sparse grid collocation method dramatically reduces the computational cost, in comparison with the popular quasi-random sampling method."
10.1016/j.jhydrol.2005.03.012,Identifiability of distributed floodplain roughness values in flood extent estimation (2005),"As a consequence, application of complex formulae to establish roughness values for changed floodplain land use would seem inappropriate, and evaluation of such changes within a probabilistic framework is suggested.","Detailed information on floodplain land use types is aggregated to form one, two or five classes of floodplain roughness.","Sensitivity analysis of model performance against the calibration data shows that as the number of floodplain classes increases, sensitivity to these roughness values decreases, given allocation of prior roughness values on the basis of constituent land use types and associated roughness values found from literature.",Evaluating the identifiability of the roughness in these classes using the Generalised Likelihood Uncertainty Estimation (GLUE) method confirms this insensitivity.,
10.1016/j.jcp.2006.02.029,Stochastic analysis of transport in tubes with rough walls (2006),Often the topology of such surfaces cannot be accurately described in all of its relevant details due to either insufficient data or measurement errors or both.,,,,
10.1016/j.jcp.2016.10.073,Predictive coarse-graining (2017),Predictive posterior distributions reflect the confidence of the model as a function of the amount of data and the level of coarse-graining.,"We propose a data-driven, coarse-graining formulation in the context of equilibrium statistical mechanics.","From an information-theoretic perspective, the framework proposed provides an improvement upon the relative entropy method [] and is capable of quantifying the uncertainty due to the information loss that unavoidably takes place during the coarse-graining process.","In contrast to existing techniques which are based on a fine-to coarse map, we adopt the opposite strategy by prescribing a probabilistic coarse-to-fine map.",A comparative assessment of the proposed methodology is presented for a lattice spin system and the SPCJE water model.
10.1016/j.jhydrol.2016.05.009,Model parameter uncertainty analysis for an annual field-scale P loss model (2016),This was due to differences in the number of model input variables and the uncertainties in the regression equations associated with each P loss pathway.,Our analysis included calculating parameter uncertainties and confidence and prediction intervals for five internal regression equations in APLE.,Phosphorous (P) fate and transport models are important tools for developing and evaluating conservation practices aimed at reducing P losses from agricultural fields.,Both the overall magnitude of the prediction uncertainties and the relative contributions of the two sources of uncertainty varied depending on management practices and field characteristics.,"In this study, we conducted an uncertainty analysis with the Annual P Loss Estimator (APLE) model."
10.1016/j.cma.2007.05.031,A Bayesian calibration approach to the thermal problem (2008),We then go on to address the regulatory question posed in the problem description.,"B  () -], but has been extended to deal with functional output of the simulation model.",,,
10.1016/j.cma.2008.08.021,Coordinated synthesis of hierarchical engineering systems (2010),This includes the development of a procedure to assess the sensitivity of system functions to changes in sub-system designs.,The developed procedures are demonstrated through a detailed example involving a particulate composite material system in which the effective thermal conductivity is evaluated in a partitioned manner.,"In this paper, we develop a formal procedure for the coordinated synthesis of hierarchically described engineering systems.",The systematic development of the procedure for analysis and synthesis of hierarchically described engineering systems is the focus in the first part of the paper.,
10.1016/j.envsoft.2009.03.007,Assessment of data availability influence on integrated urban drainage modelling uncertainty (2009),The present study demonstrates that model calibration and modelling efficiency assessment may induce the operator to be excessively confident in the model results when available data are scarce.,"At this scope, a parsimonious integrated home-made model has been used allowing for analysing the combinative effect of data availability regarding the different parts of the integrated urban drainage system; the uncertainty analysis approach has been applied to an experimental catchment in Bologna (Italy).","In urban water quality management, several models are connected and integrated for analysing the fate of pollutants from the sources in the urban catchment to the final recipient; classical problems connected with the selection and calibration of parameters are amplified by the complexity of the modelling approach increasing their uncertainty.",The number of available data points has been fictitiously reduced obtaining data sets ranging between % and % of the actually measured data.,The present paper aims at studying the influence of reductions in available data on the modelling response uncertainty with respect to the different integrated modelling outputs (both considering quantity and quality variables).
10.1016/j.jhydrol.2004.06.030,Measurement and modeling of concentrated runoff in grassed waterways (2005),The experimental data were derived by pumping concentrated inflow to the upstream end of two GWWs ( and  m long).,"Differences in hydraulic roughness between the tested GWWs were small, but in general hydraulic roughness is a sensitive parameter in runoff control of a GWW, because in case of grass submergence or high runoff velocities grass is bent to the ground, and hence the hydraulic roughness drops drastically.",() ] equation and routing the runoff with a kinematic wave approximation.,"The runoff control on the side-slopes is comparable to that of vegetative filter strips, which was intensively investigated in many studies.","The experiment showed a great difference in runoff control between the two tested GWWs, e.g."
10.1007/s00158-016-1410-9,Representative surrogate problems as test functions for expensive simulators in multidisciplinary design optimization of vehicle structures (2016),The potential of the approach is demonstrated by comparing the efficiency of several optimization algorithms on an RSP and an independent simulation-based vehicle model.,The approach is demonstrated through the construction of RSPs for multidisciplinary optimization problems that occur in the context of structural car body design.,The results corroborate the potential of the proposed approach and significant performance gains in optimization efficiency are achieved.,"This is also the case for multidisciplinary vehicle design optimization problems involving, e.g., weight, crashworthiness, and vibrational comfort responses.","The work builds on existing sensitivity analysis and surrogate data generation methods to establish a novel approach to generate surrogate function sets, which are accessible (i.e."
10.1016/j.jcp.2015.10.030,Numerical methods for high-dimensional probability density function equations (2016),A common feature of all these approaches is that they are reducible to the problem of computing the solution to high-dimensional equations via a sequence of low-dimensional problems.,In this paper we address the problem of computing the numerical solution to kinetic partial differential equations involving many phase variables.,,,
10.1016/j.envsoft.2011.11.003,Emulation techniques for the reduction and sensitivity analysis of complex environmental models (2012),"Furthermore sensitivity analysis is a well known and established tool for evaluating robustness of model based results in management and planning, and is often performed in tandem with emulation.","Emulation (also denoted as metamodelling in the literature) is an important and expanding area of research and represents one of the major advances in the study of complex mathematical models, with applications ranging from model reduction to sensitivity analysis.",This thematic issue aims at providing a guide and reference for modellers in choosing appropriate emulation modelling approaches and understanding their features.,"Tools and applications of sensitivity analysis in the context of environmental modelling are also addressed, which is a typical complement of emulation in most applications.","We hope that this thematic issue provides a useful benchmark in the academic literature for this important and expanding area of research, and will create an opportunity for dialogue between methodological and user-focused research."
10.1016/j.jcp.2007.05.020,Parametric uncertainty analysis of pulse wave propagation in a model of a human arterial network (2007),"Using the physical understanding of the dynamics of pulse waves in these types of networks we are able to provide an insight into the results of the stochastic simulations, thereby demonstrating the effects of uncertainty in physiologically accurate human arterial networks.",This type stochastic hyperbolic systems have not been previously systematically studied due to the difficulties introduced by the uncertainty such as a potential change in the mathematical character of the system and imposing boundary conditions.,The uncertain parameters are modelled as random variables and the governing equations for the arterial network therefore become stochastic.,The justification for such models typically arise due to the significantly long wavelength associated with the system in comparison to the lengths of arteries in the networks.,
10.1007/s00158-012-0846-9,Shape equilibrium constraint: a strategy for stress-constrained structural topology optimization (2013),"In the paper, we present an approach of a shape equilibrium constraint strategy with the level-set/X-FEM framework.",Several numerical examples in two dimensions are provided as a benchmark test of the proposed shape equilibrium constraint strategy for minimum-weight and fully-stressed designs and for designs with stress constraint satisfaction.,"This formulation allows us to effectively handle the stress constraint, and the intrinsic non-differentiability introduced by local stress constraints is removed.","Although remarkable achievements have been made with the SIMP (Solid Isotropic Material with Penalization) framework, a number of critical issues are yet to be fully resolved.",We formulate the topology optimization problem under (spatially-distributed) stress constraints into a shape equilibrium problem of active stress constraint.
10.1016/j.cma.2014.06.010,An integrated approach to shape optimization and mesh adaptivity based on material residual forces (2014),"In order to avoid the occurrence of oscillating boundaries in the optimal design trials, we generate the respective design updates through solving a series of fictitious boundary value problems on an updated Lagrangian configuration.","Therein, the nodal points of a finite element mesh serve as design variables in an optimization problem that aims to minimize a cost functional with respect to different constraints.",This contribution is concerned with the coupling of finite element based shape optimization to methods of mesh adaptivity.,"In each case, the derivations rest upon the notion of material residual forces induced by finite element cliscretization and the coupling of shape optimization and mesh adaptivity is of intermittent type, i.e.","We examine the benefits of the proposed method on the basis of some numerical examples in comparison to the same shape optimization method not involving adaptive mesh refinement where we evaluate the corresponding numerical costs, the gain in accuracy and the effects on the optimal shapes being obtained."
10.1016/j.cma.2015.10.015,Sparse Variational Bayesian approximations for nonlinear inverse problems: Applications in nonlinear elastography (2016),It is based on a Variational Bayesian formulation that aims at approximating the exact posterior by means of solving an optimization problem over an appropriately selected family of distributions.,"Firstly, to find lower-dimensional representations of the unknown parameter vector that capture as much as possible of the associated posterior density, and secondly to enable the computation of the approximate posterior density with as few forward calls as possible.",,,
10.1016/j.cma.2012.10.023,A generalized uncertainty propagation criterion from benchmark studies of microstructured material systems (2013),"Recognizing that modern materials contain multiple phases with inherent random microstructure and in situ constituent material properties that are oft uncharacterizable with exactness, this research uses benchmark computational studies to unveil scenarios where uncertainties significantly affect macroscopic behavior.","Besides the criterion, observed physical behavior for the benchmark problems is also presented in the context of input uncertainty.","The benchmark studies, which serve as numerical experiments capturing the main features of a wide class of problems in solid mechanics, suggest a generalized uncertainty propagation criterion A whose assessment may be used to understand whether uncertainties may non-negligibly propagate to apparent system properties.",,
10.1016/j.jhydrol.2015.05.045,Sensitivity analysis of kinetic energy-intensity relationships and maximum rainfall intensities on rainfall erosivity using a long-term precipitation dataset (2015),The relative size of the erosivity estimates is due to the relative values of  and ; on average I- was % smaller than I- at the study sites.,"Among all of the relationships, the WS logarithmic equation yielded the largest erosivity estimates; however, they were statistically equal to the estimates made with the MG and the VD relationships but were not statistically equal to estimates predicted by the BF relationship.","The results showed that among the exponential equations, the MG relationship yielded erosivity results that were statistically identical to the VD and the BF relationships.","In contrast, in comparison to the other equations, the HU linear relationship yielded significantly smaller erosivity values.","Finally, because the rainfall erosivity estimates at the study sites were highly affected by the type of ICE-I relationship, these results demonstrate that selecting an appropriate KE-I relationship is crucial for accurately estimating erosivity."
10.1016/j.jcp.2016.03.020,Coupling vs decoupling approaches for PDE/ODE systems modeling intercellular signaling (2016),"Based on a sensitivity analysis, we present a systematic comparison between coupling and decoupling approaches for this class of problems and show numerical results.",,,,
10.1007/s00158-013-0924-7,An optimization-based method for designing modular systems that traverse dynamic s-Pareto frontiers (2013),"In a previous work by the authors, a -step optimization-based method was presented to identify systems that account for predicted changes in preferences by moving from one s-Pareto design to another through module addition.","Addressing some of the limitations of this method, this paper presents an improved -step optimization-based method that builds on recent developments in multiobjective problem formulations of dynamic s-Pareto frontiers.","The use of multiobjective optimization in identifying systems that account for changes in needs (preferences), operating environments, concepts, and analysis models over time is generally not explored.","In terms ofidentifying sets of non-dominated designs, these changes result in the concept of dynamic Pareto frontiers, or dynamic s-Pareto frontiers in cases where sets of system concepts are being evaluated simultaneously over time.","In addition, recognizing the inherent uncertainty associated with predicting future needs or preferences and dynamic s-Pareto frontiers, the incorporation of uncertainty analysis in this improved method is also presented as an additional method improvement."
10.1016/j.envsoft.2007.08.001,Identification of reliable regression- and correlation-based sensitivity measures for importance ranking of water-quality model parameters (2008),The concept is demonstrated through the application of Latin Hypercube Sampling as the sensitivity analysis technique to the DUFLOW water-quality model developed for the Dender River in Belgium.,The results obtained indicate that the Semi-Partial Correlation Coefficient and its rank equivalent the Semi-Partial Rank Correlation Coefficient can be considered adequate measures to assess the sensitivity of the DUFLOW model to the uncertainty in its input parameters.,,,
10.1007/s00158-016-1562-7,High-fidelity aerostructural optimization with integrated geometry parameterization and mesh movement (2017),Capabilities of the framework are demonstrated via a number of applications involving substantial geometric changes.,This paper extends an integrated geometry parameterization and mesh movement strategy for aerodynamic shape optimization to high-fidelity aerostructural optimization based on steady analysis.,"The geometries represented are therefore independent of the mesh used for the flow analysis, which is an important advantage to this approach.",A simple technique is introduced to translate the shape changes described by the geometry parameterization to the internal structure.,The geometry parameterization is integrated with an efficient and robust grid movement algorithm which operates on a set of B-spline volumes that parameterize and control the flow grid.
10.1016/j.jcp.2015.03.047,An adaptive importance sampling algorithm for Bayesian inversion with multimodal distributions (2015),"However, the large number of repetitive forward simulations required in the sampling process could pose a prohibitive computational burden.","In three illustrative examples, the proposed adaptive importance sampling algorithm demonstrates its capabilities of automatically finding a GM proposal with an appropriate number of modes for the specific problem under study, and obtaining a sample accurately and efficiently representing the posterior with limited number of forward simulations.","Parametric uncertainties are encountered in the simulations of many physical systems, and may be reduced by an inverse modeling procedure that calibrates the simulation results to observations on the real system being simulated.",We present in this paper an adaptive importance sampling algorithm to tackle these challenges.,"Following Bayes' rule, a general approach for inverse modeling problems is to sample from the posterior distribution of the uncertain model parameters given the observations."
10.1016/j.jhydrol.2005.07.010,On the assessment of the impact of reducing parameters and identification of parameter uncertainties for a hydrologic model with applications to ungauged basins (2006),We introduce an alternative subsurface flow parameterization into VIC-L to reduce the impacts of model parameter uncertainties on model simulations by reducing the number of model parameters that need to be estimated through a calibration process.,the b parameter that represents the shape of the heterogeneity distribution of effective soil moisture capacity over a study area) has a larger impact on model simulations and could introduce more uncertainty if not estimated appropriately.,"Studies based on the  MOPEX watersheds show that compared to the parameter associated with the new subsurface flow parameterization, the VIC shape parameter (i.e.","Furthermore, investigations on the b parameter suggest that the ensembles (i.e.",The study also shows that appropriate reduction of the number of model parameters is an effective approach to reduce the impacts of parameter uncertainties on model simulations.
10.1016/j.jcp.2016.05.039,Gaussian processes with built-in dimensionality reduction: Applications to high-dimensional uncertainty propagation (2016),A wide range of physical responses exhibit a special structure known as an active subspace (AS).,An AS is a linear manifold of the stochastic space characterized by maximal response variation.,"To train the model, we design a two-step maximum likelihood optimization procedure that ensures the orthogonality of the projection matrix by exploiting recent results on the Stiefel manifold, i.e., the manifold of matrices with orthogonal columns.","In this work, we develop a probabilistic version of AS which is gradient-free and robust to observational noise.",We validate our approach by showing that it can discover the right AS in synthetic examples without gradient information using both noiseless and noisy observations.
10.1016/j.envsoft.2006.03.005,Towards coupling a 3D hydrodynamic lake model with the Canadian Regional Climate Model: Simulation on Great Slave Lake (2007),"For example, a % increase in air temperature and solar radiation was found to result in a .% and .% increase in water surface temperature and .% increase in latent heat flux.",Knowledge of the model sensitivity is crucial for future research in which the hydrodynamic model coupled with the atmosphere will be forced from the CRCM output.,"Recently, it has been recognized that large lakes exert considerable influence on regional climate systems and vice versa and that the Canadian Regional Climate Model (CRCM), which does not currently have a lake component, requires the development of a coupled lake sub-model.",Simulated temperatures compared well with cross-lake temperature observations both at the surface and vertically.,
10.1016/j.jhydrol.2014.07.049,On noise specification in data assimilation schemes for improved flood forecasting using distributed hydrological models (2014),We investigate the effects of noise specification on the quality of hydrological forecasts via an advanced data assimilation (DA) procedure using a distributed hydrological model driven by numerical weather predictions.,The rainfall ensembles are derived from ground-based rain gauge observations for the analysis step and numerical weather predictions for the forecast step.,"The sequential DA procedure is based on () a multivariate rainfall ensemble generator, which provides spatial and temporal correlation error structures of input forcing, and () lagged particle filtering to update past and current state variables simultaneously in a lag-time window to consider the response times of internal hydrologic processes.",The ensemble simulation performs multi-site updating using information from the streamflow gauging network and considers the artificial effects of reservoir release.,
10.1016/j.jcp.2005.02.007,Using stochastic analysis to capture unstable equilibrium in natural convection (2005),The stabilization parameters are shown to be functions of the time-step size.,A summary of the results and findings is provided.,,,
10.1016/j.jhydrol.2007.10.062,Sensitivity study of large-scale particle image velocimetry measurement of river discharge using numerical simulation (2008),"() The LSPIV analysis block performs a classical LSPIV analysis, including geometric transformation of the images, PIV analysis to obtain a surface velocity field, and discharge computation.",The simulator can also be used to check different scenarios and to assess relative importance of the different sources of error.,Journal of Hydrologic Engineering].,"A first validation method consists in the comparison of LSPIV measurements with classic gauging results, in field and laboratory experiments.","These methods have many potential advantages, in comparison with classical river gauging, but they have a fundamental drawback: they are indirect measurements."
10.1016/j.cma.2014.04.014,Simultaneous isogeometrical shape and material design of functionally graded structures for optimal eigenfrequencies (2014),The proposed methodology which utilizes a concurrent procedure by combining the shape and material composition optimization of these structures employs an extended form of the standard IGA method by allowing for gradation of material properties through patches.,,,,
10.1016/j.envsoft.2015.05.002,A GIS plug-in for Bayesian belief networks: Towards a transparent software framework to assess and visualise uncertainties in ecosystem service mapping (2015),"Current attempts to model ecosystem service delivery on a broad, regional scale often depend on indicator-based approaches that are generally not able to fully capture the complexity of ecosystem processes.","In this paper, we discuss a QGIS plug-in which promotes the use of Bayesian belief networks for regional modelling and mapping of ecosystem service delivery and associated uncertainties.",,,
10.1007/s00158-011-0660-9,A new level-set based approach to shape and topology optimization under geometric uncertainty (2011),The proposed method is demonstrated with a bench mark structural design.,Robust designs achieved with the proposed TOGU method are compared with their deterministic counterparts.,"Since geometric uncertainty is embedded in the boundary which is dynamic and changes continuously in the optimization process, topology optimization under geometric uncertainty (TOGU) poses extreme difficulty to the already challenging topology optimization problems.","This paper aims to solve this cutting-edge problem by integrating the latest developments in level set methods, design under uncertainty, and a newly developed mathematical framework for solving variational problems and partial differential equations that define mappings between different manifolds.","Second, a PDE-based approach is employed to overcome the deficiency of conventional level set model which cannot explicitly maintain the point correspondences between the current and the perturbed boundaries."
10.1016/j.jcp.2014.01.002,An adaptive numerical method for solving EDQNM equations for the analysis of long-time decay of isotropic turbulence (2014),"Due to its efficiency and precision, the adaptive formulation of the EDQNM model promises to be an optimal tool to be blended with the methods of the Uncertainty Quantification (UQ) theory, in order to provide new insights about isotropic turbulence decay.","In particular, a reduction up to one order of magnitude in the computational resources required is observed.","For all the initial conditions prescribed, the adaptive numerical method recovers exactly the same solution of the classical version.",The numerical algorithm proves to be progressively more efficient when long-time simulations are performed.,
10.1016/j.jcp.2016.03.047,A stochastic Galerkin method for the Boltzmann equation with uncertainty (2016),We develop a stochastic Galerkin method for the Boltzmann equation with uncertainty.,"The method is based on the generalized polynomial chaos (gPC) approximation in the stochastic Galerkin framework, and can handle random inputs from collision kernel, initial data or boundary data.","In the spatially homogeneous case, we first prove that the analytical solution preserves the regularity of the initial data in the random space, and then use it to establish the spectral accuracy of the proposed stochastic Galerkin method.",,
10.1016/j.cma.2004.12.028,Reliability-based shape optimization of structures undergoing fluid-structure interaction phenomena (2005),The design and imperfection sensitivities are computed by evaluating the analytically derived direct and adjoint coupled aeroelastic sensitivity equations.,The design optimization problem is formulated pursuant to the reliability index and performance measure approaches.,The computational framework is verified by the optimization of three-dimensional wing structures.,The system reliability is evaluated by it first-order reliability analysis method.,"In this paper, after reviewing the state-of-the-art methods in robust and reliability-based design optimization or problems undergoing fluid-structure interaction phenomena, a computational framework is presented that integrities it high-fidelity acroelastic model into reliability-based design optimization."
10.1016/j.jhydrol.2016.03.061,Operational snow mapping with simplified data assimilation using the seNorge snow model (2016),"In this paper the revised seNorge snow model (v...) for snow mapping is described, and a simplified data assimilation procedure is introduced to correct detected snow model biases in near real-time.",The data assimilation procedure is theoretically based on the Bayesian updating paradigm and is meant to be pragmatic with modest computational and input data requirements.,"Frequently updated maps of snow conditions are useful for many applications, e.g., for avalanche and flood forecasting services, hydropower energy situation analysis, as well as for the general public.",Numerical snow models are often applied in snow map production for operational hydrological services.,"The model and analysis codes as well as the ""R"" statistical software are freely available."
10.1016/S0045-7825(99)00209-1,Computational methods for creep fracture analysis by damage mechanics (2000),"In view of these results, the effects of stress-singularity at the crack tip as an essential cause of the mesh-dependence are discussed by analyzing the magnitude of stress in the finite element at the crack-tip.",Some mechanical problems of the computational method of creep fracture analysis based on continuum damage mechanics are discussed.,"Finally, the effects of the preceding damage held on stress singularity of the asymptotic stress field at mode I creep crack are analyzed to furnish a criterion to overcome the mesh-dependence in computational method for creep fracture analysis.",intrinsic feature of the fracture analysis in the framework of continuum theory and the causes of mesh-dependence of the numerical results are discussed.,
10.1016/j.jhydrol.2012.07.026,Comparison and evaluation of spatial interpolation schemes for daily rainfall in data scarce regions (2012),The successful application of regression-based interpolation methods using a high resolution TRMM pattern as covariate is very promising as it is transferable to other data scarce regions.,"To provide spatially distributed rainfall data, point measurements are interpolated.","The study was carried out in the meso-scale catchment of the Mula and the Mutha Rivers ( km()) upstream of the city of Pune, India.","Rainfall data from  rain gauges were spatially interpolated using seven different methods, including Thiessen polygons, statistical, and geostatistical approaches.","By this assessment, the regression-based methods showed the best performance."
10.1016/j.jhydrol.2003.09.005,Multidecadal hydrochemical response of a Sierra Nevada watershed: sensitivity to weathering rate and changes in deposition (2004),"The long-term simulations were stable, but conflicts in the simulation of base cation and silica concentrations indicate that the model has a missing process or misrepresents mineral weathering.",Proxy data of discharge and snowfall were used to develop the necessary inputs for the -year runs.,"Additionally, comparison of annual modeled mass flux to observed mass flux indicates that the model overestimates cation and silica export in dry years and underestimates export in wet years.",,
10.1016/j.jhydrol.2017.02.050,Identification of the dominant hydrological process and appropriate model structure of a karst catchment through stepwise simplification of a complex conceptual model (2017),"For this catchment, the spring discharge is the only available data for the model calibration.","In this paper, we adopt a multi-model framework to identify the dominant hydrological process and appropriate model structure of a karst spring, located in Guilin city, China.",How to find out the appropriate model structure supported by the available data to simulate the catchment is still a big challenge in the hydrological research.,This framework starts with a relative complex conceptual model according to the perception of the catchment and then this complex is simplified into several different models by gradually removing the model component.,The multi-objective approach is used to compare the performance of these different models and the regional sensitivity analysis (RSA) is used to investigate the parameter identifiability.
10.1016/j.jhydrol.2007.04.006,Hydrological modelling of the chaohe basin in china: Statistical model formulation and Bayesian inference (2007),"The difficulties even increase in arid regions with high seasonal variation of precipitation, where the modelled residuals often exhibit high heteroscedasticity and autocorrelation.",The technique was tested with the calibration of the hydrologic sub-model of the Soil and Water Assessment Toot (SWAT) in the Chaohe Basin in North China.,A comparison with an independent error model and with error models that only considered a subset of the suggested techniques clearly showed the superiority of the approach based on all the features (i)-(iv) mentioned above.,The use and assessment of model results for this purpose require a careful calibration and uncertainty analysis.,"Extending earlier work in this field, we developed a procedure to overcome (i) the problem of non-identifiability of distributed parameters by introducing aggregate parameters and using Bayesian inference, (ii) the problem of heteroscedasticity of errors by combining a Box-Cox transformation of results and data with seasonally dependent error variances, (iii) the problems of autocorrelated errors, missing data and outlier omission with a continuous-time autoregressive error model, and (iv) the problem of the seasonal variation of error correlations with seasonally dependent characteristic correlation times."
10.1016/j.cma.2016.03.012,Uncertainty quantification in computational linear structural dynamics for viscoelastic composite structures (2016),This paper deals with the analysis of a stochastic reduced-order computational model in computational linear dynamics for linear viscoelastic composite structures in the presence of uncertainties.,It is shown that the uncertainties on the damping matrix have a strong influence on the observed statistical dispersion of the stiffness matrix.,The computational aspects related to the nonparametric stochastic modeling of the reduced stiffness matrix and the reduced damping matrix that are frequency-dependent random matrices are presented.,"Due to the causality of the dynamical system, these two frequency-dependent random matrices are statistically dependent and are linked by a compatibility equation induced by the causality of the system, involving a Hilbert transform.",The computational framework proposed is based on a recent theoretical work that allows for constructing the stochastic reduced-order model using the nonparametric probabilistic approach.
10.1016/j.jcp.2012.06.002,Sequential data assimilation with multiple models (2012),Data assimilation is an essential tool for predicting the behavior of real physical systems given approximate simulation models and limited observations.,The mathematical equivalence of the iterative method and the direct method is established.,It is desirable to incorporate multiple models into the assimilation procedure in order to obtain a more accurate prediction of the physics than any model alone can provide.,The assimilated solution is a linear combination of all model predictions and data.,
10.1016/j.envsoft.2014.03.007,Spatially-explicit integrated uncertainty and sensitivity analysis of criteria weights in multicriteria land suitability evaluation (2014),"Multiple output suitability maps are generated and summarized using: an average suitability map, a standard deviation uncertainty map, and a number of sensitivity maps.","Areas of high average suitability and low uncertainty signify robust suitability sites, whereas high average suitability and high uncertainty characterize candidate areas.","These candidate areas are potentially suitable but need further examination with variance-based sensitivity analysis, in which the variability of land suitability is decomposed and attributed to individual criteria weights.",We demonstrate how these surfaces help detect critical regions of suitability on the example of habitat suitability evaluation for a wetland plant.,"The resulting sensitivity maps delineate regions of weight dominance, where a particular weight greatly influences the uncertainty of suitability scores."
10.1016/j.cma.2004.04.004,Design across length scales: a reduced-order model of polycrystal plasticity for the control of micro structure-sensitive material properties (2004),The model reduction is extended to the sensitivity analysis and is a key element for the success of computational design of deformation processes.,"Furthermore, novel design problems are introduced for the control of microstructure based on realistic polycrystalline plasticity.",This reduced-order modeling approach is based on the technique of proper orthogonal decomposition (POD) and the method of snapshots.,Numerical examples that highlight the benefits of the continuum sensitivity method and model reduction are presented.,Reduced-order models are developed to model the evolution of microstructure described by an orientation distribution function using a finite element discretization of the orientation space.
10.1016/j.envsoft.2010.09.005,Uncertainty analysis in a GIS-based multi-criteria analysis tool for river catchment management (2011),"The importance of uncertainty analysis has been increasingly recognised, due to the influence of uncertainties in data, models and expert judgements.",The indicator-based method provides a pragmatic approach to communicating areas of uncertainty to decision-makers without assuming any prior knowledge of uncertainty analysis techniques.,This paper analyses uncertainty sources in MCA.,"In this module, the influence of uncertainties on decision-making can be visually explored using an indicator-based method.","Building on this review, an uncertainty analysis module developed for use within a GIS-based MCA tool for catchment management is presented."
10.1016/j.jhydrol.2007.10.010,Runoff and sediment yield modeling from a small agricultural watershed in India using the WEPP model (2008),indicate accurate simulation of runoff from the watershed.,"), Nash-Sutcliffe simulation model efficiency (.-.","), Nash-Sutcliffe simulation model efficiency (.-.)","Initially, the model was calibrated using data from the  monsoon season and subsequently its performance was evaluated by estimating the daily runoff and sediment yield using the monsoon season data of different years.",Performance of the WEPP model for simulation of sediment yield was also evaluated.
10.1016/j.jhydrol.2017.08.015,Representative parameter estimation for hydrological models using a lexicographic calibration strategy (2017),"Besides the similarities of the parameter sets, the goodness-of-fit criteria for the cross-validation were better for the lexicographic approach and the water balance components were also more similar.",(C)  The Authors.,"The criteria for the evaluation of the approach were (i) robustness and transferability of the resulting parameters, (ii) goodness-of-fit criteria in calibration and validation and (iii) time-efficiency.",An order of preference was determined prior to the calibration and the parameters were separated into groups for a stepwise calibration to reduce the search space.,"Furthermore, the parameter sets obtained by the lexicographic calibration strategy for different time periods were much more similar to each other than the parameters obtained by SCE-UA."
10.1016/j.cma.2008.02.034,A computational procedure for response statistics-based optimization of stochastic non-linear FE-models (2008),An illustrative example is presented that shows the efficiency of the proposed methodology: it considers a building finite element model enforced with non-linear hysteretic devices and subject to a stochastic ground acceleration.,An approach for an efficient solution of response statistics-based optimization problems of non-linear FE systems under stochastic loading is presented.,"A sequential approximate optimization approach, where approximate stochastic analyses are used during portions of the optimization process, is implemented in the proposed formulation.","In this approach, analytical approximations of the performance functions in terms of the design variables are considered during the optimization process.",The state of the system is defined in terms of the statistical second-moment characteristics of the structural response.
10.1016/j.envsoft.2017.06.013,Sensitivity and uncertainty analysis of PnET-BGC to inform the development of Total Maximum Daily Loads (TMDLs) of acidity in the Great Smoky Mountains National Park (2017),"Even if current atmospheric deposition is reduced to pre-industrial levels, only one of the twelve impaired streams might be recovered to its site-specific standard by .","The quantified model uncertainty enabled application of an ""exceedance probability"" approach to determine allowable atmospheric deposition in the form of Total Maximum Daily Loads (TMDLs) for twelve acid-impaired streams in Great Smoky Mountains National Park.",Results indicate that acidification of surface water resulting from acidic deposition has been substantial.,,
10.1016/j.jhydrol.2012.03.043,"Quantifying riparian zone structure from airborne LiDAR: Vegetation filtering, anisotropic interpolation, and uncertainty propagation (2012)","EIDW, which accounts for surface anisotropy by converting the remaining elevation points to streamwise co-ordinates, can outperform isoptropic interpolation (IDW) on channel banks, however, performs less well in isotropic conditions, and when local anisotropy is different to that of the main channel.","Understanding and developing methods to deal with such errors is important to inform users of the true quality of laser scanning products, such that they can be used effectively in hydrological applications.","Consequently, it is important that this uncertainty is assessed.",,
10.1016/j.jcp.2016.07.016,Quantifying uncertainties in first-principles alloy thermodynamics using cluster expansions (2016),"Also, the use of the bond stiffness versus bond length approximation to calculate temperature dependent properties from a reduced set of alloy configurations showed similar uncertainty to the approach where all training configurations are considered but at a much reduced computational cost.",The cluster expansion is a popular surrogate model for alloy modeling to avoid costly quantum mechanical simulations.,We found that the uncertainty in the predicted phase transition temperature increases when including the temperature dependence of the effective cluster interactions.,"This methodology is applied to two binary alloys, SiGe and MgLi, including the temperature dependence in their effective cluster interactions.","Furthermore, the coefficients of the model need to be determined from some known data set (training set)."
10.1007/s00158-012-0880-7,Stress constrained topology optimization (2013),"The stress constraints are used together with an objective function that minimizes mass or maximizes stiffness, and in addition, the traditional stiffness based formulation is discussed for comparison.",It can therefore be used to generate conceptual designs for industrial applications.,"However, we restrict the numerical examples to D structures with bilinear quadrilateral elements.","This is done in a general manner, so that different element types and D as well as D structures can be treated.",We give a detailed description of the formulations and the sensitivity analysis.
10.1016/j.jhydrol.2010.12.027,"GIS mapping of regional probabilistic groundwater potential in the area of Pohang City, Korea (2011)",SPC data were then randomly selected in a / ratio to train and validate the model.,"m()/d/m, corresponding to a yield of  m()/d, were input to a spatial database.",The results show that soil texture had the greatest effect on the groundwater potential and ground elevation had the least effect.,"This study analyzed the relationships between groundwater specific capacity (SPC) and its related hydrological factors to assess the sensitivity of each factor and map the regional groundwater potential for the area of Pohang City, Korea, using a geographic information system (GIS) and a probability model.","In the sensitivity analysis, the best accuracy was obtained by omitting ground elevation data (.%), and the worst accuracy resulted when soil texture was not included (.%)."
10.1016/j.cma.2011.06.010,Uncertainty quantification of MEMS using a data-dependent adaptive stochastic collocation method (2011),This paper presents a unified framework for uncertainty quantification (UQ) in microelectromechanical systems (MEMS).,"Since we are primarily interested in quantifying the statistics of the output parameters of interest, we develop an adaptive refinement strategy to efficiently propagate the uncertainty through the device model, in order to obtain quantities like the mean and the variance of the stochastic solution with minimal computational effort.","We consider different electromechanical actuators that operate using a combination of electrostatic and electrothermal modes of actuation, for which high-fidelity numerical models have been developed.",We also validate the method by comparing our results with experimentally determined uncertainties in an electrostatic microswitch.,We show how our framework results in the accurate computation of uncertainties in micromechanical systems with lower computational effort.
10.1016/j.cma.2012.10.016,Uncertainty quantification in computational stochastic multiscale analysis of nonlinear elastic materials (2013),"To overcome the curse of dimensionality, due to the high number of involved random variables, the problem is transformed into another one consisting in identifying the potential on a polynomial chaos expansion.","Several strategies, based on novel algorithms dedicated to high stochastic dimension, are used and adapted for the class of multi-modal random variables which may characterize the potential.",The geometry of the microstructure is random and characterized by a high number of random parameters.,The method is based on a deterministic non-concurrent multiscale approach devoted to micro-macro nonlinear mechanics which leads us to characterize the nonlinear constitutive equation with an explicit continuous form of the strain energy density function with respect to the large scale Cauchy Green strain states.,"At the microscale level, the nonlinear constitutive equation of the material is characterized by a stochastic potential for which a polynomial chaos representation is used."
10.1007/s00158-014-1108-9,A parallel aerostructural optimization framework for aircraft design studies (2014),"To address this limitation, we present a computationally efficient aerostructural design framework for initial aircraft design studies that uses a full finite-element model of key structural components to better assess the potential benefits of new technologies.","To demonstrate the capabilities of the framework, we present a design optimization of a large transport aircraft wing that includes a detailed structural design parametrization.",The results demonstrate that the proposed framework can be used to make detailed structural design decisions to meet overall aircraft mission requirements.,We use a three-dimensional panel method to predict the aerodynamic forces and couple the lifting surface deflections to compute the deformed aerodynamic flying shape.,"However, this limitation is too restrictive when we wish to assess the relative benefits of new structural technologies and new aircraft configurations early in the design process."
10.1016/S0045-7825(02)00259-1,Design sensitivity analysis of structures based upon the singular value decomposition (2002),"As the squares of singular values are the bounds of power, energy and power spectral density ratios between the input and output vectors, shaping the singular values of a structure is equivalent to shaping the response of the structure, Comparison is made of the proposed sensitivity analysis based upon the SVD with the conventional techniques.","As shown, design sensitivity analysis based upon the SVD can give good insight into static and dynamic response characteristics of structures: it is more informative than eigenvalue design sensitivity analysis and.",Numerical examples are presented to illustrate the proposed approach.,computationally advantageous in case of multiple load cases.,
10.1007/s00158-010-0592-9,Maximum stiffness and minimum weight optimization of laminated composite beams using continuous fiber angles (2011),A sequence of closely related problems with an increasing number of design variables is treated.,This modeling approach is therefore an attractive alternative in computationally intensive applications at the conceptual design stage where the focus is on the global structural response.,An optimization strategy is presented which aims at enabling the use of fiber angles as continuous design variables albeit the problems may have many local minima.,This paper deals with identification of optimal fiber orientations and laminate thicknesses in maximum stiffness and minimum weight design of laminated composite beams.,The results indicate that the devised strategy is well suited for finding optimal fiber orientations and laminate thicknesses in the design of slender laminated composite structures.
10.1016/j.envsoft.2013.09.022,A General Probabilistic Framework for uncertainty and global sensitivity analysis of deterministic models: A hydrological case study (2014),"The results of the framework can be used in a loop for model improvement, parameter estimation or model simplification.",The analysis is conducted with the variance-based approach of Sobol/Saltelli where first and total sensitivity indices are estimated.,The results show that the sources of uncertainty are different for each output considered and it is necessary to consider multiple output variables for a proper assessment of the model.,"The framework is applied to SWAP, a  hydrological model for the transport of water, solutes and heat in unsaturated and saturated soils.","Improvements on the performance of the model can be achieved reducing the uncertainty in the observations, in the soil parameters and in the weather data."
10.1016/j.cma.2017.01.042,Bayesian model selection using automatic relevance determination for nonlinear dynamical systems (2017),"Given noisy measurement data, a parametrically flexible model is envisioned to represent the dynamical system.",The resulting joint prior pdf is the combination of parametrized ARD priors assigned to parameters whose relevance to the system dynamics is questionable and the known prior pdf for parameters whose relevance is known a priori.,"Bayesian model selection is augmented with automatic relevance determination (ARD) to perform model reduction of complex dynamical systems modelled by nonlinear, stochastic ordinary differential equations (ODE).",The optimal nested model with the maximum posterior model probability is chosen as the overall optimal model.,An efficient numerical implementation for evidence computation using Markov Chain Monte Carlo sampling of the parameter posterior distribution is presented for the case when the analytical evaluation of evidence is not possible.
10.1007/s00158-015-1246-8,Analytical sensitivity in topology optimization for elastoplastic composites (2015),It is verified that the proposed method can provide highly accurate sensitivity enough to obtain reliable optimization results by comparing with that evaluated from the finite difference approach.,The present study proposes a topology optimization of composites considering elastoplastic deformation to maximize the energy absorption capacity of a structure under a prescribed material volume.,"For optimization applying a gradient-based method, the accuracy of sensitivities iscritical to obtain a reliable optimization result.","In this study, we formulate the analytical sensitivity for topology optimization considering elastoplastic deformationand its path-dependency.",
10.1016/j.jhydrol.2015.02.013,"Global sensitivity analysis in hydrological modeling: Review of concepts, methods, theoretical framework, and applications (2015)","Finally, some conclusions and guidance recommendations on SA in hydrological modeling are provided, as well as a list of important future research directions that may facilitate more robust analyses when assessing hydrological modeling performance.","To better understand how these complex models work, efficient SA methods should be applied before the application of hydrological modeling.",The common definitions of SA and the typical categories of SA methods are described.,This study provides a comprehensive review of global SA methods in the field of hydrological modeling.,The advantages and disadvantages are also discussed and summarized.
10.1016/j.envsoft.2010.06.001,Spatial sensitivity analysis of multi-criteria weights in GIS-based land suitability evaluation (2010),A case study of irrigated cropland suitability assessment addressing the application of the new GIS-based AHP-SA tool is described.,"It demonstrates that the tool is spatial, simple and flexible.","With growing interest in extending GIS to support multi-criteria decision-making (MCDM) methods, enhancing GIS-based MCDM with sensitivity analysis (SA) procedures is crucial to understand the model behavior and its limitations.",A methodology was developed to perform simulations where the weights associated with all criteria used for suitability modelling were varied one-at-a-time (OAT) to investigate their relative impacts on the final evaluation results.,
10.1016/j.cma.2009.06.010,Sensitivity analysis in kinematically incompatible models (2009),"In this sense, the present work is concerned with the sensitivity analysis of the variational formulation corresponding to the kinematically incompatible models when the boundary over which the incompatibility between the models takes place is changed.","Assuming the presence of a discontinuity in the fields over a given interface between two incompatible models, this analysis allows to measure the sensitivity of a given cost functional when the location of such interface is changed.","The application for which this analysis is envisaged is to assess the correctness, or incorrectness, in the definition of the positioning of such coupling interface between dimensionally-heterogeneous domains.",,
10.1016/S0045-7825(03)00274-3,Design sensitivity analysis and topology optimization of displacement-loaded non-linear structures (2003),"However, when the displacement-loaded system is used, there is no convergence difficulty.","In the adjoint variable method, the solution space requires just homogeneous boundary conditions even if the original system has nonhomogeneous ones.",,,
10.1016/j.envsoft.2012.02.008,Managing uncertainty in integrated environmental modelling: The UncertWeb framework (2013),"We conclude by highlighting areas that require further research and development in UncertWeb, such as model calibration and inference within complex environmental models.",We describe the scope and architecture required to support uncertainty management as developed in UncertWeb.,"On the other hand, the rich array of modelling frameworks and simulation tools which support uncertainty propagation in complex and chained models typically lack the benefits of web based solutions such as ready publication, discoverability and easy access.",In this article we describe the developments within the UncertWeb project which are designed to provide uncertainty support in the context of the proposed 'Model Web'.,"Web-based distributed modelling architectures are gaining increasing recognition as potentially useful tools to build holistic environmental models, combining individual components in complex workflows."
10.1016/j.jcp.2014.08.023,Automated divertor target design by adjoint shape sensitivity analysis and a one-shot method (2014),"Furthermore, by using a one-shot method the entire optimization problem can be solved at an equivalent cost of only a few forward simulations.","The methodology is applied to target shape design for uniform power load, in simplified edge plasma geometry.",Such an optimization approach to divertor target shape design is elaborated in the present paper.,"Using a continuous adjoint framework, design sensitivities can be computed at a cost of only two edge plasma simulations, independent of the number of design variables.","Due to the complex edge plasma flows and large number of design variables, this method is computationally very demanding."
10.1007/s00158-004-0415-y,Structural optimization complexity: what has Moore's law done for us? (2004),"However, these are supplemented with other structural optimization examples to illustrate the universality of the message.",This is due to the constant increase in the required fidelity (and hence complexity) of analysis models.,"In this paper, we review how increases in computer power were utilized in structural optimization.",We use examples of optimum design of composite structures to guide the discussion due to our familiarity with such problems.,"We resolve problem complexity into components relating to complexity of analysis model, analysis procedure and optimization methodology."
10.1016/j.jcp.2010.05.036,Uncertainty quantification via random domain decomposition and probabilistic collocation on sparse grids (2010),"A series of one-, two-, and three-dimensional computational examples demonstrate that the combined RDD-PCM approach yields efficient, robust and non-intrusive approximations for the statistics of diffusion in random composites.",Quantitative predictions of the behavior of many deterministic systems are uncertain due to ubiquitous heterogeneity and insufficient characterization by data.,,,
10.1016/S1364-8152(02)00017-8,An organic matter and nitrogen dynamics model for the ecological analysis of integrated aquaculture/agriculture systems: II. Model evaluation and application (2002),"Model sensitivity analysis results showed that research on stocking density, sediment processes and water management practices was required, in order to improve the overall understanding of the functioning of the integrated aquaculture/agriculture system.",Application of the model to investigate the effects of different cycling pathways on nitrogen retention and productivity showed that the recycling of plant wastes to aquaculture ponds had a major effect in reducing system nitrogen losses and increasing system productivity.,The performance of a model developed to simulate organic matter and nitrogen dynamics in integrated aquaculture/agriculture systems was evaluated using sensitivity analysis and model verification procedures with data from three sites.,The results of the modeling study suggest that the system nitrogen status may be more important than the number of pathways in determining the number and type of cycling pathways that should be incorporated in integrated aquaculture/agriculture system.,
10.1016/j.cma.2004.06.046,Adaptivity in linear elastic fracture mechanics based on shape sensitivity analysis (2005),The shape derivative of the total potential energy stored in the cracked body <(Pi)over dot > depends on the displacement field u and on the shape change velocity field V which characterize the crack growth.,This error estimator has been specifically designed to evaluate the energy release rate in mesh refinement or re-meshing procedures so as to obtain improved meshes for which the optimal rate of convergence is recovered even in a case of singularities.,"To do this, we adopt as cost function the total potential energy and as state equation the equilibrium equation.",,
10.1016/j.cma.2007.09.026,Structural dynamics challenge problem: Summary (2008),() Validation of the substructure mathematical model.,Specifically the following issues are considered: () Development of a mathematical framework for uncertainty quantification of a substructure.,() Calibration of a mathematical model for the substructure.,,
10.1016/j.jcp.2015.04.030,POD/DEIM reduced-order strategies for efficient four dimensional variational data assimilation (2015),This work studies reduced order modeling (ROM) approaches to speed up the solution of variational data assimilation problems with large scale nonlinear dynamical models.,It is shown that a key requirement for a successful reduced order solution is that reduced order Karush-Kuhn-Tucker conditions accurately represent their full order counterparts.,"In the case of Petrov-Galerkin projection, stabilization strategies must be considered for the reduced order models.","For the first time POD, tensorial POD, and discrete empirical interpolation method (DEIM) are employed to develop reduced data assimilation systems for a geophysical flow model, namely, the two dimensional shallow water equations.",
10.1016/j.jcp.2012.07.008,A reduced basis method for electromagnetic scattering by multiple particles in three dimensions (2012),"The emphasis is on problems that need to be solved rapidly to accurately simulate the interaction of scattered fields under parametric variation, e. g., for design, detection, or uncertainty quantification.","The parametrization may describe the location, orientation, size, shape and number of scattering bodies as well as properties of the source field such as frequency, polarization and incident direction.",We consider the development of efficient and fast computational methods for parametrized electromagnetic scattering problems involving many scattering three dimensional bodies.,"The approach includes (i) a computationally intensive offline procedure to create a selection of a set of snapshot parameters and the construction of an associated reduced basis for each reference scatterer and (ii) an inexpensive online algorithm to generate the surface current and scattered field of the parametrized configuration, for any choice of parameters within the parameter domains used in the offline procedure.",Comparison of our numerical results with directly measured results for some benchmark configurations demonstrate the power of our method to rapidly simulate the interacting electromagnetic fields under parametric variation of the overall multiple particle configuration.
10.1007/s00158-011-0653-8,Reliability-based design optimization using kriging surrogates and subset simulation (2011),The adaptive surrogate-based strategy for reliability estimation is finally involved into a classical gradient-based optimization algorithm in order to solve the RBDO problem.,The surrogate error onto the limit-state surfaces is propagated to the failure probabilities estimates in order to provide an empirical error measure.,"Starting with the premise that simulation-based approaches are not affordable for such problems, and that the most-probable-failure-point-based approaches do not permit to quantify the error on the estimation of the failure probability, an approach based on both metamodels and advanced simulation techniques is explored.",Reliability and reliability sensitivity analyses are performed by means of the subset simulation technique for the sake of numerical efficiency.,This error is then sequentially reduced by means of a population-based adaptive refinement technique until the kriging surrogates are accurate enough for reliability analysis.
10.1016/j.jhydrol.2003.10.003,Using a multiobjective approach to retrieve information on surface properties used in a SVAT model (2004),"A procedure for specifying surface properties from MOGSA results was tested on the thermal and hydraulic soil parameters, and evaluated through the SiSPAT-RS model performance.","As a preliminary step before data assimilation in the model, the objectives of this study were () to apply a multiobjective approach for retrieving quantitative information about the surface properties from different surface measurements and () to determine the potential of the SiSPAT-RS model to be applied with 'little' a priori information about input parameters.",The required accuracy of the surface properties depends on the model complexity and their misspecification can affect model performance.,"To reach these goals, the ability of the Multiobjective Generalized Sensitivity Analysis (MOGSA) algorithm to determine and quantify the most influential input parameters of the SiSPAT-RS model on several simulated output variables, was investigated.","Although slightly lower than a reference simulation, the performance were satisfactory and suggested that complex-SVAT models can be driven with little a priori information"
10.1016/j.cma.2014.07.002,Isogeometric shape design sensitivity analysis of stress intensity factors for curved crack problems (2014),"Compared with the conventional finite element approach, a higher continuity of stress and strain fields are expected in the interaction integral domain.",A direct differentiation method is employed for the design sensitivity analysis and the size and orientation of the crack are selected as design variables.,"The CAD-based exact representation of tangential and normal vectors enables us to exactly define a local coordinate system at the crack-tip, whose shape dependency naturally leads to configuration design variations that include the change of crack orientation.",An isogeometric shape design sensitivity analysis method is developed for the stress intensity factors (SIFs) in curved crack problems.,The precise evaluation of the crack-face integral as well as the interaction integral is essential for the computation of the stress intensity factors for the curved crack problems in a mixed-mode.
10.1016/j.cma.2005.08.018,Numerical modelling of welding (2006),The paper focuses on different modelling aspects.,The most important modelling issues are the models for heat input and material behaviour.,,,
10.1016/S0045-7825(00)00213-9,Shape optimization and preform design in metal forming processes (2000),"Weak shape sensitivity equations are developed that are consistent with the kinematic analysis, constitutive sub-problem as well as the analysis of the contact/friction sub-problem used in the solution of the direct deformation problem, The shape sensitivities are defined in a rigorous sense and the linear sensitivity analysis is performed in an infinite-dimensional continuum framework, The direct deformation and the sensitivity; deformation problems are implemented using the finite element method, The shape sensitivity analysis is validated bq a comparison of the results with those obtained from the solution of the perturbed direct deformation problem (i.e.",A continuum sensitivity analysis is presented for the computation of the shape sensitivity of finite: hyperelastic-viscoplastic deformations involving contact with friction using a direct differentiation method.,"using finite differences), Finite-dimensional gradients of objective functions are then computed using the results of the shape sensitivity analysis for the purpose of preform design and shape optimization in metal forming, The effectiveness of the proposed methodology is demonstrated by solving practical shape optimal design problems in forging processing, (C)  Elsevier Science B.V, All rights reserved.",,
10.1016/j.envsoft.2012.02.014,"Time-scale dependence in numerical simulations: Assessment of physical, chemical, and biological predictions in a stratified lake at temporal scales of hours to months (2012)",This was confirmed by wavelet analysis in both the time and frequency domains.,"The use of wavelet analysis is novel to aquatic ecosystem modeling, is complementary to traditional goodness-of-fit metrics, and allows for assessment of variability at specific temporal scales.",We evaluated the predictive ability of a one-dimensional coupled hydrodynamic-biogeochemical model across multiple temporal scales using wavelet analysis and traditional goodness-of-fit metrics.,"In this way, the effect of processes operating at distinct temporal scales can be isolated and better understood, both in situ and in silico.","Although the magnitude and timing of physical and biological changes were simulated adequately at the seasonal time scale through calibration, time scale-specific dynamics, for example short-term cycles, were difficult to reproduce, and were relatively insensitive to the effects of varying parameters."
10.1016/j.cma.2013.06.010,Towards simultaneous reduction of both input and output spaces for interactive simulation-based structural design (2013),Engineering design problems generally involve a high-dimensional input space of design variables yielding an output space by means of costly high-fidelity evaluations.,The output space is reduced using constrained Proper Orthogonal Decomposition.,"In this paper, we propose a simultaneous meta-modeling protocol for both input and output spaces.",Geometric parameterization methods in traditional CAD present difficulties in expressing these constraints leading to a high failure rate and the generation of inadmissible shapes.,"In order to decrease the overall cost, reduced-order models for the output space such as Proper Orthogonal Decomposition (POD) and Proper Generalized Decomposition (PGD) are an active area of research."
10.1007/s00158-006-0025-y,Update strategies for kriging models used in variable fidelity optimization (2006),One solution to this problem would be to replace the kriging models with traditional Taylor series response surface models.,"The scheme uses the trust region ratio (TR-MUMS), which is a ratio that compares the approximation to the true model.",Two demonstration problems are used to evaluate the proposed method: an internal combustion engine sizing problem and a control-augmented structural design problem.,"In this paper, a metamodel update management scheme (MUMS) is proposed to reduce the cost of using kriging models sequentially by updating the kriging model parameters only when they produce a poor approximation.",Many optimization methods for simulation-based design rely on the sequential use of metamodels to reduce the associated computational burden.
10.1016/j.cma.2010.12.012,A hierarchical framework for statistical model calibration in engineering product development (2011),A cellular phone is used to demonstrate the hierarchical calibration framework of the computational models presented in this paper.,"The calibration execution activity takes a bottom-up approach, which systematically improves the predictive capability of the computational models from the lowest level to the highest using the statistical calibration technique.",The procedure consists of two activities: () calibration planning (top-down) and () calibration execution (bottom-up).,"As the role of computational models has increased, the accuracy of computational results has been of great concern to engineering decision-makers.","Then, an engineered system can be decomposed into subsystems or components of which computational models are better understood in terms of PoF mechanisms or system performances of interest."
10.1016/j.cma.2017.08.044,A physical domain-based substructuring as a framework for dynamic modeling and reanalysis of systems (2017),A comprehensive physical domain-based formulation of reduced-order models based on dominant and residual normal modes and interface reduction is presented.,Special attention is considered to the proper treatment of residual normal modes in the context of system reanalyses and sensitivity analyses.,Numerical results show that the technique allows an effective dynamic modeling and reanalysis of a class of structural models.,,
10.1016/j.cma.2016.08.016,Large-scale robust topology optimization using multi-GPU systems (2016),Data-level parallelism with different granularities is then exploited for the efficient resolution of each simulation model and the computation required by the topology optimization process.,"For these reasons, the efficient resolution of robust topology optimization with large models remains an important computational challenge.",Such a proposal exploits the multilevel parallelism provided by multi-GPU systems for the parallel execution both within FE models and through uncertainty propagation methods.,Robust topology optimization of continuum structures is an intensive computational task due to the use of uncertainty propagation methods to estimate the statistical metrics within the topology optimization process.,Task-level parallelism is used to concurrently evaluate the independent simulation models arising from a sparse grid stochastic collocation method.
10.1016/j.jhydrol.2016.03.001,A joined multi-metric calibration of river discharge and nitrate loads with different performance measures (2016),"Using a multi-metric performance approach, the simultaneous multi-variable calibration led to a balanced model result for all magnitudes of discharge and nitrate loads.","The calibration of these models is a crucial step to adapt the model to the catchment conditions, allowing effective simulations of environmental processes.",This study presents a joined multi-metric calibration of discharge and nitrate loads simulated with the ecohydrological model SWAT.,"In that manner, plausible results were obtained for discharge and nitrate loads in the same model run.",The results show that a separate assessment of five different magnitudes improves the calibrated nitrate loads.
10.1016/j.jcp.2017.04.057,A robust bi-orthogonal/dynamically-orthogonal method using the covariance pseudo-inverse with application to stochastic flow problems (2017),The robustness of the proposed method stems from addressing the following issues in the DO/BO formulation: (i) eigenvalue crossing: we resolve the issue of eigenvalue crossing in the BO formulation by switching to the DO near eigenvalue crossing using the equivalence theorem and switching back to BO when the distance between eigenvalues is larger than a threshold value; (ii) ill-conditioned covariance matrix: we utilize a pseudo-inverse strategy to invert the covariance matrix; (iii) adaptivity: we utilize an adaptive strategy to add/remove modes to resolve the covariance matrix up to a threshold value.,"Both approaches are variants of a generalized Karhunen-Loeve (KL) expansion in which both the stochastic coefficients and the spatial basis evolve according to system dynamics, hence, capturing the low-dimensional structure of the solution.","Specifically, the BO formulation may fail due to crossing of the eigenvalues of the covariance matrix, while both BO and DO become unstable when there is a high condition number of the covariance matrix or zero eigenvalues.","We demonstrate the capability of the proposed methodology with several numerical examples, namely (i) stochastic Burgers equation: we analyze the performance of the method in the presence of eigenvalue crossing and zero eigenvalues; (ii) stochastic Kovasznay flow: we examine the method in the presence of a singular covariance matrix; and (iii) we examine the adaptivity of the method for an incompressible flow over a cylinder where for large stochastic forcing thirteen DO/BO modes are active.","When the total variance approaches zero, we show that the DO/BO formulation becomes equivalent to the evolution equation of the Optimally Time-Dependent modes []."
10.1016/j.cma.2004.10.015,A new adaptive remeshing scheme based on the sensitivity analysis of the SPR point wise error estimation (2006),The capability of the presented sensitivity analysis for the detection of pollution error has also been tested.,This strategy produces very cheap meshes for the accurate evaluation of stresses at specific points.,A new adaptive remeshing strategy based on the sensitivity analysis of the point wise error estimation has been developed and tested.,The numerical accuracy of the presented sensitivity analysis has been tested by perturbing a mesh.,This paper presents a formulation for the obtainment of the sensitivity analysis of a point wise error estimator with respect to the nodal coordinates using the adjoint state method.
10.1016/j.cma.2014.01.013,Generalized variability response functions for two-dimensional elasticity problems (2014),The ability to determine probabilistic characteristics of response quantities in structural mechanics (e.g.,The key property of the VRF in its classical sense is its independence from the marginal probability distribution function (PDF) and the spectral density function (SDF) of the uncertain system parameters (it depends only on the deterministic structural configuration and boundary conditions).,"displacements, stresses) as well as effective material properties is restricted due to lack of information on the probabilistic characteristics of the uncertain system parameters.","For statically indeterminate structures, the Monte Carlo based generalized variability response function (GVRF) methodology has been proposed recently as a generalization of the VRF concept to indeterminate linear and some nonlinear beams.",The concept of the variability response function (VRF) has been proposed as a means to systematically capture the effect of the stochastic spectral characteristics of uncertain system parameters modeled by homogeneous random fields on the uncertain structural response.
10.1007/s00158-009-0362-8,Sensitivity analysis of vibro-acoustic systems in statistical energy analysis framework (2010),"The above equations are applied to a simple model of three plates, joined in the form of a 'Z', to minimize the total energy of one of the plates.",The results of this paper can be useful to optimization of vibro-acoustic systems at the drawing board stage in the SEA framework.,It has been verified that these approaches lead to the same results and the difference between them is only with respect to the computational efficiency.,Equations for computing these sensitivities for a general SEA model are obtained from two different approaches: () direct method and () adjoint method.,The main objective of this paper is to present first and second-order sensitivity analysis of vibro-acoustic systems in the statistical energy analysis (SEA) frame work.
10.1016/j.envsoft.2015.09.002,Assessment of a parallel evolutionary optimization approach for efficient management of coastal aquifers (2015),This study presents a parallel evolutionary optimization approach to determine optimal management strategies of large-scale coastal groundwater problems.,"By implementing the parallelization strategy, a speedup ratio of up to .","Based on solution quality and computational time criteria, the CACO robustness is observed in comparison to other EAs.",,
10.1016/j.envsoft.2015.01.008,"Rainfall-runoff modeling, parameter estimation and sensitivity analysis in a semiarid catchment (2015)","Finally, the Morris method is used to analyze model parameters sensitivity for the objective functions NSE and RE.","The model is used to simulate discharge in the Luanhe River basin, a semiarid region.","In addition, the studies indicate that the HIMS model with all-gauge data improves runoff prediction compared with single-gauge data.",The model includes nine parameters in need of calibration.,
10.1016/j.jcp.2017.07.008,Impact of parametric uncertainty on estimation of the energy deposition into an irradiated brain tumor (2017),Predictions of the total energy deposited into a brain tumor through X-ray irradiation are notoriously error-prone.,"A nonlinear radiation-diffusion equation dramatically magnifies the coefficient of variation of the uncertain parameters, yielding a large coefficient of variation for the predicted energy deposition.","Our analysis also reveals that SC outperforms standard Monte Carlo, but its relative efficiency decreases as the number of uncertain parameters increases from one to three.",This demonstrates that accurate prediction of the energy deposition requires a proper treatment of even small parametric uncertainty.,We investigate how this predictive uncertainty is affected by uncertainty in both the location of the region occupied by a dose-enhancing iodinated contrast agent and the agent's concentration.
10.1016/j.cma.2007.03.009,Aeroelastic design optimization for laminar and turbulent flows (2008),The structure is modeled via a geometrically nonlinear finite element method.,"The design of flexible structures undergoing aeroelastic deformations is a challenging task, in particular if the prediction of the fluid loads and the evaluation of the aerodynamic performance criteria require accounting for laminar and turbulent effects.",This paper presents a general optimization methodology for fluid-structure interaction problems based on turbulent flow models.,The global design sensitivity equations are presented and solution methods for computing the numerically consistent and approximated design sensitivities are introduced.,The potential of the overall optimization methodology is illustrated by the shape and thickness optimization of a realistic wing.
10.1016/j.cma.2013.09.003,Parametric solutions involving geometry: A step towards efficient shape optimization (2014),"Thus, a direct numerical solution is needed for each choice of the process parameters, with the subsequent impact on the computing time.","Then, an appropriate cost function is evaluated and its optimality checked.",Usual strategies proceed by defining a trial choice of those parameters and then solving the resulting model.,"Optimization of manufacturing processes or structures involves the optimal choice of many parameters (process parameters, material parameters or geometrical parameters).","While the optimum is not reached, the process parameters should be updated by using an appropriate optimization procedure, and then the model must be solved again for the updated process parameters."
10.1007/s00158-014-1153-4,Cable stretching force optimization of concrete cable-stayed bridges including construction stages and time-dependent effects (2015),This paper presents an optimization algorithm to compute the prestressing forces on concrete cable-stayed bridges to achieve the desired final geometry.,"The structural analysis includes the load history and geometry changes due to the construction sequence and the time-dependent effects due to creep, shrinkage and aging of the concrete.",An entropy-based approach was used for structural optimization and discrete direct sensitivity analysis was used to evaluate the structural response to changes in the design variables.,,
10.1016/j.jcp.2016.12.015,A robust and efficient stepwise regression method for building sparse polynomial chaos expansions (2017),The variable selection criterion is based on efficient tools relevant to probabilistic method.,A common approach to address such problems is to make use of sparse PC expansions.,"Moreover, the most important stochastic features are captured at a reduced computational cost compared to the LAR method.",The results also demonstrate the superior robustness of the method by repeating the analyses using random experimental designs.,The computational cost of classical PC solution schemes is unaffordable as the number of deterministic simulations to be calculated grows dramatically with the number of stochastic dimension.
10.1016/j.jhydrol.2015.05.046,Uncertainty analysis of support vector machine for online prediction of five-day biochemical oxygen demand (2015),"In this research, a proper methodology was proposed to determine the uncertainty of support vector machine (SVM) for the prediction of five-day biochemical oxygen demand (BOD).","Besides, results showed that the SVM model had acceptable uncertainty in BOD prediction.","By this methodology, the parameters of SVM model will be obtained  times, giving various predicted BOD values each time.",Uncertainty is considered as one of the most important limitations for applying the results of artificial intelligence techniques (AI) in water quality management to obtain appropriate control strategies.,
10.1016/j.envsoft.2011.08.010,Sobol' sensitivity analysis of a complex environmental model (2011),"Sensitivity analysis (SA) results enable the selection of the parameters to include in a calibration procedure, but can also assist in the identification of the model processes.","Additionally, a sensitivity analysis can yield crucial information on the use and meaning of the model parameters.","The analysis also supports the identification of model processes, parameter values and parameter interaction effects.",pointing out  significant pairwise interactions.,"It is also shown that the Sobol' sensitivity analysis enhances the understanding of the model, by e.g."
10.1016/j.cma.2014.03.009,A new perspective on the solution of uncertainty quantification and reliability analysis of large-scale problems (2014),The purpose of this work is to perform an assessment of the range of the relative superiority of these approaches with regard to a variety of stochastic parameters.,"In both approaches, the solution of the resulting algebraic equations is performed with a combination of primal and dual domain decomposition methods implementing specifically tailored preconditioners.","The solution of repeated simulations of the Monte Carlo method is accelerated with an A-orthogonalization procedure aiming at reducing the iterations of subsequent simulations, while the solution of the augmented equations of the stochastic Galerkin method is enhanced with preconditioners which combine the block diagonal features of the resulting matrices as well as the sparsity pattern of the off block-diagonal terms.",This work revisits the computational performance of non-intrusive Monte Carlo versus intrusive Galerkin methods of large-scale stochastic systems in the framework of high performance computing environments.,
10.1016/j.envsoft.2014.02.014,"Environmental comprehensive assessment of agricultural systems at the, farm level using fuzzy logic: A case study in cane farms in Iran (2014)",We also tried to make an analysis on the efficiency of current mathematical parameters in the development of our fuzzy model.,There is currently very little literature on the topic of the best selection of parameters for development of expert based inference models.,"To validate the developed model, we inserted several cycles of analysis using graphical and global sensitivity methods on the model and compared the model outcomes with experts' viewpoints.","Finally, in a practical example we demonstrate the applicability of the developed model for improvement of environmental status of the cane farming in Iran.","Development of a fuzzy inference model is a complex multi-step process in which we encounter a large number of parameters such as type and number of membership functions, fuzzy operators, defuzzification and implication methods and etc."
10.1007/s00158-010-0513-y,Multidisciplinary design optimization with discrete and continuous variables of various uncertainties (2010),"This paper proposes the formula of RFCDV (Random/Fuzzy Continuous/Discrete Variables)Multidisciplinary Design Optimization (RFCDV-MDO), uncertainty analysis for RFCDV-MDO, and a method of RFCDV-MDO within the framework of Sequential Optimization and Reliability Assessment (RFCDV-MDO-SORA) to solve RFCDVMDO problems.","Moreover, both aleatory and epistemic uncertainties may exist.",,,
10.1007/s00158-014-1100-4,Continuum shape sensitivity analysis and what-if study for two-dimensional multi-scale crack propagation problems using bridging scale decomposition (2015),The finite difference part of the sensitivity analysis is only intended for calculating the sensitivity of crack growth speed based on the analytically obtained sensitivity coefficients of structural responses.,"It is also demonstrated through a what-if study that with an adequate performance measure, the impact of macroscopic shape changes on microscopic crack propagation speed can be accurately predicted.","Due to the fact that the crack propagation speed in an atomistic simulation is discrete in design, and cannot be formulated as a continuous function of shape design variables, we propose a hybrid method that combines analytical sensitivity analysis with finite difference approach.","Furthermore, we evaluate and compare several performance measures that quantify crack propagation speed based on crack tip locations for sensitivity analysis and ultimately for structural optimization.",This paper presents a shape sensitivity analysis and what-if study for two-dimensional multi-scale crack propagation problems using bridging scale decomposition.
10.1007/s00158-016-1500-8,Error estimation of load identification based on linear sensitivity analysis and interval technique (2017),"The results show that the measurement errors of damping loss factors and coupling loss factors have a large effect on identified load, so the measurement errors of damping loss factors and coupling loss factors are non-ignorable when the high-frequency load identification based on SEA is carried out.","By considering the damping loss factors and coupling loss factors with measurement errors as interval variables, the errors in identified loads can finally be estimated.",The presented interval approach is demonstrated through the simulated study for a two-plate coupling structure and the simulated study for a plate-shell coupling structure.,"Meanwhile, the identified load with considering the measurement errors of the damping loss factors and coupling loss factors is compared with that without considering the measurement errors of the damping loss factors and coupling loss factors.",
10.1016/j.cma.2003.05.001,Spectral stochastic homogenization of divergence-type PDEs (2004),"The formulation yields a chaos decomposition for the predicted behavior of the homogeneous medium that captures, in addition to the effect of heterogeneity, the effect of variability.",The framework of homogenization is adopted to describe an effective medium that is equivalent in some sense to a heterogeneous medium of interest.,,,
10.1016/S0045-7825(00)00227-9,Topology and shape optimization for elastoplastic structural response (2001),"In shape optimization, the derivatives of the state variables with respect to the optimization variables are evaluated analytically by a variational direct approach.","In topology optimization, a geometrically adaptive procedure is additionally applied in order to increase the efficiency and to avoid artificial stress singularities.",The objective of the design problem is to maximize the structural ductility in the elastoplastic range while the mass in the design space is prescribed.,"For topology optimization problems, the gradient of the ductility is determined by the variational adjoint approach.","It is a common practice to base both, material topology optimization as well as a subsequent shape optimization on linear elastic response."
10.1016/j.cma.2008.12.027,Optimization and real-time control for laser treatment of heterogeneous soft tissues (2009),Predicting the outcome of thermotherapies in cancer treatment requires an accurate characterization of the bioheat transfer processes in soft tissues.,This computational strategy can be applied to other thermotherapies using the heat source such as radio frequency or high intensity focused ultrasound.,,,
10.1016/j.jhydrol.2014.06.052,Comparative evaluation of maximum likelihood ensemble filter and ensemble Kalman filter for real-time assimilation of streamflow data into operational hydrologic models (2014),"For ensemble forecasting, ensemble Kalman filter (EnKF) is an appealing candidate for familiarity and relative simplicity.","In this work, we apply MLEF and EnKF as a fixed lag smoother to the Sacramento (SAC) soil moisture accounting model and unit hydrograph (UH) for assimilation of streamflow, mean areal precipitation (MAP) and potential evaporation (MAPE) data for updating soil moisture states.",Various data assimilation (DA) methods have been used and are being explored for use in operational streamflow forecasting.,"As such, without an iterative approach, EnKF may not be appropriate for assimilating streamflow data for updating soil moisture states due to the strong nonlinear relationships between the two.","Maximum likelihood ensemble filter (MLEF), on the other hand, is not subject to the above limitation."
10.1016/j.jhydrol.2010.01.025,Analysis of parameter uncertainty in semi-distributed hydrological models using bootstrap method: A case study of SWAT model applied to Yingluoxia watershed in northwest China (2010),Only -% of the observed runoff data fall inside the % simulation confidence intervals in the calibration and validation periods.,The uncertainty of model parameters is one of the major uncertainty sources in hydrological modelling.,"Further investigation about the effects of parameter uncertainty on simulation results shows that although the parameter uncertainty is one of the important sources of uncertainties, its contribution to simulation uncertainty is relatively small.",Much attention has been paid to uncertainty issues in hydrological modelling due to their great effects on prediction and further on decision-making.,"Results show that the approximate results are obtained from both methods, not only in the percentage of observations falling inside the % confidence interval of simulations, but also in the uncertainty range of parameters, although the range obtained from Bayesian method is slightly narrower than that from bootstrap method, possibly due to the correlation structure amongst parameters in the MCMC (Markov Chain Monte Carlo) simulation employed in Bayesian method."
10.1016/j.jcp.2016.10.039,"Multimodal, high-dimensional, model-based, Bayesian inverse problems with applications in biomechanics (2017)","While such information is contained in the posterior density in Bayesian formulations, the discovery of a single mode, let alone multiple, poses a formidable computational task.","This is the setting in many problems in computational physics where forward models with nonlinear PDEs are used and the parameters to be calibrated involve spatio-temporarily varying coefficients, which upon discretization give rise to a high-dimensional vector of unknowns.","We demonstrate the performance of the proposed strategy in nonlinear elastography where the identification of the mechanical properties of biological materials can inform non-invasive, medical diagnosis.",The goal of the present paper is two-fold.,One of the consequences of the well-documented ill-posedness of inverse problems is the possibility of multiple solutions.
10.1016/j.envsoft.2016.01.003,"Parameterization of the InVEST Crop Pollination Model to spatially predict abundance of wild blueberry (Vaccinium angustifolium Aiton) native bee pollinators in Maine, USA (2016)",This suggests that expert opinion may not result in the best parameter values for the InVEST model.,"The proportion of deciduous/mixed forest within  m of a blueberry field also reliably predicted native bee abundance in blueberry fields, however, the InVEST model provides an efficient tool to estimate bee abundance beyond the field perimeter.",We evaluated model performance with parameters informed by four approaches: ) expert opinion; ) sensitivity analysis.,"We applied the InVEST Crop Pollination model, developed to predict native bee abundance from habitat resources, in Maine's wild blueberry crop landscape.",
10.1016/j.cma.2014.06.034,A comparison of different methods for calculating tangent-stiffness matrices in a massively parallel computational peridynamics code (2014),"The methods were compared through profiling of the code for accuracy, speed, efficiency, and parallel scalability.",This research provides data that can serve as practical guide for code developers and analysts faced with choosing which method best suits the needs of their application code.,The complex-step method was implemented in a massively parallel computational peridynamics code for the purpose of this comparison.,,
10.1016/S0045-7825(02)00599-6,Topological sensitivity analysis (2003),The main feature of this methodology is that all the mathematical procedure already developed in the context of shape sensitivity analysis may be used in the calculus of the topological derivative.,This derivative characterizes the sensitivity of the problem when a small hole is created at each point of the domain.,This work proposes an alternative way to compute the topological derivative based on the shape sensitivity analysis concepts.,"Further, to point out the straightforward use of the proposed methodology, it is applied for solving some design problems in steady-state heat conduction.","Therefore, some specific mathematical framework should be developed in order to obtain the derivatives."
10.1016/j.jcp.2013.08.006,A one-time truncate and encode multiresolution stochastic framework (2014),"In addition to algebraic and ordinary differential equations, numerical results for the challenging D Kraichnan-Orszag are reported in terms of accuracy and convergence.","Its formulations permits to recover the same results concerning the interpolation theory of the classical multiresolution approach, but with an extension to uncertainty quantification problems.",All the numerical results are compared with respect to classical Monte Carlo solution and with a non-intrusive Polynomial Chaos method.,"Moreover, the flexibility of the proposed approach allows to employ any kind of probability density function, even discontinuous and time varying, without introducing further complications in the algorithm.","In this work a novel adaptive strategy for stochastic problems, inspired from the classical Harten's framework, is presented."
10.1016/j.jhydrol.2017.10.061,Simultaneous state-parameter estimation supports the evaluation of data assimilation performance and measurement design for soil-water-atmosphere-plant system (2017),This study provides an insight into the response of soil moisture and grain yield to data assimilation in SWAP system and is helpful for soil moisture movement and crop growth modeling and measurement design in practice.,"In this study, simultaneous state-parameter estimation using ensemble Kalman filter (EnKF) was employed to evaluate the data assimilation performance and provide advice on measurement design for SWAP system.","However, the performance of SSPE assimilation strategy could deteriorate with an increasing number of uncertain parameters as a result of soil stratification and limited knowledge on crop parameters.",The results demonstrated that a proper selection of state vector is critical to effective data assimilation.,"In addition to the most easily available surface soil moisture (SSM) and leaf area index (LAI) measurements, deep soil moisture, grain yield or other auxiliary data were required to provide sufficient constraints on parameter estimation and to assure the data assimilation performance."
10.1016/j.jhydrol.2017.03.027,Towards robust quantification and reduction of uncertainty in hydrologic predictions: Integration of particle Markov chain Monte Carlo and factorial polynomial chaos expansion (2017),Results reveal that the degree of spatial variability of soil moisture capacity is the most identifiable model parameter with the fastest convergence through the streamflow assimilation process.,The unified probabilistic framework is applied to the Xiangxi River watershed of the Three Gorges Reservoir (TGR) region in China to demonstrate its validity and applicability.,The particle filtering techniques have been receiving increasing attention from the hydrologic community due to its ability to properly estimate model parameters and states of nonlinear and non-Gaussian systems.,A Gaussian anamorphosis technique is used to establish a seamless bridge between the data assimilation using the PMCMC and the uncertainty propagation using the FPCE through a straightforward transformation of posterior distributions of model parameters.,
10.1016/j.jhydrol.2011.05.052,Uncertainty estimates by Bayesian method with likelihood of AR (1) plus Normal model and AR (1) plus Multi-Normal model in different time-scales hydrological models (2011),"Firstly, the resulting goodness of fit of the daily model vs. observations as measured by the Nash-Sutcliffe efficiency value is comparable with that calculated by the optimization algorithm in monthly WASMOD.",This study pursues a comprehensive inter-comparison and evaluation of uncertainty assessments by Bayesian revision using the Metropolis Hasting (MH) algorithm with the hydrological model WASMOD with daily and monthly time step.,"Secondly, the AR () model is not sufficiently adequate to estimate the distribution of residuals in daily WASMOD since PUCI shows that Model  outperforms Model .",Model  on the other hand is superior for daily time step WASMOD if the auto-correlation of parameters is considered.,"In the daily step model three likelihood functions are used in combination with Bayesian revision: (i) the AR () plus Normal time period independent model (Model ), (ii) the AR () plus Multi-Normal model (Model ), and (iii) the AR () plus Normal time period dependent model (Model )."
10.1016/j.jcp.2015.09.021,Quantification of sampling uncertainty for molecular dynamics simulation: Time-dependent diffusion coefficient in simple fluids (2015),We obtain analytic expressions for the level of the statistical errors present in the time-dependent diffusion coefficient as well as the VACF and the MSD.,"Under the assumption that the velocity of the tracer particle is a Gaussian process, all results are expressed in terms of the VACF.","For validation, we perform MD simulations for the self-diffusion of a Lennard-Jones fluid and the diffusion of a large and massive colloid particle suspended in the fluid.","Hence, the standard errors of all relevant quantities are computable once the VACF is obtained from MD simulation.",
10.1016/j.envsoft.2016.06.018,FSAUA: A framework for sensitivity analysis and uncertainty assessment in historical and forecasted land use maps (2016),This study aims to develop a new conceptual framework for sensitivity analysis and uncertainty assessment (FSAUA) which compares multiple maps under various data error scenarios.,FSAUA performs sensitivity analyses in land use maps using a reference map and assess uncertainty in predicted maps.,Land change modelers often create future maps using reference land use map.,"However, future land use maps may mislead decision-makers, who are often unaware of the sensitivity and the uncertainty in land use maps due to, error in data.","Since most metrics that communicate uncertainty require using reference land use data to calculate accuracy, the assessment of uncertainty becomes challenging when no reference land use map for future is available."
10.1016/j.envsoft.2017.03.005,Rejecting hydro-biogeochemical model structures by multi-criteria evaluation (2017),"However, only .% of all model runs passed the complete rejectionist framework.",This work presents a novel way for assessing and comparing different hydro-biogeochemical model structures and their performances.,Our results show that each model combination had its strength for particular criteria.,"We used the LandscapeDNDC modelling framework to set up four models of different complexity, considering two soil-biogeochemical and two hydrological modules.","In contrast, our comparatively applied assessments of single thresholds, as frequently used in other studies, lead to a much higher acceptance rate of -%."
10.1016/j.envsoft.2014.08.018,"Sensitivity analysis, calibration and validation of EPIC for modelling soil phosphorus dynamics in Swiss agro-ecosystems (2014)","To avoid excessive P accumulation in soil, a methodology for predicting long-term variations in soil P content is required.","After performing a sensitivity analysis to identify the most influential model parameters for which calibration was needed, we calibrated the influential parameters on the available topsoil P data of  selected NABO sites and then we tested the calibrated model by comparison of predictions with data from a second set of  sites.",Proper management of soil phosphorus (P) is essential to ensure sustainability in agriculture.,"Using the Swiss Soil Monitoring Network (NABO) database, we tested the efficiency of the model EPIC to predict soil P temporal changes for typical Swiss arable and grassland sites.",
10.1016/j.jhydrol.2014.10.060,Radionuclide migration through fractured rock for arbitrary-length decay chain: Analytical solution and global sensitivity analysis (2015),The nuclides are retarded as they diffuse in the porous rock matrix and stagnant zones in the fracture.,"Moreover, if one tries to evaluate the true values of the input parameters at the same cost and effort, the determination of priorities should follow a certain sequence.","More importantly, the global sensitivity analysis reveals that for time periods greater than a few thousand years, the uncertainty of the model output is more sensitive to the values of the individual parameters than to the interaction between them.","The analytical solution to the nuclide concentrations at the fracture outlet is governed by nine parameters representing different mechanisms acting on nuclide transport through a fracture, including diffusion into the rock matrices, diffusion into the stagnant water zone, chain decay and hydrodynamic dispersion.",The Sobol indices show how uncertainty in the model output is apportioned to the uncertainty in the model input.
10.1016/j.jhydrol.2005.07.016,Impact of biased and randomly corrupted inputs on the efficiency and the parameters of watershed models (2006),Two different rainfall-runoff model structures were tested to get a more general overview on this issue.,with re-calibration of model parameters).,Results indicate that watershed models use their different functions (and corresponding parameters) to absorb input errors and muffle their impact on streamflow simulations.,,
10.1007/s00158-017-1684-6,Likelihood-based representation of epistemic uncertainty and its application in robustness-based design optimization (2017),This likelihood-based approach is general and is able to estimate the parameters of any known probability distributions.,The likelihood-based representation of epistemic uncertainty is then used in the existing framework for robustness-based design optimization to achieve computational efficiency.,"A worst-case maximum likelihood-based approach is developed for the representation of epistemic uncertainty, which is able to estimate the distribution parameters of a random variable described by sparse point and/or interval data.","In this paper, we propose a new likelihood-based methodology to represent epistemic uncertainty described by sparse point and/or interval data for input variables in uncertainty analysis and design optimization problems.",
10.1016/j.cma.2008.01.008,Statistical volume element method for predicting micro structure-constitutive property relations (2008),"In this paper, we have developed a statistical volume element method to analyze, quantify, and calibrate such microstructure-constitutive property relations by statistical means.",The proposed approach is applied to examine a porous steel alloy material for demonstrative purposes.,Statistical volume element simulations are adopted to predict material constitutive properties corresponding to various realizations of random microstructure configurations.,A statistical cause-effect analysis approach is proposed to study the influence of random material microstructure on material constitutive properties.,"The uncertainties in material constitutive properties due to random microstructure configurations are quantified in terms of distributions, statistical moments, and correlations."
10.1007/s00158-003-0366-8,A unified approach for shape sensitivity analysis of elastic shells (2004),This expression is an explicit function of the tangent and normal components of the known velocity field that characterizes the shape change of the shell.,This approach and the direct method of shape sensitivity analysis leads to a very useful expression for the shape sensitivity of the total potential energy.,"For this purpose, a suitable velocity distribution over the middle surface of the shell, decomposed on a local basis given by the unit normal and the tangent plane of the shell, is adopted.",,
10.1016/j.cma.2015.06.007,A global/local probabilistic approach for reduced-order modeling adapted to the low- and mid-frequency structural dynamics (2015),This paper presents a general framework for constructing the modified kinetic energy by introducing classes of kinematic reductions.,The research presented here is devoted to the construction of a probabilistic reduced-order computational model adapted to the low- and mid-frequency structural dynamics.,,,
10.1007/s00158-017-1742-0,Topology optimization of continuum structures subjected to the variance constraint of reaction forces (2017),"In this paper, the attainment of uniform reaction forces at the specific fixed boundary is investigated for topology optimization of continuum structures.",Numerical examples are dealt with to reveal the effect of the variance constraint in comparison with solutions of standard topology optimization.,,,
10.1016/j.jhydrol.2014.03.021,A similarity index for storm runoff due to saturation excess overland flow (2014),An index for the determination of hydrologic similarity is proposed and demonstrated.,,,,
10.1016/j.jhydrol.2006.09.022,"Suitability of Gamma, Chi-square, Weibull, and beta distributions as synthetic unit hydrographs (2007)","Simple formulae are derived using analytical and numerical schemes to compute the distribution parameters, and their validity is checked with simulation of field data.","Further, an analogous triangular hydrograph approach was used to express the mean and variance of the UH in terms of time base and time to peak of the UH.",Use of Storm and Watershed Characteristics in Synthetic Hydrograph Analysis and Application: V. Mockus.,"Although the validity of this equation could not be evaluated with a proper amount of data, the results give an indication of the relationship between pdf and statistical properties of the UH to be further elaborated in future research.",Both were found to behave similarly at higher alpha (ratio of time to base and time to peak of UH) values.
10.1016/j.cma.2008.03.016,Probabilistic equivalence and stochastic model reduction in multiscale analysis (2008),An illustration in stochastic structural dynamics is provided to demonstrate the proposed framework.,A reduced-order probabilistic model is constructed as a coarse-scale representation of a specified fine-scale model whose probabilistic structure can be accurately determined.,A significant stochastic model reduction can a prior!,This paper presents a probabilistic upscaling of mechanics models.,
10.1016/j.jhydrol.2011.08.030,Model parameter analysis using remotely sensed pattern information in a multi-constraint framework (2011),Results indicate that employing spatially distributed model parameterizations has limited impact on improving model performance when evaluated against traditional model objectives of stream flow and groundwater head.,"In contrast, objective functions that incorporate remote sensing based surface temperatures, highlighted the comparatively poor reproduction of spatial patterns when using a spatially uniform parameterization.","The advantage of incorporating remote sensing based observations into the model evaluation process is their spatially distributed information content, enabling an assessment of the capacity of the model to reproduce observed spatial patterns.","Indeed, a spatially uniform parameterization produced almost identical model performance.","In the analyses, model performance based on objective functions using conventional stream flow and groundwater head observations are compared against objective functions that utilize spatially distributed satellite based surface temperature retrievals as the calibration variable."
10.1007/s00158-017-1689-1,Concurrent topology optimization of multiscale structures with multiple porous materials under random field loading uncertainty (2017),D and D examples demonstrate the effectiveness of the proposed approach in simultaneously obtaining robust optimal macro structural topology and material microstructural topologies.,"To determine the optimal distribution of the porous materials at the macro/structural scale, our key idea is to employ the discrete material optimization method to interpolate the material properties for multiple porous materials.",Design of multiscale structures is a challenging task due to a vast design space of both materials and structures.,This scheme integrates the SIMP (Solid Isotropic Material with Penalization) at the microscale and PAMP (Porous Anisotropic Material with Penalization) at the macroscale into a single equation.,"In this paper, a robust concurrent TO (topology optimization) approach is developed for designing multiscale structures composed of multiple porous materials under random field loading uncertainty."
10.1007/s00158-012-0805-5,Concurrent treatment of parametric uncertainty and metamodeling uncertainty in robust design (2013),Previous metamodel-based robust designs often treat a metamodel as the real model and ignore the influence of metamodeling uncertainty.,This introduces the so-called metamodeling uncertainty.,"The proposed uncertainty quantification method for robust design is shown to be effective in mitigating the effect of metamodeling uncertainty, and the obtained solution is found to be more ""robust"" compared to the conventional approach.",Many works exist on mitigating the influence of parametric uncertainty associated with design or noise variables.,Simplified expressions of the response mean and variance is derived for a Kriging metamodel.
10.1007/s00158-016-1428-z,A full-space barrier method for stress-constrained discrete material design optimization (2016),The proposed optimization algorithm uses a Newton method where an approximate linearization of the KKT conditions is solved inexactly at each iteration using a preconditioned Krylov subspace method.,The advantages of the full-space barrier method are twofold.,Sparse constraints that arise in the discrete material parametrization are treated using a null-space method.,"Second, by using the full-space, it is no longer necessary to employ stress constraint aggregation techniques to reduce adjoint-gradient evaluation costs.",
10.1016/j.envsoft.2013.09.033,A new approach to visualizing time-varying sensitivity indices for environmental model diagnostics across evaluation time-scales (2014),whether dominant processes are emerging in the model at the right times and over the appropriate time periods).,"As a case study, we estimate first order sensitivity indices with the FAST (Fourier Amplitude Sensitivity Test) method for a typical conceptual rainfall-runoff model.",In this short communication we present a new approach to visualizing such time-varying sensitivity across time scales of integration.,"Assessing the time-varying sensitivity of environmental models has become a common approach to understand both the value of different data periods for estimating specific parameters, and as part of a diagnostic analysis of the model structure itself (i.e.",
10.1016/j.envsoft.2016.05.014,A theoretical and real world evaluation of two Bayesian techniques for the calibration of variety parameters in a sugarcane crop model (2016),This study evaluated the use of two Bayesian approaches to calibrate sugarcane varieties in APSIM-Sugar: Generalized Likelihood Uncertainty Estimation (GLUE) and Markov Chain Monte Carlo (MCMC).,"Process based agricultural systems models allow researchers to investigate the interactions between variety, environment and management.",We found that the MCMC approach can be used to calibrate varieties in APSIM-Sugar based on yield data.,"With appropriate variety definitions, APSIM-Sugar could be used for early risk assessment of adopting new varieties.","The 'Sugar' module in the Agricultural Productions Systems sIMulator (APSIM-Sugar) currently includes definitions for  sugarcane varieties, most of which are no longer commercially grown."
10.1016/j.envsoft.2017.07.001,How sensitive is a vineyard crop model to the uncertainty of its runoff module? (2017),This work shows that uncertainty quantification can benefit from the knowledge of mathematical properties of a model and provide clear guidelines to model users.,"In this work, we evaluate for a vineyard crop model the structure uncertainty coming from its uncertain runoff module.",We introduce a new method based on additional knowledge about the runoff process and on a mathematical property of the model structure.,,
10.1016/j.cma.2015.01.012,Reliability sensitivity estimation of nonlinear structural systems under stochastic excitation: A simulation-based approach (2015),"In addition, the method provides information about the whole trend of the reliability sensitivity estimates in terms of the threshold levels.",The approach is validated on two nonlinear structural models under stochastic ground excitation.,This work explores the feasibility of using advanced simulation-based methods for reliability sensitivity analysis of nonlinear structural systems subject to stochastic excitation.,,
10.1016/j.envsoft.2011.10.006,A generic framework for regression regionalization in ungauged catchments (2012),"The approach developed has been applied to both lumped and distributed models, in order to investigate the benefits of adopting distributed models to represent catchment heterogeneity.","Approaches such as this have been criticized due to issues associated with the ability to identify suitable parameter values, as well as the approach used to predict them from catchment information, incorporating interactions between parameters.","Most recently, donor catchment approaches have been identified as the most successful at providing suitable model parameter values.","However, no benefit was found for applying the approach on a distributed scale, most likely due to scale issues with the parameter values.",
10.1007/s00158-014-1061-7,Uncertainty analysis on process responses of conventional spinning using finite element method (2014),"The Most Probable Point (MPP) method, which has been widely used to estimate the failure probability in other applications, is further developed in this paper to obtain the probability distribution of the system responses.","Following an evaluation of the system responses conducted by the MPP method, a control variable method is used to reduce the variance of spun part wall thickness and total roller force to satisfy the  sigma quality requirement.",Three process variables are randomized by Gaussian distribution to study the probabilistic characteristics of two process responses.,"However, inherent uncertainty properties involved in the spinning process are rarely considered in previous studies.","In this paper, an uncertainty analysis and process optimisation procedure have been developed and implemented on conventional spinning with D Finite Element Method (FEM)."
10.1016/j.cma.2011.11.012,A POD-based reduced-order model for free surface shallow water flows over real bathymetries for Monte-Carlo-type applications (2012),"In the present work, the POD bases are constructed from data provided by a full-order finite volume model for a considered benchmark test with some given input parameters.","The ROM is designed by projecting the non-linear shallow-water equations on a low-dimension basis, obtained using the proper orthogonal decomposition (POD) method.","The non-linear terms are treated, through some specific approximations, to obtain the speedup expected from the reduced-order modeling methodology.",The main motivation is the need for a faster numerical model to tackle the challenges posed by multiple-query applications such as optimal design or probabilistic analyses that use a large number of evaluations of the outputs for different values of input parameters.,This study first shows that the reduced-order model can simulate the dynamics of various dam break flows over variable bathymetries with significant speedups.
10.1016/j.cma.2014.06.007,Stress constrained shape and topology optimization with fixed mesh: A B-spline finite cell method combined with level set function (2014),High-order B-spline shape functions are further implemented to ensure precisions of stress analysis and sensitivity analysis.,Involved parameters rather than the conventional discrete form of LSF are directly taken as design variables to facilitate the numerical computing process.,"To be specific, the LSF is constructed by means of R-functions that incorporate cubic splines as implicit functions to offer flexibilities for shape optimization within the framework of fixed mesh, while the compactly supported radial basis functions (CS-RBFs) are employed as implicit functions for stress constrained topology optimization.",It is shown the proposed FCM/LSF method is a convenient approach that makes it possible to calculate stress and stress sensitivities with high precision.,
10.1007/s00158-013-0901-1,A reliability-based multidisciplinary design optimization procedure based on combined probability and evidence theory (2013),"In these two stages, the reliability-based optimization both in the system level and the disciplinary level are computationally expensive as it entails nested optimization and uncertainty analysis.","In the first stage, the surrogate based MDF is used to quickly identify the promising reliable regions.","The existing deterministic multistage-multilevel multidisciplinary design optimization (MDO) procedure MDF-CSSO, which combines the multiple discipline feasible (MDF) procedure and the concurrent subspace optimization (CSSO) procedure to mimic the general conceptual design process, is used as the basic framework.","To alleviate the computational burden, the sequential optimization and mixed uncertainty analysis (SOMUA) method is used to decompose the traditional double-level reliability-based optimization problem into separate deterministic optimization and mixed uncertainty analysis sub-problems, which are solved sequentially and iteratively until convergence is achieved.","In the second stage, the surrogate based CSSO is used to organize the disciplinary optimization and system coordination, which allows the disciplinary specialists to investigate and optimize the design with the corresponding high-fidelity models independently and concurrently."
10.1016/j.jhydrol.2006.08.001,Sensitivity analysis and identification of the best evapotranspiration and runoff options for hydrological modelling in SWAT-2000 (2007),"As a first step, a sensitivity analysis was conducted to identify the sensitive parameters affecting stream flow for subsequent application in stream flow calibration.",Usually a calibration is undertaken to reduce the uncertainties associated with the estimation of model parameters.,"To ensure efficient calibration, a sensitivity analysis is conducted to identify the most sensitive parameters.",SWAT gives various options for both evapotranspiration and runoff modelling.,"The Hargreaves and Penman-Montieth methods of evapotranspiration estimation and the NRCS curve number (CN) and Green and Ampt infiltration methods for runoff estimation techniques were used, in four different combinations, to identify the combination of methodologies that best reproduced the observed data."
10.1007/s00158-015-1391-0,A reliability index extrapolation method for separable limit states (2016),"The accuracies of these simulation based techniques, on the other hand, diminishes as the structural reliability increases.",This paper proposes a reliability index extrapolation method to predict reliability of a highly safe structure that has a separable limit state function.,The accuracy of the proposed method is evaluated through reliability assessment of mathematical and structural mechanics example problems as well as a reliability based design optimization problem.,"Finally, an extrapolation is performed to estimate the actual (higher) reliability index.",It is found that the proposed method can provide reasonable accuracy for high reliability index estimations with only  response function evaluations.
10.1007/s00158-016-1550-y,Remarks on multi-fidelity surrogates (2017),"Three counterparts in simple frameworks are also included, which have the same functional form but can be built with ready-made surrogates.","For the examples considered, MFS frameworks were found to be more useful for saving computational time rather than improving accuracy.",The cross-validation error appears to be a reasonable candidate for estimating poor MFS frameworks for a specific problem but it does not perform well compared to choosing single fidelity surrogates.,Computational cost savings and accuracy improvement over a single fidelity surrogate model are investigated as a function of the ratio of the sampling costs between low and high fidelity simulations.,"For the Hartmann  function example, the maximum cost saving for the same accuracy was  %, while the maximum accuracy improvement for the same cost was %."
10.1016/j.envsoft.2012.07.008,Bayesian belief modeling of climate change impacts for informing regional adaptation options (2013),"Using two cases, this article focuses on the processes and methodological issues relating to the use of the BBN modeling technique when the data are based on expert opinion.","The article raises questions about the most appropriate scale at which the methodology applied can be used to identify useful generic determinants of adaptive capacity when, at the scale used, the most useful determinants were sector-specific.","Comparisons between individual BBN conditional probabilities identified diverging and converging beliefs, and that the sensitivity of response variables to direct descendant nodes was not always perceived consistently.",The study expected to find both generic and specific determinants of adaptive capacity based on the perceptions of the stakeholders involved.,While generic determinants were found (e.g.
10.1016/j.envsoft.2014.05.007,"Model simplification and development via reuse, sensitivity analysis and composition: A case study in crop modelling (2014)","In particular, two new versions of WOFOST, the most widespread model from this family, were developed.","Crop models, like many representations of environmental processes, tend to be over-parameterised.",Each version was evaluated for rice and winter wheat.,"Results highlighted a similar accuracy for the three versions: the original one achieved mean normalized RMSE of .% and .% for winter wheat and rice; corresponding values for the new versions were .% and .% (WOFOST-GT), and .% and .% (WOFOST-GT).","A redesign of the SUCROS family of crop models, largely driven by sensitivity analysis, is presented here."
10.1007/s00158-010-0527-5,Topology optimization involving thermo-elastic stress loads (2010),"Furthermore, sensitivity analysis of the structural mean compliance is developed in the case of steady-state heat conduction.","In such a way, the element stiffness and the thermal stress load can be penalized independently in terms of element pseudo-density.",Numerical examples of two-phase and three-phase materials are presented.,The key issues about the penalty models of the element stiffness and thermal stress load of the finite element model are highlighted.,Structural topology optimization of thermo-elastic problems is investigated in this paper.
10.1016/j.cma.2007.09.027,Multivariate approach to the thermal challenge problem (2008),The correlation structure of the model was used to pool the prediction/measurement differences to evaluate the corresponding cumulative density function (CDF).,This paper presents an engineering approach to the thermal challenge problem defined by Dowding et al.,"The effect of model parameter uncertainty is accounted for through first-order sensitivity analysis for the ensemble/validation tests, and first-order sensitivity analysis and Monte-Carlo analysis for the regulatory prediction.",This approach to model validation is based on a multivariate validation metric that accounts for model parameter uncertainty and correlation between multiple measurement/prediction differences.,The use of a temperature dependent effective conductivity with the linear model resulted in model predictions that were consistent with the data.
10.1016/j.envsoft.2011.03.002,Evaluation of an integrated land use change model including a scenario analysis of land use change for continental Africa (2011),"The global integrated land use model, LandSHIFT, is evaluated by testing its performance against available data sets, by analyzing the sensitivity of model parameters and structure, and by conducting a scenario analysis of future land use change in Africa.","Results showed that cropland land may expand greatly up to  (-%, depending on the scenario) because of increasing food demand and despite expected increases in crop yield.","This expansion comes largely at the expense of forested land, although the average continental deforestation rate computed from  to  is lower than the computed rate for the s. The testing and scenario analysis showed the ability of the model to develop consistent scenarios of land use change on the continental scale by combining the effects of driving forces and competition between land uses in a single spatially-explicit framework.",The model showed more ability to calculate the spatial distribution of cropland suitability and continental average deforestation rates than to compute the spatial distribution of deforestation.,"With regards to the scenario analysis, the model was applied to two scenarios for Africa that cover a wide range of assumptions about future driving forces."
10.1016/j.jcp.2016.10.029,Systematic parameter inference in stochastic mesoscopic modeling (2017),Fully access to the response surfaces within the confidence range enables us to infer the optimal force parameters given the desirable values of target properties at the macroscopic scale.,"To alleviate the computational cost to evaluate the target properties, we employ the compressive sensing method to compute the coefficients of the dominant gPC terms given the prior knowledge that the coefficients are ""sparse"".","The response surfaces of various target properties (viscosity, diffusivity, pressure, etc.)","The proposed method provides an efficient alternative approach for constructing mesoscopic models by inferring model parameters to recover target properties of the physics systems (e.g., from experimental measurements), where those force field parameters and formulation cannot be derived from the microscopic level in a straight forward way.",
10.1016/j.jcp.2013.01.020,Adjoint design sensitivity analysis of reduced atomic systems using generalized Langevin equation for lattice structures (2013),"A reduced atomic system and the adjoint system are constructed in a locally confined region, utilizing generalized Langevin equation (GLE) for periodic lattice structures.","Due to the translational symmetry of lattice structures, the size of time history kernel function that accounts for the boundary effects of the reduced atomic systems could be reduced to a single atom's degrees of freedom.","However, the adjoint method is very efficient regardless of the number of design variables since one additional time integration is required for the adjoint GLE.",An efficient adjoint design sensitivity analysis method is developed for reduced atomic systems.,"Through numerical examples, the derived adjoint sensitivity turns out to be accurate and efficient through the comparison with finite difference sensitivity."
10.1016/j.jhydrol.2015.06.004,Development of an inexact-variance hydrological modeling system for analyzing interactive effects of multiple uncertain parameters (2015),"The results show that, under a lower degree of plausibility (i.e.",The modeling outputs indicate a good performance of SLURP model in describing the daily streamflow at the Dashankou hydrological station.,"Results based on ANOVA reveal that (i) precipitation factor (PF), one of main factors dominating the runoff processes, should be paid more attention in order to enhance the model performance; (ii) retention constant for fast store (RS) controls the amount and timing of the outflow from saturated zone and has a highly nonlinear effect on the average flow; (iii) the interaction between retention constant for fast store (RF) and maximum capacity for fast store (MF) has statistically significant (p < .)","In this study, an inexact-variance hydrological modeling system (IVHMS) is developed for assessing parameter uncertainty on modeling outputs in the Kaidu River Basin, China.",effect on modeling outputs through affecting the maximum water holding capacity and the soil infiltration rate.
10.1016/j.envsoft.2016.04.010,A comparison of two Bayesian approaches for uncertainty quantification (2016),"Whereas the MCMC approach samples probable draws of the parameters, the MCPD samples the most probable draws when one of the parameters is set at various prescribed values.","Recently, an alternative technique to calculate the so-called Maximal Conditional Posterior Distribution (MCPD) appeared.",The results show that parameter and predictive uncertainties can be accurately assessed with both the MCMC and MCPD approaches.,"In this study, the results of a user-friendly MCMC sampler called DREAM((zs)) and those of the MCPD sampler are compared.",
10.1016/j.jcp.2015.06.013,Stochastic Discrete Equation Method (sDEM) for two-phase flows (2015),The propagation of initial conditions uncertainties is evaluated in terms of mean and variance of several thermodynamic properties of the two phases.,Some reference test-cases are performed in order to demonstrate the convergence properties and the efficiency of the overall scheme.,A new scheme for the numerical approximation of a five-equation model taking into account Uncertainty Quantification (UQ) is presented.,,
10.1016/j.jcp.2013.04.009,A flexible uncertainty quantification method for linearly coupled multi-physics systems (2013),We demonstrate the utility of such a framework on a practical application involving a linearly coupled multi-species reactive transport model.,"Our ""hybrid"" UQ methodology supports independent development of the most suitable UQ method, intrusive or non-intrusive, for each physics module by providing an algorithmic framework to couple these ""stochastic"" modules for propagating ""global"" uncertainties.",,,
10.1016/j.cma.2016.10.047,Hybrid uncertain static analysis with random and interval fields (2017),"Subsequently, by utilizing either parametric or nonparametric statistical analysis, the probability density functions (PDFs), as well as the cumulative distribution functions (CDFs), of the extreme bounds of the concerned structural responses can be effectively established.","Unlike the traditional hybrid uncertain static analysis involving random and interval variables, the concept of random and interval fields has been implemented to model the spatially dependent uncertainties associated with the system inputs.",,,
10.1016/j.envsoft.2013.03.012,Using a parallelized MCMC algorithm in R to identify appropriate likelihood functions for SWAT (2013),We provide this approach to reduce barriers to the use of MCMC algorithms and to promote the development of appropriate likelihood functions.,The general approach is transferrable to any executable that reads input files.,"For long-running models, the Differential Evolution Adaptive Metropolis (DREAM) algorithm offers spectacular reductions in time required for MCMC analysis.","The ability to use this feature is hindered in models that have a large number of input files, such as SWAT.",Markov Chain Monte Carlo (MCMC) algorithms allow the analysis of parameter uncertainty.
10.1007/s00158-016-1642-8,Shape optimization of microstructural designs subject to local stress constraints within an XFEM-level set framework (2017),"The problem formulation relies on the extended finite element method (XFEM) combined with a level set representation of the geometry, to deal with complex microstructures and handle large shape modifications while working on fixed meshes.","()), the scope of the developed approach is extended to tackle the problem of stress objective or constraint functions.",The present paper investigates the tailoring of bimaterial microstructures minimizing their local stress field exploiting shape optimization.,,
10.1016/j.envsoft.2016.03.010,Applicability of Hydrologic Response Units in low topographic relief catchments and evaluation using high resolution aerial photograph analysis (2016),Topography and geomorphology of a catchment are major drivers of runoff generation.,The thresholds derived from the DEM analysis are found in the same range as obtained from the aerial photographs analysis.,"To verify the proposed HRUs delineation logic, the thresholds derived from the DEM analysis are evaluated here at catchment scale using high resolution aerial photograph analysis and associated site visits.","In the present study, this approach is evaluated for low topographic relief catchment and found to be applicable.",
10.1016/j.jcp.2013.11.016,Selection of polynomial chaos bases via Bayesian model uncertainty methods with applications to sparse approximation of PDEs with stochastic inputs (2014),"The proposed methods are suitable for, but not restricted to, problems whose stochastic solutions are sparse in the stochastic space with respect to the gPC bases while the deterministic solver involved is expensive.","Moreover, the proposed methods quantify the importance of the gPC bases in the probabilistic sense through inclusion probabilities.",Generalized polynomial chaos (gPC) expansions allow us to represent the solution of a stochastic system using a series of polynomial chaos basis functions.,The number of gPC terms increases dramatically as the dimension of the random input variables increases.,The former accounts for the model uncertainty and provides Bayes-optimal predictions; while the latter provides a sparse representation of the stochastic solutions by evaluating the expansion on a subset of dominating gPC bases.
10.1016/j.envsoft.2017.06.044,Uncertainty related to climate change in the assessment of the DDF curve parameters (2017),"In the context of climate change, the evaluation of the parameters of Depth-Duration-Frequency (DDF) curves has become a critical issue.","In this study, uncertainty analysis was integrated into trend analysis to provide an estimate of trends that cannot actually be rigorously verified.",The methodology was implemented to estimate the DDF parameters for  sites in Sicily (Southern Italy).,A Bayesian procedure was suggested for the updating of DDF curve parameters and to evaluate the uncertainty related to their assessment.,
10.1007/s00158-016-1422-5,Reliability-based topology optimization using a new method for sensitivity approximation - application to ground structures (2016),"In the literature, those problems are primarily performed with approaches that use a first-order reliability method (FORM) to estimate the gradient of the probability of failure.","Meanwhile, this implementation also improves the approximation of the probability evaluation at no extra cost.",This paper proposes an efficient gradient-based optimization approach for reliability-based topology optimization of structures under uncertainties.,"However, these approaches may lead to deficient or even invalid results because the gradient of probabilistic constraints, calculated by first order approximation, might not be sufficiently accurate.","To overcome this issue, a newly developed segmental multi-point linearization (SML) method is employed in the optimization approach for a more accurate estimation of the gradient of failure probability."
10.1016/j.jhydrol.2016.02.042,Classification of hydrological parameter sensitivity and evaluation of parameter transferability across 431 US MOPEX basins (2016),The sensitivity of CLM-simulated water and energy fluxes to hydrological parameters across  MOPEX basins are first examined using an efficient stochastic sampling-based sensitivity analysis approach.,This study aims to evaluate the potential of transferring hydrologic model parameters in CLM through sensitivity analyses and classification across watersheds from the Model Parameter Estimation Experiment (MOPEX) in the United States.,"The basins are then classified according to their parameter sensitivity patterns (internal attributes), as well as their hydrologic indices attributes (external hydrologic factors) separately, using Principal component analysis (PCA) and expectation-maximization (EM) - based clustering approach.","Similarities and differences among the parameter sensitivity-based classification system (S-Class), the hydrologic indices-based classification (H-Class), and the Koppen climate classification systems (K-Class) are discussed.","Within each parameter sensitivity-based classification system (S-Class) with similar parameter sensitivity characteristics, similar inversion modeling setups can be used for parameter calibration, and the parameters and their contribution or significance to water and energy cycling may also be more transferrable."
10.1016/j.cma.2004.02.027,Robust design of non-linear structures using optimization methods (2005),The robust design of non-linear structures with path-dependent response is stated as a two-criteria optimization problem and is solved by the method of mathematical programming.,"desirability function, and feasibility indices in the constraints, the mathematical model of structural robust design problem is formulated and is solved with a gradient-based algorithm.",,,
10.1016/j.cma.2016.01.003,Nonlinear structural design using multiscale topology optimization. Part II: Transient formulation (2016),We extend the hierarchical multiscale design framework of Nakshatrala et al.,It is assumed that the primary wavelengths of interest are much longer than the micro-structural length scale and hence the effective properties are computed using the static homogenization theory.,"As in Part I, a well-posed topology optimization problem is obtained via (a) relaxation to design the macroscale which requires homogenization theory to relate the macroscopic homogenized response to its micro-structure and (b) via restriction to design the microscale to obtain a well-defined micro-structural length scale.",() to nonlinear elastodynamics wherein we use topology optimization to design material micro-structures to achieve desired energy propagation in nonlinear elastic material systems subjected to impact loading.,
10.1016/j.jhydrol.2014.10.025,Efficient calibration of a distributed pde-based hydrological model using grid coarsening (2014),"Comparing the model results for these different grids, we observe differences in peak discharge, evapotranspiration, and near-surface saturation.","In this study, we present an efficient model calibration strategy, based on a hierarchy of grid resolutions, each of them resolving the same zonation of subsurface and land-surface units.",The calibration results are satisfactory and the duration of the calibration has been greatly decreased by using different model grid resolutions.,Partial-differential-equation based integrated hydrological models are now regularly used at catchment scale.,"Hydraulic heads and low flow, however, are very similar for all tested parameter sets, which allows the use of these variables to calibrate our model."
10.1016/j.envsoft.2013.09.031,A comprehensive evaluation of various sensitivity analysis methods: A case study with a hydrological model (2014),"For the Sobol' method, the minimum samples needed are  to compute the first-order and total sensitivity indices correctly.",(C)  The Authors.,"All SA methods are tested using a variety of sampling techniques to screen out the most sensitive (i.e., important) parameters from the insensitive ones.","Morris One-At-a-Time (MOAT) screening is the most efficient, needing only  samples to identify the most important parameters, but it is the least robust method.","We use a newly developed software package, a Problem Solving environment for Uncertainty Analysis and Design Exploration (PSUADE), to evaluate the effectiveness and efficiency of ten widely used SA methods, including seven qualitative and three quantitative ones."
10.1016/j.envsoft.2016.12.005,Metamodeling and global sensitivity analysis for computer models with correlated inputs: A practical approach tested with a 3D light interception computer model (2017),It is based on a truncated Polynomial Chaos Expansion of the output whose coefficients are estimated by Partial Least Squares Regression.,We now have fast-running metamodels that simultaneously provide good approximations of the outputs of this computer model and a clear overview of its input influences thanks to new sensitivity indices.,This situation of non-independence between the inputs is always a challenge in view of simultaneously achieving a global sensitivity analysis of the model output and a metamodeling of this output.,"In this paper, a novel practical method is proposed for reaching this two-fold goal.",
10.1016/j.jhydrol.2014.06.019,"The dilemma of spatial representation for urban hydrology semi-distributed modelling: Trade-offs among complexity, calibration and geographical data (2014)","Results for water quantity modelling show that the inclusion of some basic geographical information, particularly on land uses, clearly improves performances, but further refinements are less effective.",The Nash criterion is used to calibrate the model and compare alternative configurations.,,,
10.1007/s00158-015-1351-8,A semi-single-loop method using approximation of most probable point for reliability-based design optimization (2016),A decoupled method has also been developed in an effort to improve the efficiency of RBDO.,"As long as the approximation of MPP is valid, the proposed method has a complete single-loop structure with great efficiency and assured accuracy.",This structure makes up for the weaknesses of the double-loop method and the single-loop method.,Numerical examples are tested to verify these advantages of the proposed method and to compare the results here to those of existing RBDO methods.,"According to the validity of the approximation, the approximated MPP is used for the evaluation of probabilistic constraints."
10.1016/j.cma.2005.05.005,Uncertainty propagation in finite deformations - A spectral stochastic Lagrangian approach (2006),A total Lagrangian approach to the stochastic large deformation problem is presented.,,,,
10.1016/j.jhydrol.2009.10.010,Deriving probabilistic regional envelope curves with two pooling methods (2010),"In this study, the influence of two pooling methods on PREC for a large group of catchments located in the south-east of Germany is investigated.",A probabilistic regional envelope Curve (PREC) assigns a recurrence interval to a regional envelope curve.,A leave-one-out jackknifing procedure points out a similar performance of cluster analysis and RoI.,The ensemble of PREC realisations reveals the sensitivity of the PREC flood quantiles.,A flood discharge associated with the recurrence interval (PREC flood quantile) is estimated for each gauge of a homogeneous region.
10.1016/j.jhydrol.2016.04.073,Sensitivity analysis of standardization procedures in drought indices to varied input data selections (2016),"Using meteorological observations (-) in the Yellow River basin,  sub-datasets with a length of  years are firstly generated with the moving window method.","In addition, it is found that the introduction of the self-calibrating procedure for duration factors further aggravates the dependence of drought index on input datasets compared with original empirical algorithm that Palmer uses, making SC-PDSI more sensitive to variations in data sample.","Then we use the whole time series and  sub-datasets to compute two indices separately, and compare their spatiotemporal differences, as well as performances in capturing drought areas.","Sensitivity analysis shows that among the three parameters in the generalized extreme value (GEV) distribution, SPDI is most sensitive to changes in the scale parameter, followed by location and shape parameters.",
